entity,coupled,degree,average-revs
vllm/lora/layers/logits_processor.py,vllm/lora/layers/vocal_parallel_embedding.py,100,7
csrc/attention/paged_attention_v1.cu,csrc/attention/paged_attention_v2.cu,100,7
vllm/lora/ops/sgmv_expand.py,vllm/lora/ops/sgmv_expand_slice.py,100,7
cacheflow/model_executor/models/gpt2.py,cacheflow/model_executor/models/opt.py,100,6
cacheflow/model_executor/models/gpt2.py,cacheflow/model_executor/models/gpt_neox.py,100,6
cacheflow/model_executor/models/gpt_neox.py,cacheflow/model_executor/models/opt.py,100,6
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json","vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json",100,5
benchmarks/disagg_benchmarks/disagg_overhead_benchmark.sh,benchmarks/disagg_benchmarks/disagg_performance_benchmark.sh,100,5
docs/features/quantization/fp8.md,docs/features/quantization/int4.md,100,5
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json","vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json",100,5
vllm/lora/ops/bgmv_expand.py,vllm/lora/ops/bgmv_expand_slice.py,100,5
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json","vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json",100,5
examples/online_serving/prithvi_geospatial_mae.py,tests/plugins_tests/test_io_processor_plugins.py,92,7
vllm/lora/ops/sgmv_expand_slice.py,vllm/lora/ops/sgmv_shrink.py,92,7
vllm/lora/layers/base.py,vllm/lora/layers/logits_processor.py,92,7
vllm/lora/ops/sgmv_expand.py,vllm/lora/ops/sgmv_shrink.py,92,7
vllm/lora/layers/base.py,vllm/lora/layers/vocal_parallel_embedding.py,92,7
examples/offline_inference/prithvi_geospatial_mae_io_processor.py,examples/online_serving/prithvi_geospatial_mae.py,90,6
docs/features/quantization/int4.md,docs/features/quantization/int8.md,90,6
docs/features/quantization/fp8.md,docs/features/quantization/int8.md,90,6
cacheflow/model_executor/models/gpt2.py,cacheflow/model_executor/models/llama.py,90,6
cacheflow/model_executor/models/gpt_neox.py,cacheflow/model_executor/models/llama.py,90,6
cacheflow/model_executor/models/llama.py,cacheflow/model_executor/models/opt.py,90,6
requirements/test.in,requirements/test.txt,88,82
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/block/interfaces.py,88,17
vllm/lora/layers/column_parallel_linear.py,vllm/lora/layers/vocal_parallel_embedding.py,87,8
vllm/lora/layers/column_parallel_linear.py,vllm/lora/layers/logits_processor.py,87,8
vllm/lora/ops/triton_ops/lora_expand_op.py,vllm/lora/ops/triton_ops/lora_shrink_op.py,85,11
csrc/rocm/ops.h,csrc/rocm/torch_bindings.cpp,85,11
csrc/punica/bgmv/bgmv_config.h,tests/lora/test_punica.py,83,16
vllm/lora/ops/bgmv_expand_slice.py,vllm/lora/ops/sgmv_expand.py,83,6
examples/offline_inference/prithvi_geospatial_mae_io_processor.py,tests/plugins_tests/test_io_processor_plugins.py,83,6
vllm/lora/ops/bgmv_expand_slice.py,vllm/lora/ops/sgmv_expand_slice.py,83,6
cacheflow/config.py,cacheflow/server/arg_utils.py,83,6
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/multi_process_adapter.py,vllm/distributed/kv_transfer/kv_connector/v1/lmcache_mp_connector.py,83,6
csrc/quantization/gptq_marlin/awq_marlin_repack.cu,csrc/quantization/gptq_marlin/gptq_marlin_repack.cu,83,6
tests/lora/test_punica_sizes.py,tests/lora/test_punica_variation.py,83,6
csrc/quantization/marlin/dense/marlin_cuda_kernel.cu,csrc/quantization/marlin/qqq/marlin_qqq_gemm_kernel.cu,83,6
vllm/lora/ops/bgmv_expand.py,vllm/lora/ops/sgmv_expand.py,83,6
vllm/lora/ops/bgmv_expand.py,vllm/lora/ops/sgmv_expand_slice.py,83,6
csrc/moe/marlin_moe_wna16/generate_kernels.py,csrc/moe/marlin_moe_wna16/ops.cu,83,6
examples/offline_inference/basic/embed.py,examples/offline_inference/basic/score.py,83,6
vllm/lora/layers/base.py,vllm/lora/layers/column_parallel_linear.py,80,8
tests/kernels/test_causal_conv1d.py,tests/kernels/test_mamba_ssm.py,80,8
csrc/custom_all_reduce.cuh,csrc/custom_all_reduce_test.cu,80,8
vllm/core/block/naive_block.py,vllm/core/block/prefix_caching_block.py,78,19
vllm/core/block/interfaces.py,vllm/core/block/naive_block.py,78,17
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/block/naive_block.py,78,17
tests/distributed/test_basic_distributed_correctness.py,tests/distributed/test_chunked_prefill_distributed.py,77,9
tests/v1/kv_connector/unit/test_remote_decode_lifecycle.py,tests/v1/kv_connector/unit/test_remote_prefill_lifecycle.py,77,9
tests/models/language/pooling/test_nomic.py,tests/models/language/pooling/test_snowflake_arctic_embed.py,76,7
tests/models/test_aqlm.py,tests/models/test_gptq_marlin_24.py,76,7
tests/samplers/test_typical_acceptance_sampler.py,vllm/model_executor/layers/typical_acceptance_sampler.py,76,7
tests/v1/determinism/test_batch_invariance.py,tests/v1/determinism/utils.py,76,7
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py,76,7
docs/source/dev/offline_inference/llm_inputs.rst,tests/mq_llm_engine/utils.py,76,7
vllm/v1/attention/backends/tree_attn.py,vllm/v1/attention/backends/xformers.py,75,12
tests/v1/attention/test_attention_splitting.py,vllm/v1/worker/ubatch_utils.py,75,8
vllm/lora/layers/column_parallel_linear.py,vllm/lora/layers/row_parallel_linear.py,75,8
vllm/lora/layers/column_parallel_linear.py,vllm/lora/lora_weights.py,75,8
csrc/ops.h,csrc/torch_bindings.cpp,74,129
vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py,vllm/transformers_utils/tokenizer_group/tokenizer_group.py,73,10
vllm/lora/layers/base_linear.py,vllm/lora/layers/column_parallel_linear.py,73,10
vllm/model_executor/models/bamba.py,vllm/model_executor/models/mamba2.py,72,17
cacheflow/models/llama.py,cacheflow/models/opt.py,72,13
.github/workflows/clang-format.yml,.github/workflows/yapf.yml,72,11
vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py,vllm/model_executor/layers/mamba/ops/ssd_combined.py,72,11
vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py,vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py,72,11
vllm/lora/layers/logits_processor.py,vllm/lora/layers/row_parallel_linear.py,71,7
vllm/lora/layers/row_parallel_linear.py,vllm/lora/layers/vocal_parallel_embedding.py,71,7
tests/compile/piecewise/test_multiple_graphs.py,tests/compile/test_decorator.py,71,7
csrc/cutlass_extensions/epilogue/scaled_mm_epilogues_c2x.hpp,csrc/cutlass_extensions/epilogue/scaled_mm_epilogues_c3x.hpp,71,7
tests/tokenization/test_tokenizer_group.py,vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py,71,7
vllm/model_executor/models/bamba.py,vllm/model_executor/models/zamba2.py,70,19
tests/v1/sample/test_sampler.py,vllm/v1/sample/metadata.py,70,16
tests/mq_llm_engine/test_error_handling.py,tests/mq_llm_engine/utils.py,70,10
cacheflow/server/llm_server.py,examples/simple_server.py,70,9
csrc/attention_kernels.cu,tests/kernels/attention.py,70,9
vllm/model_executor/layers/mamba/ops/ssd_combined.py,vllm/model_executor/layers/mamba/ops/ssd_state_passing.py,70,9
vllm/lora/layers/base_linear.py,vllm/lora/layers/vocal_parallel_embedding.py,70,9
tests/entrypoints/openai/test_rerank.py,tests/entrypoints/openai/test_score.py,70,9
vllm/lora/layers/base_linear.py,vllm/lora/layers/logits_processor.py,70,9
vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py,vllm/model_executor/layers/mamba/ops/ssd_state_passing.py,70,9
tests/compile/piecewise/test_simple.py,tests/compile/piecewise/test_toy_llama.py,69,23
vllm/core/block/common.py,vllm/core/block/interfaces.py,69,13
tests/core/block/test_prefix_caching_block.py,vllm/core/block/prefix_caching_block.py,68,18
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,68,18
.github/workflows/ruff.yml,.github/workflows/yapf.yml,68,15
tests/models/registry.py,vllm/model_executor/models/registry.py,67,271
csrc/moe/moe_ops.h,csrc/moe/torch_bindings.cpp,66,26
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/block/prefix_caching_block.py,66,20
vllm/core/block/interfaces.py,vllm/core/block/prefix_caching_block.py,66,20
vllm/model_executor/models/bamba.py,vllm/model_executor/models/falcon_h1.py,66,17
tests/v1/spec_decode/test_ngram.py,vllm/v1/spec_decode/ngram_proposer.py,66,17
tests/quantization/test_torchao.py,vllm/model_executor/layers/quantization/torchao.py,66,14
tests/kernels/moe/test_pplx_cutlass_moe.py,tests/kernels/moe/test_pplx_moe.py,66,11
vllm/model_executor/model_loader/runai_streamer_loader.py,vllm/model_executor/model_loader/sharded_state_loader.py,66,9
csrc/quantization/gguf/gguf_kernel.cu,csrc/quantization/gguf/mmvq.cuh,66,9
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_dynamictoken.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_statictensor.py,66,8
vllm/v1/worker/gpu/sample/penalties.py,vllm/v1/worker/gpu/sample/sampler.py,66,8
csrc/quantization/machete/generate.py,csrc/quantization/machete/machete_prepack_launcher.cuh,66,8
tests/samplers/test_typical_acceptance_sampler.py,vllm/model_executor/layers/spec_decode_base_sampler.py,66,8
examples/offline_inference/vision_language.py,examples/offline_inference/vision_language_multi_image.py,64,80
tests/kernels/moe/test_deepep_deepgemm_moe.py,tests/kernels/moe/test_deepep_moe.py,64,14
tests/kernels/test_activation.py,tests/kernels/test_layernorm.py,64,13
vllm/core/block/common.py,vllm/core/block/naive_block.py,64,13
vllm/model_executor/models/clip.py,vllm/model_executor/models/siglip.py,63,36
tests/kernels/moe/test_cutlass_moe.py,tests/kernels/moe/test_pplx_cutlass_moe.py,63,11
vllm/model_executor/models/nemotron.py,vllm/model_executor/models/solar.py,63,11
csrc/moe/marlin_moe_ops.cu,csrc/moe/marlin_moe_ops.h,63,10
csrc/mamba/causal_conv1d/causal_conv1d.cu,tests/kernels/test_causal_conv1d.py,63,10
docs/source/dev/multimodal/multimodal_index.rst,docs/source/dev/offline_inference/llm_inputs.rst,63,10
vllm/model_executor/models/mamba2.py,vllm/model_executor/models/zamba2.py,62,16
vllm/model_executor/models/falcon_h1.py,vllm/model_executor/models/zamba2.py,62,16
vllm/model_executor/models/aquila.py,vllm/model_executor/models/internlm.py,62,15
tests/core/block/test_prefix_caching_block.py,vllm/core/block/naive_block.py,62,15
csrc/mamba/causal_conv1d/causal_conv1d.cu,csrc/mamba/causal_conv1d/causal_conv1d.h,62,8
csrc/quantization/fp4/activation_nvfp4_quant_fusion_kernels.cu,csrc/quantization/fp4/nvfp4_experts_quant.cu,62,8
csrc/moe/marlin_moe_wna16/kernel.h,csrc/moe/marlin_moe_wna16/marlin_template.h,62,8
tests/models/test_gptq_marlin.py,tests/models/test_gptq_marlin_24.py,62,8
vllm/lora/layers/base.py,vllm/lora/layers/base_linear.py,62,8
csrc/quantization/fp4/nvfp4_experts_quant.cu,csrc/quantization/fp4/nvfp4_quant_entry.cu,62,8
tests/models/test_gptq_marlin_24.py,tests/models/test_marlin.py,62,8
.github/workflows/actionlint.yml,.github/workflows/clang-format.yml,62,8
csrc/moe/marlin_moe_wna16/marlin_template.h,csrc/quantization/gptq_marlin/marlin_template.h,62,8
vllm/model_executor/layers/spec_decode_base_sampler.py,vllm/model_executor/layers/typical_acceptance_sampler.py,62,8
vllm/model_executor/models/bert.py,vllm/model_executor/models/roberta.py,61,34
vllm/engine/multiprocessing/__init__.py,vllm/engine/multiprocessing/client.py,61,33
vllm/model_executor/layers/fused_moe/fused_batched_moe.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,61,21
vllm/core/block/common.py,vllm/core/block/cpu_gpu_block_allocator.py,61,13
vllm/model_executor/layers/quantization/awq_marlin.py,vllm/model_executor/layers/quantization/gptq_marlin.py,60,51
vllm/model_executor/models/bloom.py,vllm/model_executor/models/gpt_neox.py,60,20
vllm/model_executor/models/gpt_j.py,vllm/model_executor/models/gpt_neox.py,60,20
vllm/model_executor/models/granitemoehybrid.py,vllm/model_executor/models/mamba2.py,60,15
vllm/model_executor/models/falcon_h1.py,vllm/model_executor/models/granitemoehybrid.py,60,15
vllm/core/block/block_table.py,vllm/core/block/common.py,60,12
tests/spec_decode/e2e/test_medusa_correctness.py,tests/spec_decode/e2e/test_ngram_correctness.py,60,10
docs/source/models/generative_models.md,docs/source/models/pooling_models.md,60,10
tests/models/test_gptq_marlin.py,tests/models/test_marlin.py,60,10
vllm/core/block_manager_v1.py,vllm/core/block_manager_v2.py,59,22
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/fused_batched_moe.py,59,19
requirements/build.txt,requirements/rocm-build.txt,59,14
.github/workflows/clang-format.yml,.github/workflows/ruff.yml,59,14
vllm/attention/backends/rocm_flash_attn.py,vllm/attention/backends/xformers.py,58,53
vllm/platforms/hpu.py,vllm/platforms/neuron.py,58,21
vllm/model_executor/models/llama_eagle.py,vllm/model_executor/models/llama_eagle3.py,58,21
tests/compile/test_functionalization.py,tests/compile/test_fusion.py,58,17
vllm/model_executor/models/granitemoehybrid.py,vllm/model_executor/models/zamba2.py,58,17
vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py,vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py,58,16
tests/samplers/test_rejection_sampler.py,vllm/model_executor/layers/rejection_sampler.py,58,16
tests/spec_decode/test_spec_decode_worker.py,vllm/spec_decode/interfaces.py,58,16
tests/v1/kv_connector/unit/test_offloading_connector.py,vllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py,58,12
vllm/v1/executor/ray_executor.py,vllm/v1/executor/uniproc_executor.py,58,12
vllm/model_executor/layers/rotary_embedding/base.py,vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py,58,12
cacheflow/config.py,cacheflow/server/llm_server.py,58,9
csrc/mamba/mamba_ssm/selective_scan.h,csrc/mamba/mamba_ssm/selective_scan_fwd.cu,58,9
csrc/quantization/gguf/dequantize.cuh,csrc/quantization/gguf/gguf_kernel.cu,58,9
tests/models/test_aqlm.py,tests/models/test_marlin.py,58,9
vllm/lora/layers/base_linear.py,vllm/lora/layers/row_parallel_linear.py,58,9
tests/models/test_aqlm.py,tests/models/test_gptq_marlin.py,58,9
csrc/torch_bindings.cpp,vllm/_custom_ops.py,57,170
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,57,26
vllm/model_executor/layers/quantization/experts_int8.py,vllm/model_executor/layers/quantization/moe_wna16.py,57,18
vllm/model_executor/models/bamba.py,vllm/model_executor/models/granitemoehybrid.py,57,18
vllm/model_executor/models/falcon_h1.py,vllm/model_executor/models/mamba2.py,57,14
tests/spec_decode/test_ngram_worker.py,vllm/spec_decode/top1_proposer.py,57,11
vllm/model_executor/models/exaone.py,vllm/model_executor/models/solar.py,57,11
benchmark/benchmark_latency.py,simple_server.py,57,11
tests/entrypoints/test_responses_utils.py,vllm/entrypoints/responses_utils.py,57,11
cacheflow/model_executor/layers/sampler.py,cacheflow/sampling_params.py,57,11
vllm/model_executor/models/blip2.py,vllm/model_executor/models/chameleon.py,56,36
vllm/model_executor/models/llava_next_video.py,vllm/model_executor/models/llava_onevision.py,56,34
vllm/attention/backends/ipex_attn.py,vllm/attention/backends/pallas.py,56,23
vllm/core/block_manager_v2.py,vllm/core/interfaces.py,56,20
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/block_manager_v2.py,56,20
cacheflow/worker/controller.py,cacheflow/worker/worker.py,56,16
tests/spec_decode/e2e/test_mlp_correctness.py,tests/spec_decode/e2e/test_ngram_correctness.py,56,13
tests/compile/test_sequence_parallelism.py,vllm/compilation/vllm_inductor_pass.py,56,13
vllm/engine/multiprocessing/__init__.py,vllm/engine/multiprocessing/engine.py,55,27
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,55,24
tests/distributed/test_pynccl.py,vllm/distributed/device_communicators/pynccl.py,55,24
vllm/lora/punica_wrapper/punica_base.py,vllm/lora/punica_wrapper/punica_gpu.py,55,20
tests/multimodal/test_cache.py,vllm/multimodal/cache.py,55,15
cacheflow/models/model_utils.py,cacheflow/models/opt.py,55,15
tests/core/block/test_naive_block.py,tests/core/block/test_prefix_caching_block.py,55,9
tests/compile/test_async_tp.py,tests/compile/test_sequence_parallelism.py,55,9
tests/v1/cudagraph/test_cudagraph_dispatch.py,vllm/v1/cudagraph_dispatcher.py,55,9
vllm/v1/attention/backends/mamba1_attn.py,vllm/v1/attention/backends/short_conv_attn.py,55,9
vllm/v1/worker/gpu/sample/metadata.py,vllm/v1/worker/gpu/states.py,55,9
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py,55,9
.buildkite/lm-eval-harness/run-lm-eval-gsm-hf-baseline.sh,.buildkite/lm-eval-harness/run-lm-eval-gsm-vllm-baseline.sh,55,9
tests/tokenization/test_tokenizer_group.py,vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py,55,9
csrc/moe/marlin_moe_wna16/marlin_template.h,csrc/moe/marlin_moe_wna16/ops.cu,55,9
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py,55,9
vllm/model_executor/layers/fused_moe/fused_moe_method_base.py,vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py,55,9
.github/workflows/actionlint.yml,.github/workflows/yapf.yml,55,9
vllm/model_executor/model_loader/base_loader.py,vllm/model_executor/model_loader/tensorizer_loader.py,55,9
vllm/transformers_utils/config.py,vllm/transformers_utils/configs/__init__.py,54,126
vllm/v1/engine/async_llm.py,vllm/v1/engine/llm_engine.py,54,112
tests/v1/core/test_kv_cache_utils.py,vllm/v1/core/kv_cache_utils.py,54,66
tests/models/decoder_only/vision_language/test_models.py,tests/models/decoder_only/vision_language/vlm_utils/model_utils.py,54,33
.buildkite/scripts/generate-nightly-index.py,.buildkite/scripts/upload-wheels.sh,54,11
tests/v1/tpu/test_sampler.py,vllm/v1/sample/tpu/metadata.py,54,11
vllm/worker/openvino_model_runner.py,vllm/worker/openvino_worker.py,54,11
vllm/v1/worker/gpu/cudagraph_utils.py,vllm/v1/worker/gpu/model_runner.py,53,34
vllm/distributed/kv_transfer/kv_connector/v1/base.py,vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py,53,32
vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,53,28
vllm/v1/sample/metadata.py,vllm/v1/sample/sampler.py,53,26
tests/core/block/test_prefix_caching_block.py,vllm/core/block/interfaces.py,53,15
tests/core/block/test_prefix_caching_block.py,vllm/core/block/cpu_gpu_block_allocator.py,53,15
vllm/model_executor/models/glm4v.py,vllm/model_executor/models/qwen_vl.py,53,15
tests/v1/sample/test_rejection_sampler.py,vllm/v1/sample/metadata.py,53,15
tests/compile/test_functionalization.py,vllm/compilation/vllm_inductor_pass.py,53,13
tests/entrypoints/openai/test_serving_models.py,vllm/entrypoints/openai/serving_models.py,53,13
vllm/model_executor/models/granite.py,vllm/model_executor/models/solar.py,53,13
vllm/v1/attention/backends/mamba1_attn.py,vllm/v1/attention/backends/mamba2_attn.py,53,13
vllm/model_executor/layers/quantization/awq.py,vllm/model_executor/layers/quantization/squeezellm.py,53,13
vllm/transformers_utils/tokenizer_group/__init__.py,vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py,53,13
vllm/model_executor/models/llava.py,vllm/model_executor/models/llava_next.py,52,80
vllm/model_executor/layers/fused_moe/fused_batched_moe.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,52,33
vllm/inputs/__init__.py,vllm/inputs/data.py,52,23
tests/compile/test_fusion.py,vllm/compilation/fusion.py,52,21
vllm/model_executor/layers/quantization/experts_int8.py,vllm/model_executor/layers/quantization/quark/quark_moe.py,52,19
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,52,17
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/interfaces.py,52,17
tests/kernels/test_activation.py,tests/kernels/test_pos_encoding.py,52,17
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/ipex_attn.py,52,17
vllm/core/block/interfaces.py,vllm/core/interfaces.py,52,17
csrc/mamba/causal_conv1d/causal_conv1d.cu,csrc/mamba/mamba_ssm/selective_scan_fwd.cu,52,12
vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py,vllm/transformers_utils/tokenizer_group/tokenizer_group.py,52,12
vllm/model_executor/layers/fused_moe/fused_moe_method_base.py,vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py,52,12
docs/source/dev/offline_inference/llm_inputs.rst,vllm/inputs/__init__.py,52,12
tests/spec_decode/e2e/test_medusa_correctness.py,tests/spec_decode/e2e/test_mlp_correctness.py,52,12
tests/models/language/pooling/test_gte.py,tests/models/language/pooling/test_nomic.py,52,10
csrc/quantization/fp4/nvfp4_experts_quant.cu,csrc/quantization/fp4/nvfp4_quant_kernels.cu,52,10
vllm/model_executor/models/aquila.py,vllm/transformers_utils/configs/aquila.py,52,10
docs/source/dev/offline_inference/llm_inputs.rst,tests/mq_llm_engine/test_error_handling.py,52,10
tests/samplers/test_rejection_sampler.py,vllm/model_executor/layers/spec_decode_base_sampler.py,52,10
tests/spec_decode/e2e/test_logprobs.py,tests/spec_decode/e2e/test_ngram_correctness.py,52,10
tests/v1/core/test_prefix_caching.py,vllm/v1/core/kv_cache_manager.py,51,66
csrc/cache.h,csrc/cache_kernels.cu,51,33
vllm/v1/worker/gpu/input_batch.py,vllm/v1/worker/gpu/model_runner.py,51,31
tests/v1/sample/test_sampler.py,tests/v1/worker/test_gpu_input_batch.py,51,22
vllm/core/block_manager_v1.py,vllm/core/interfaces.py,51,20
vllm/core/block/interfaces.py,vllm/core/block_manager_v2.py,51,20
vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,51,18
vllm/spec_decode/batch_expansion.py,vllm/spec_decode/interfaces.py,51,16
tests/v1/sample/test_rejection_sampler.py,tests/v1/sample/test_sampler.py,51,16
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,51,16
vllm/core/block/common.py,vllm/core/block/prefix_caching_block.py,51,16
vllm/core/block/block_table.py,vllm/core/block/interfaces.py,51,16
vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py,vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py,51,14
vllm/attention/backends/torch_sdpa.py,vllm/attention/backends/xformers.py,50,40
tests/v1/core/utils.py,tests/v1/kv_connector/unit/utils.py,50,24
vllm/core/block/prefix_caching_block.py,vllm/core/block_manager_v2.py,50,22
vllm/model_executor/models/falcon.py,vllm/model_executor/models/gpt_j.py,50,20
vllm/model_executor/models/falcon.py,vllm/model_executor/models/gpt_neox.py,50,20
vllm/model_executor/models/bloom.py,vllm/model_executor/models/gpt_j.py,50,20
.github/workflows/mypy.yaml,.github/workflows/yapf.yml,50,20
vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py,vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py,50,20
vllm/model_executor/models/falcon_h1.py,vllm/model_executor/models/nemotron_h.py,50,18
tests/spec_decode/test_multi_step_worker.py,vllm/spec_decode/multi_step_worker.py,50,18
benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py,tests/kernels/quantization/test_block_fp8.py,50,16
vllm/v1/worker/gpu/input_batch.py,vllm/v1/worker/gpu/spec_decode/eagle.py,50,16
csrc/layernorm_kernels.cu,csrc/layernorm_quant_kernels.cu,50,16
vllm/spec_decode/ngram_worker.py,vllm/spec_decode/top1_proposer.py,50,14
tests/spec_decode/test_multi_step_worker.py,tests/spec_decode/utils.py,50,14
vllm/model_executor/models/mistral.py,vllm/model_executor/models/yi.py,50,12
vllm/v1/executor/ray_executor.py,vllm/v1/executor/ray_utils.py,50,12
cacheflow/master/server.py,simple_server.py,50,12
vllm/entrypoints/openai/rpc/client.py,vllm/entrypoints/openai/rpc/server.py,50,12
cacheflow/core/scheduler.py,cacheflow/server/llm_server.py,50,12
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,vllm/model_executor/layers/fused_moe/prepare_finalize.py,50,12
vllm/model_executor/model_loader/gguf_loader.py,vllm/model_executor/model_loader/tensorizer_loader.py,50,12
cacheflow/models/memory_analyzer.py,cacheflow/models/model_utils.py,50,12
vllm/model_executor/model_loader/sharded_state_loader.py,vllm/model_executor/model_loader/tensorizer_loader.py,50,10
docs/source/dev/multimodal/multimodal_index.rst,tests/mq_llm_engine/utils.py,50,10
vllm/model_executor/model_loader/openvino.py,vllm/worker/openvino_model_runner.py,50,10
vllm/model_executor/model_loader/base_loader.py,vllm/model_executor/model_loader/gguf_loader.py,50,10
tests/distributed/test_context_parallel.py,vllm/attention/ops/common.py,50,10
vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py,vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py,50,10
cacheflow/models/llama.py,cacheflow/models/memory_analyzer.py,50,10
vllm/model_executor/model_loader/runai_streamer_loader.py,vllm/model_executor/model_loader/tensorizer_loader.py,50,10
csrc/ops.h,vllm/_custom_ops.py,49,169
vllm/entrypoints/openai/serving_chat.py,vllm/entrypoints/openai/serving_completion.py,49,148
tests/quantization/test_compressed_tensors.py,vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py,49,69
vllm/attention/backends/flash_attn.py,vllm/attention/backends/xformers.py,49,57
vllm/v1/metrics/loggers.py,vllm/v1/metrics/stats.py,49,53
benchmarks/benchmark_latency.py,benchmarks/benchmark_throughput.py,48,65
vllm/model_executor/models/blip2.py,vllm/model_executor/models/fuyu.py,48,38
vllm/entrypoints/openai/serving_embedding.py,vllm/entrypoints/openai/serving_pooling.py,48,35
.github/workflows/mypy.yaml,format.sh,48,33
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/xformers.py,48,29
tests/entrypoints/llm/test_guided_generate.py,vllm/model_executor/guided_decoding/__init__.py,48,27
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/fused_batched_moe.py,48,27
vllm/v1/core/kv_cache_coordinator.py,vllm/v1/core/single_type_kv_cache_manager.py,48,25
vllm/model_executor/models/gpt_neox.py,vllm/model_executor/models/mpt.py,48,19
vllm/model_executor/models/gpt_j.py,vllm/model_executor/models/mpt.py,48,19
csrc/rocm/attention.cu,csrc/rocm/ops.h,48,17
vllm/core/block/naive_block.py,vllm/core/interfaces.py,48,17
cacheflow/core/scheduler.py,cacheflow/sequence.py,48,17
vllm/spec_decode/batch_expansion.py,vllm/spec_decode/util.py,48,17
vllm/spec_decode/batch_expansion.py,vllm/spec_decode/top1_proposer.py,48,17
tests/kernels/test_layernorm.py,tests/kernels/test_pos_encoding.py,48,15
vllm/model_executor/models/minimax_vl_01.py,vllm/model_executor/models/tarsier.py,48,13
cacheflow/models/memory_analyzer.py,cacheflow/models/opt.py,48,13
vllm/reasoning/abs_reasoning_parsers.py,vllm/reasoning/gptoss_reasoning_parser.py,48,13
vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,vllm/model_executor/layers/fused_moe/prepare_finalize.py,48,13
vllm/model_executor/models/chameleon.py,vllm/model_executor/models/fuyu.py,47,36
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,47,34
vllm/model_executor/guided_decoding/__init__.py,vllm/model_executor/guided_decoding/xgrammar_decoding.py,47,30
vllm/model_executor/layers/quantization/awq_marlin.py,vllm/model_executor/layers/quantization/experts_int8.py,47,28
requirements-test.in,requirements-test.txt,47,28
vllm/attention/backends/ipex_attn.py,vllm/attention/backends/torch_sdpa.py,47,28
tests/v1/worker/test_gpu_input_batch.py,vllm/v1/sample/metadata.py,47,21
vllm/model_executor/models/granitemoehybrid.py,vllm/model_executor/models/nemotron_h.py,47,19
vllm/core/block/naive_block.py,vllm/core/block_manager_v2.py,47,19
tests/lora/test_chatglm3_tp.py,tests/lora/test_llama_tp.py,47,17
tests/models/language/pooling/mteb_utils.py,vllm/model_executor/models/bert_with_rope.py,47,17
vllm/model_executor/models/dots_ocr.py,vllm/model_executor/models/siglip2navit.py,47,17
vllm/platforms/hpu.py,vllm/platforms/openvino.py,47,17
benchmark/benchmark_latency.py,cacheflow/master/server.py,47,11
tests/v1/spec_decode/test_ngram.py,vllm/v1/spec_decode/suffix_decoding.py,47,11
cacheflow/core/scheduler.py,cacheflow/model_executor/layers/sampler.py,47,11
tests/spec_decode/test_ngram_worker.py,vllm/spec_decode/ngram_worker.py,47,11
tests/spec_decode/test_multi_step_worker.py,tests/spec_decode/test_ngram_worker.py,47,11
vllm/model_executor/models/bert.py,vllm/model_executor/models/modernbert.py,46,35
vllm/model_executor/models/jamba.py,vllm/model_executor/models/mamba.py,46,33
tests/kernels/test_attention.py,tests/kernels/test_cache.py,46,32
vllm/distributed/device_communicators/base_device_communicator.py,vllm/distributed/device_communicators/cuda_communicator.py,46,22
vllm/model_executor/models/falcon.py,vllm/model_executor/models/opt.py,46,22
vllm/v1/worker/gpu/cudagraph_utils.py,vllm/v1/worker/gpu/input_batch.py,46,20
Dockerfile.neuron,Dockerfile.ppc64le,46,15
docs/source/dev/multimodal/multimodal_index.rst,vllm/inputs/__init__.py,46,15
vllm/spec_decode/interfaces.py,vllm/spec_decode/top1_proposer.py,46,13
tests/entrypoints/llm/test_encode.py,tests/entrypoints/llm/test_generate.py,46,13
vllm/v1/attention/backends/mamba2_attn.py,vllm/v1/attention/backends/short_conv_attn.py,46,13
cacheflow/core/scheduler.py,cacheflow/sampling_params.py,46,13
vllm/model_executor/layers/quantization/experts_int8.py,vllm/model_executor/layers/quantization/rtn.py,46,13
vllm/v1/spec_decode/ngram_proposer.py,vllm/v1/spec_decode/suffix_decoding.py,46,13
tests/lora/test_lora_manager.py,tests/lora/utils.py,46,13
tests/lora/test_fused_moe_lora_kernel.py,vllm/lora/ops/triton_ops/fused_moe_lora_op.py,46,13
tests/spec_decode/test_multi_step_worker.py,vllm/spec_decode/interfaces.py,46,13
vllm/platforms/cuda.py,vllm/platforms/interface.py,45,134
vllm/v1/engine/__init__.py,vllm/v1/request.py,45,49
vllm/executor/gpu_executor.py,vllm/executor/ray_gpu_executor.py,45,44
vllm/engine/multiprocessing/client.py,vllm/engine/multiprocessing/engine.py,45,40
csrc/attention/attention_kernels.cu,tests/kernels/test_attention.py,45,31
tests/v1/sample/test_sampler.py,vllm/v1/sample/sampler.py,45,27
vllm/model_executor/models/bloom.py,vllm/model_executor/models/gpt2.py,45,22
vllm/model_executor/models/nemotron_h.py,vllm/model_executor/models/zamba2.py,45,20
vllm/model_executor/models/bloom.py,vllm/model_executor/models/falcon.py,45,20
vllm/compilation/collective_fusion.py,vllm/compilation/sequence_parallelism.py,45,20
vllm/model_executor/guided_decoding/outlines_decoding.py,vllm/model_executor/guided_decoding/outlines_logits_processors.py,45,18
vllm/inputs/__init__.py,vllm/inputs/parse.py,45,18
tests/distributed/test_comm_ops.py,tests/distributed/test_custom_all_reduce.py,45,16
vllm/core/block/block_table.py,vllm/core/block/cpu_gpu_block_allocator.py,45,16
Dockerfile.tpu,docs/source/getting_started/tpu-installation.rst,45,16
tests/core/test_block_manager.py,tests/core/utils.py,45,16
.buildkite/nightly-benchmarks/scripts/convert-results-json-to-markdown.py,.buildkite/nightly-benchmarks/scripts/run-performance-benchmarks.sh,45,16
vllm/model_executor/model_loader/gguf_loader.py,vllm/model_executor/model_loader/sharded_state_loader.py,45,11
tests/kernels/test_mamba_ssm.py,vllm/model_executor/layers/mamba/ops/mamba_ssm.py,45,11
vllm/model_executor/model_loader/gguf_loader.py,vllm/model_executor/model_loader/runai_streamer_loader.py,45,11
vllm/model_executor/models/aquila.py,vllm/model_executor/models/yi.py,45,11
tests/lora/test_baichuan.py,tests/lora/test_quant_model.py,45,11
vllm/lora/punica_wrapper/punica_base.py,vllm/lora/punica_wrapper/punica_tpu.py,45,11
tests/entrypoints/test_renderer.py,vllm/entrypoints/renderer.py,45,11
cacheflow/models/memory_analyzer.py,cacheflow/models/sample.py,45,11
.github/workflows/add_label_automerge.yml,.github/workflows/reminder_comment.yml,45,11
tests/compile/backend.py,vllm/compilation/vllm_inductor_pass.py,45,11
tests/spec_decode/e2e/test_logprobs.py,tests/spec_decode/e2e/test_mlp_correctness.py,45,11
csrc/quantization/cutlass_w8a8/scaled_mm_c2x.cuh,csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu,45,11
vllm/transformers_utils/tokenizer_group/__init__.py,vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py,45,11
vllm/platforms/tpu.py,vllm/platforms/xpu.py,44,73
requirements/nightly_torch_test.txt,requirements/test.in,44,55
vllm/lora/models.py,vllm/lora/worker_manager.py,44,47
tests/v1/engine/test_engine_core.py,tests/v1/engine/test_engine_core_client.py,44,43
tests/spec_decode/test_spec_decode_worker.py,vllm/spec_decode/spec_decode_worker.py,44,39
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/qwen.py,44,36
vllm/v1/attention/backends/mla/flashmla.py,vllm/v1/attention/backends/mla/rocm_aiter_mla.py,44,34
vllm/v1/attention/backends/mla/flashattn_mla.py,vllm/v1/attention/backends/mla/flashmla.py,44,30
vllm/executor/gpu_executor.py,vllm/executor/neuron_executor.py,44,25
.github/workflows/mypy.yaml,.github/workflows/ruff.yml,44,23
vllm/model_executor/models/gpt_bigcode.py,vllm/model_executor/models/gpt_j.py,44,23
vllm/model_executor/models/gpt_bigcode.py,vllm/model_executor/models/gpt_neox.py,44,23
vllm/core/block/block_table.py,vllm/core/block_manager_v2.py,44,18
vllm/model_executor/models/mamba2.py,vllm/model_executor/models/nemotron_h.py,44,18
tests/compile/test_fusion.py,vllm/compilation/vllm_inductor_pass.py,44,18
cacheflow/models/opt.py,cacheflow/models/sample.py,44,14
vllm/model_executor/models/exaone.py,vllm/model_executor/models/granite.py,44,14
tests/mq_llm_engine/utils.py,vllm/engine/multiprocessing/__init__.py,44,14
docs/models/supported_models.md,tests/models/registry.py,43,245
vllm/attention/backends/flash_attn.py,vllm/attention/backends/flashinfer.py,43,72
vllm/inputs/data.py,vllm/inputs/preprocess.py,43,46
vllm/v1/worker/gpu/model_runner.py,vllm/v1/worker/gpu/spec_decode/eagle.py,43,30
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,43,26
vllm/model_executor/models/bamba.py,vllm/model_executor/models/nemotron_h.py,43,21
vllm/model_executor/models/bloom.py,vllm/model_executor/models/mpt.py,43,19
vllm/model_executor/models/falcon.py,vllm/model_executor/models/mpt.py,43,19
vllm/model_executor/models/blip.py,vllm/model_executor/models/intern_vit.py,43,16
cacheflow/worker/controller.py,simple_server.py,43,12
tests/kernels/moe/test_cutlass_moe.py,tests/kernels/moe/test_pplx_moe.py,43,12
.buildkite/nightly-benchmarks/benchmark-pipeline.yaml,.buildkite/nightly-benchmarks/scripts/wait-for-image.sh,43,12
csrc/mamba/causal_conv1d/causal_conv1d.h,vllm/model_executor/layers/mamba/ops/causal_conv1d.py,43,12
csrc/quantization/fp8/common.cu,csrc/quantization/fp8/common.cuh,43,12
vllm/model_executor/layers/quantization/fbgemm_fp8.py,vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py,43,12
.github/workflows/cleanup_pr_body.yml,.github/workflows/pre-commit.yml,43,12
vllm/model_executor/models/internlm.py,vllm/model_executor/models/yi.py,43,12
vllm/reasoning/abs_reasoning_parsers.py,vllm/reasoning/basic_parsers.py,43,12
.github/workflows/actionlint.yml,.github/workflows/ruff.yml,43,12
vllm/transformers_utils/tokenizer_group/__init__.py,vllm/transformers_utils/tokenizer_group/tokenizer_group.py,43,12
vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py,vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py,43,12
vllm/model_executor/models/exaone.py,vllm/model_executor/models/nemotron.py,43,12
vllm/core/interfaces.py,vllm/core/placeholder_block_space_manager.py,43,12
vllm/model_executor/models/qwen2_5_vl.py,vllm/model_executor/models/qwen2_vl.py,42,109
vllm/model_executor/models/llava.py,vllm/model_executor/models/phi3v.py,42,84
tests/v1/core/test_kv_cache_utils.py,tests/v1/core/test_prefix_caching.py,42,54
vllm/model_executor/models/qwen2_audio.py,vllm/model_executor/models/ultravox.py,42,42
vllm/entrypoints/openai/serving_embedding.py,vllm/entrypoints/openai/serving_score.py,42,38
tests/models/multimodal/generation/test_common.py,tests/models/multimodal/generation/vlm_utils/model_utils.py,42,36
cmake/cpu_extension.cmake,csrc/cpu/torch_bindings.cpp,42,35
vllm/entrypoints/openai/serving_pooling.py,vllm/entrypoints/openai/serving_score.py,42,26
vllm/inputs/data.py,vllm/inputs/parse.py,42,24
vllm/model_executor/models/aquila.py,vllm/model_executor/models/baichuan.py,42,24
tests/v1/sample/test_rejection_sampler.py,tests/v1/worker/test_gpu_input_batch.py,42,21
.github/workflows/clang-format.yml,.github/workflows/mypy.yaml,42,19
tests/v1/test_serial_utils.py,vllm/v1/serial_utils.py,42,19
tests/spec_decode/test_spec_decode_worker.py,vllm/spec_decode/batch_expansion.py,42,19
tests/compile/test_fusion.py,tests/compile/test_silu_mul_quant_fusion.py,42,19
tests/entrypoints/llm/test_guided_generate.py,tests/model_executor/test_guided_processors.py,42,17
tests/mq_llm_engine/test_error_handling.py,vllm/engine/multiprocessing/__init__.py,42,17
vllm/compilation/inductor_pass.py,vllm/compilation/sequence_parallelism.py,42,17
tests/spec_decode/test_spec_decode_worker.py,tests/spec_decode/utils.py,42,17
vllm/model_executor/models/olmoe.py,vllm/model_executor/models/phimoe.py,42,17
.buildkite/scripts/hardware_ci/run-tpu-v1-test-part2.sh,.buildkite/scripts/hardware_ci/run-tpu-v1-test.sh,42,17
tests/entrypoints/openai/test_audio.py,tests/entrypoints/openai/test_video.py,42,17
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py,42,14
vllm/model_executor/models/granite.py,vllm/model_executor/models/nemotron.py,42,14
tests/kernels/moe/test_block_fp8.py,tests/kernels/moe/test_deepep_deepgemm_moe.py,42,14
vllm/model_executor/layers/rejection_sampler.py,vllm/model_executor/layers/typical_acceptance_sampler.py,42,14
vllm/spec_decode/top1_proposer.py,vllm/spec_decode/util.py,42,14
benchmarks/kernels/benchmark_marlin.py,tests/kernels/test_marlin_gemm.py,42,14
tests/entrypoints/openai/test_transcription_validation.py,tests/entrypoints/openai/test_translation_validation.py,42,14
tests/models/test_llava.py,tests/models/test_llava_next.py,42,14
vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,vllm/model_executor/layers/fused_moe/prepare_finalize.py,42,14
docs/models/supported_models.md,vllm/model_executor/models/registry.py,41,230
vllm/platforms/interface.py,vllm/platforms/rocm.py,41,125
vllm/model_executor/models/llava_next.py,vllm/model_executor/models/phi3v.py,41,65
tests/multimodal/test_processing.py,vllm/multimodal/processing.py,41,60
tests/v1/worker/test_gpu_input_batch.py,vllm/v1/worker/gpu_input_batch.py,41,56
vllm/model_executor/models/llava_next.py,vllm/model_executor/models/llava_onevision.py,41,51
vllm/model_executor/models/llava_next.py,vllm/model_executor/models/llava_next_video.py,41,44
vllm/spec_decode/batch_expansion.py,vllm/spec_decode/spec_decode_worker.py,41,39
vllm/model_executor/layers/fused_moe/cutlass_moe.py,vllm/model_executor/layers/fused_moe/fused_batched_moe.py,41,32
vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/fused_batched_moe.py,41,29
vllm/multimodal/__init__.py,vllm/multimodal/base.py,41,27
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/internlm.py,41,24
vllm/model_executor/layers/quantization/experts_int8.py,vllm/model_executor/layers/quantization/gguf.py,41,22
requirements/cpu-build.txt,requirements/cpu.txt,41,22
tests/model_executor/test_guided_processors.py,vllm/model_executor/guided_decoding/__init__.py,41,22
vllm/model_executor/layers/quantization/moe_wna16.py,vllm/model_executor/layers/quantization/quark/quark_moe.py,41,22
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py,41,20
tests/v1/generation/test_batch_invariance.py,vllm/model_executor/layers/batch_invariant.py,41,20
vllm/core/block/prefix_caching_block.py,vllm/core/interfaces.py,41,20
vllm/v1/executor/abstract.py,vllm/v1/executor/uniproc_executor.py,41,17
vllm/model_executor/models/aquila.py,vllm/model_executor/models/gpt_j.py,41,17
vllm/model_executor/models/aquila.py,vllm/model_executor/models/gpt_neox.py,41,17
vllm/spec_decode/interfaces.py,vllm/spec_decode/multi_step_worker.py,41,17
tests/models/language/pooling/mteb_utils.py,tests/models/language/pooling/test_jina.py,41,15
vllm/model_executor/layers/fused_moe/prepare_finalize.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,41,15
docs/source/dev/multimodal/multimodal_index.rst,vllm/multimodal/__init__.py,41,15
.buildkite/nightly-benchmarks/README.md,.buildkite/nightly-benchmarks/scripts/convert-results-json-to-markdown.py,41,15
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/prepare_finalize.py,41,12
Dockerfile.openvino,Dockerfile.xpu,41,12
tests/lora/test_chatglm3_tp.py,tests/lora/test_quant_model.py,41,12
tests/mq_llm_engine/utils.py,vllm/inputs/__init__.py,41,12
csrc/quantization/cutlass_w8a8/scaled_mm_c2x.cu,csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu,41,12
tests/kernels/mamba/test_mamba_ssm_ssd.py,vllm/model_executor/layers/mamba/ops/ssd_combined.py,41,12
tests/spec_decode/e2e/test_multistep_correctness.py,tests/spec_decode/e2e/test_ngram_correctness.py,41,12
vllm/reasoning/abs_reasoning_parsers.py,vllm/reasoning/mistral_reasoning_parser.py,41,12
cacheflow/models/llama.py,cacheflow/models/model_utils.py,41,12
vllm/lora/ops/triton_ops/lora_shrink_op.py,vllm/lora/ops/triton_ops/utils.py,41,12
docs/source/dev/offline_inference/llm_inputs.rst,vllm/inputs/parse.py,41,12
csrc/cutlass_extensions/epilogue/scaled_mm_epilogues_c3x.hpp,csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu,41,12
vllm/v1/engine/core.py,vllm/v1/engine/core_client.py,40,128
vllm/entrypoints/openai/serving_completion.py,vllm/entrypoints/openai/serving_engine.py,40,125
vllm/platforms/interface.py,vllm/platforms/tpu.py,40,96
examples/offline_inference/vision_language.py,tests/models/multimodal/processing/test_common.py,40,90
vllm/attention/backends/flash_attn.py,vllm/attention/backends/rocm_flash_attn.py,40,69
vllm/engine/metrics.py,vllm/engine/metrics_types.py,40,30
vllm/model_executor/layers/quantization/awq_marlin.py,vllm/model_executor/layers/quantization/moe_wna16.py,40,30
examples/offline_inference_vision_language.py,examples/offline_inference_vision_language_multi_image.py,40,28
tests/entrypoints/openai/test_audio.py,tests/entrypoints/openai/test_vision.py,40,27
benchmarks/kernels/benchmark_paged_attention.py,tests/kernels/test_attention.py,40,25
vllm/model_executor/models/gpt2.py,vllm/model_executor/models/gpt_bigcode.py,40,25
vllm/model_executor/models/bloom.py,vllm/model_executor/models/gpt_bigcode.py,40,23
vllm/executor/cpu_executor.py,vllm/executor/neuron_executor.py,40,23
vllm/model_executor/models/gritlm.py,vllm/model_executor/models/modernbert.py,40,23
vllm/model_executor/models/dots_ocr.py,vllm/model_executor/models/ernie45_vl.py,40,22
vllm/model_executor/models/gpt2.py,vllm/model_executor/models/gpt_neox.py,40,22
vllm/model_executor/models/olmoe.py,vllm/model_executor/models/qwen2_moe.py,40,22
vllm/model_executor/models/deepseek_vl2.py,vllm/model_executor/models/h2ovl.py,40,20
vllm/model_executor/models/bert_with_rope.py,vllm/model_executor/models/modernbert.py,40,20
csrc/activation_kernels.cu,csrc/pos_encoding_kernels.cu,40,18
vllm/model_executor/models/falcon.py,vllm/model_executor/models/phi.py,40,18
tests/core/test_block_manager.py,vllm/core/block_manager_v2.py,40,18
csrc/rocm/attention.cu,csrc/rocm/torch_bindings.cpp,40,15
cacheflow/models/attention.py,cacheflow/models/opt.py,40,15
vllm/core/block/block_table.py,vllm/core/block/naive_block.py,40,15
tests/compile/backend.py,tests/compile/test_fusion.py,40,15
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py,40,15
vllm/v1/worker/gpu/input_batch.py,vllm/v1/worker/gpu/states.py,40,15
tests/core/test_block_manager.py,vllm/core/interfaces.py,40,15
vllm/model_executor/layers/rejection_sampler.py,vllm/model_executor/layers/spec_decode_base_sampler.py,40,15
cacheflow/models/model_utils.py,cacheflow/worker/controller.py,40,13
tests/models/language/pooling/mteb_utils.py,tests/models/language/pooling/test_nomic.py,40,13
tests/compile/test_functionalization.py,vllm/compilation/fix_functionalization.py,40,13
tests/kernels/test_attention_selector.py,vllm/worker/openvino_worker.py,40,13
tests/mq_llm_engine/utils.py,vllm/inputs/parse.py,40,13
tests/compile/test_silu_mul_quant_fusion.py,vllm/compilation/activation_quant_fusion.py,40,13
cacheflow/models/attention.py,cacheflow/models/memory_analyzer.py,40,13
cacheflow/sampling_params.py,simple_server.py,40,13
vllm/model_executor/models/llama4_eagle.py,vllm/model_executor/models/llama_eagle.py,40,13
cacheflow/models/attention.py,cacheflow/models/input_metadata.py,40,13
vllm/platforms/cuda.py,vllm/platforms/rocm.py,39,141
tests/v1/kv_connector/unit/test_nixl_connector.py,vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py,39,73
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/cutlass_moe.py,39,28
tests/kernels/moe/test_deepep_deepgemm_moe.py,vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,39,26
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/pallas.py,39,23
vllm/v1/attention/backends/mla/flashmla.py,vllm/v1/attention/backends/mla/triton_mla.py,39,23
vllm/attention/ops/chunked_prefill_paged_decode.py,vllm/attention/ops/prefix_prefill.py,39,21
vllm/model_executor/models/gemma.py,vllm/model_executor/models/phi.py,39,21
vllm/engine/async_llm_engine.py,vllm/engine/llm_engine.py,38,218
requirements/nightly_torch_test.txt,requirements/test.txt,38,57
vllm/attention/backends/flash_attn.py,vllm/attention/backends/utils.py,38,55
vllm/attention/backends/rocm_flash_attn.py,vllm/attention/backends/torch_sdpa.py,38,52
vllm/model_executor/layers/fused_moe/cutlass_moe.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,38,42
vllm/entrypoints/openai/serving_embedding.py,vllm/entrypoints/openai/serving_tokenization.py,38,39
vllm/model_executor/layers/fused_moe/cutlass_moe.py,vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,38,39
vllm/v1/attention/backends/rocm_aiter_fa.py,vllm/v1/attention/backends/triton_attn.py,38,37
vllm/attention/backends/pallas.py,vllm/attention/backends/torch_sdpa.py,38,34
vllm/model_executor/layers/quantization/awq_marlin.py,vllm/model_executor/layers/quantization/quark/quark_moe.py,38,32
vllm/model_executor/layers/fused_moe/modular_kernel.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,38,32
vllm/executor/cpu_executor.py,vllm/executor/gpu_executor.py,38,29
tests/mq_llm_engine/test_error_handling.py,vllm/engine/multiprocessing/engine.py,38,24
vllm/multimodal/audio.py,vllm/multimodal/image.py,38,24
tests/v1/sample/test_rejection_sampler.py,vllm/v1/sample/rejection_sampler.py,38,24
vllm/model_executor/models/gpt2.py,vllm/model_executor/models/opt.py,38,24
vllm/assets/video.py,vllm/multimodal/video.py,38,24
vllm/model_executor/models/ernie45_vl.py,vllm/model_executor/models/siglip2navit.py,38,21
vllm/spec_decode/multi_step_worker.py,vllm/spec_decode/ngram_worker.py,38,18
vllm/v1/executor/abstract.py,vllm/v1/executor/ray_executor.py,38,18
vllm/model_executor/models/keye.py,vllm/model_executor/models/keye_vl1_5.py,38,18
vllm/core/block/block_table.py,vllm/core/block/prefix_caching_block.py,38,18
vllm/model_executor/layers/quantization/moe_wna16.py,vllm/model_executor/layers/quantization/rtn.py,38,16
vllm/core/block/common.py,vllm/core/block_manager_v2.py,38,16
vllm/engine/output_processor/interfaces.py,vllm/engine/output_processor/multi_step.py,38,16
vllm/model_executor/layers/rotary_embedding/base.py,vllm/model_executor/layers/rotary_embedding/common.py,38,16
vllm/model_executor/layers/fused_moe/fused_batched_moe.py,vllm/model_executor/layers/fused_moe/prepare_finalize.py,38,16
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,38,16
cacheflow/models/input_metadata.py,cacheflow/worker/worker.py,38,16
docker/Dockerfile.xpu,requirements/xpu.txt,38,16
vllm/v1/worker/gpu/attn_utils.py,vllm/v1/worker/gpu/cudagraph_utils.py,38,16
vllm/model_executor/layers/mamba/mamba_mixer.py,vllm/v1/attention/backends/mamba1_attn.py,38,13
docs/source/dev/offline_inference/llm_inputs.rst,vllm/engine/multiprocessing/__init__.py,38,13
tests/models/language/pooling/embed_utils.py,tests/models/language/pooling/mteb_utils.py,38,13
vllm/spec_decode/interfaces.py,vllm/spec_decode/ngram_worker.py,38,13
vllm/core/block/common.py,vllm/core/interfaces.py,38,13
tests/v1/attention/test_sparse_mla_backends.py,vllm/v1/attention/backends/mla/flashmla_sparse.py,38,13
vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py,vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py,38,13
vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py,vllm/model_executor/layers/quantization/experts_int8.py,38,13
tests/compile/test_sequence_parallelism.py,vllm/compilation/sequence_parallelism.py,38,13
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py,38,13
tests/spec_decode/utils.py,vllm/spec_decode/interfaces.py,38,13
docs/source/dev/multimodal/multimodal_index.rst,tests/mq_llm_engine/test_error_handling.py,38,13
vllm/model_executor/models/blip.py,vllm/model_executor/models/idefics2_vision_model.py,38,13
vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py,vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py,38,13
vllm/engine/multiprocessing/client.py,vllm/engine/protocol.py,37,48
vllm/worker/cpu_model_runner.py,vllm/worker/xpu_model_runner.py,37,41
vllm/model_executor/layers/pooler.py,vllm/model_executor/models/bert.py,37,41
vllm/model_executor/models/ernie45_vl.py,vllm/model_executor/models/glm4_1v.py,37,40
vllm/spec_decode/multi_step_worker.py,vllm/spec_decode/spec_decode_worker.py,37,40
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,37,38
.buildkite/run-cpu-test.sh,Dockerfile.cpu,37,35
vllm/lora/utils.py,vllm/lora/worker_manager.py,37,32
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,37,29
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,37,29
vllm/v1/worker/gpu/model_runner.py,vllm/v1/worker/gpu/states.py,37,29
vllm/attention/backends/ipex_attn.py,vllm/attention/backends/xformers.py,37,29
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/gpt_neox.py,37,27
vllm/model_executor/models/aquila.py,vllm/model_executor/models/qwen.py,37,27
vllm/model_executor/models/internlm.py,vllm/model_executor/models/qwen.py,37,27
vllm/worker/neuron_model_runner.py,vllm/worker/xpu_model_runner.py,37,27
vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py,vllm/v1/core/sched/output.py,37,24
vllm/model_executor/layers/quantization/gguf.py,vllm/model_executor/layers/quantization/moe_wna16.py,37,24
tests/lora/test_lora_manager.py,vllm/lora/worker_manager.py,37,24
vllm/model_executor/models/keye.py,vllm/model_executor/models/siglip2navit.py,37,22
vllm/model_executor/models/bloom.py,vllm/model_executor/models/opt.py,37,22
vllm/v1/structured_output/backend_guidance.py,vllm/v1/structured_output/backend_xgrammar.py,37,22
vllm/model_executor/models/gpt_neox.py,vllm/model_executor/models/opt.py,37,22
tests/kernels/test_prefix_prefill.py,vllm/attention/ops/prefix_prefill.py,37,22
tests/entrypoints/openai/test_video.py,tests/entrypoints/openai/test_vision.py,37,22
vllm/attention/backends/mla/common.py,vllm/attention/backends/rocm_aiter_mla.py,37,22
vllm/v1/worker/gpu/cudagraph_utils.py,vllm/v1/worker/gpu/spec_decode/eagle.py,37,19
.github/workflows/publish.yml,.github/workflows/yapf.yml,37,19
csrc/cpu/quant.cpp,csrc/cpu/torch_bindings.cpp,37,19
vllm/model_executor/model_loader/bitsandbytes_loader.py,vllm/model_executor/model_loader/runai_streamer_loader.py,37,16
csrc/activation_kernels.cu,tests/kernels/test_activation.py,37,16
vllm/entrypoints/openai/serving_classification.py,vllm/entrypoints/openai/serving_pooling.py,37,16
tests/lora/test_fused_moe_lora_kernel.py,vllm/lora/punica_wrapper/punica_gpu.py,37,16
vllm/model_executor/models/dots_ocr.py,vllm/model_executor/models/paddleocr_vl.py,37,16
vllm/model_executor/model_loader/default_loader.py,vllm/model_executor/model_loader/sharded_state_loader.py,37,16
tests/compile/test_functionalization.py,vllm/compilation/fusion.py,37,16
tests/compile/test_pass_manager.py,vllm/compilation/inductor_pass.py,37,14
docs/models/generative_models.md,docs/models/pooling_models.md,37,14
benchmarks/kernels/benchmark_rope.py,tests/kernels/test_pos_encoding.py,37,14
vllm/core/block_manager_v1.py,vllm/core/embedding_model_block_manager.py,37,14
csrc/mamba/mamba_ssm/selective_scan_fwd.cu,vllm/model_executor/layers/mamba/ops/mamba_ssm.py,37,14
tests/models/language/pooling/mteb_utils.py,tests/models/language/pooling/test_qwen3_reranker.py,37,14
vllm/core/block_manager_v2.py,vllm/core/embedding_model_block_manager.py,37,14
tests/models/test_big_models.py,tests/models/test_models.py,37,14
vllm/config.py,vllm/engine/arg_utils.py,36,605
tests/v1/core/test_scheduler.py,vllm/v1/core/sched/scheduler.py,36,119
vllm/attention/backends/abstract.py,vllm/attention/backends/flash_attn.py,36,63
vllm/attention/backends/flash_attn.py,vllm/attention/backends/torch_sdpa.py,36,56
tests/multimodal/test_utils.py,vllm/multimodal/utils.py,36,50
vllm/worker/cpu_model_runner.py,vllm/worker/cpu_worker.py,36,46
tests/v1/worker/test_gpu_input_batch.py,tests/v1/worker/test_gpu_model_runner.py,36,42
vllm/executor/executor_base.py,vllm/executor/gpu_executor.py,36,38
vllm/spec_decode/spec_decode_worker.py,vllm/spec_decode/top1_proposer.py,36,36
vllm/engine/multiprocessing/__init__.py,vllm/engine/protocol.py,36,36
vllm/multimodal/base.py,vllm/multimodal/image.py,36,33
vllm/lora/fully_sharded_layers.py,vllm/lora/layers.py,36,33
vllm/model_executor/layers/fused_moe/cutlass_moe.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,36,31
vllm/model_executor/layers/mamba/mamba_mixer2.py,vllm/model_executor/models/bamba.py,36,30
vllm/model_executor/layers/mamba/mamba_mixer2.py,vllm/model_executor/models/mamba2.py,36,28
tests/entrypoints/openai/test_chat.py,tests/entrypoints/openai/test_completion.py,36,28
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/torch_sdpa.py,36,28
tests/kernels/test_cache.py,tests/kernels/test_pos_encoding.py,36,25
vllm/compilation/pass_manager.py,vllm/compilation/vllm_inductor_pass.py,36,22
vllm/v1/structured_output/__init__.py,vllm/v1/structured_output/request.py,36,22
vllm/model_executor/models/blip.py,vllm/model_executor/models/clip.py,36,22
vllm/model_executor/models/gpt2.py,vllm/model_executor/models/gpt_j.py,36,22
vllm/model_executor/layers/fused_moe/fused_batched_moe.py,vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,36,19
vllm/compilation/fusion.py,vllm/compilation/inductor_pass.py,36,19
tests/spec_decode/e2e/test_mlp_correctness.py,vllm/spec_decode/batch_expansion.py,36,17
tests/spec_decode/utils.py,vllm/spec_decode/batch_expansion.py,36,17
cacheflow/sampling_params.py,cacheflow/sequence.py,36,17
tests/v1/attention/test_attention_backends.py,tests/v1/attention/test_mla_backends.py,36,17
tests/compile/test_fusion.py,tests/compile/test_sequence_parallelism.py,36,17
vllm/attention/backends/hpu_attn.py,vllm/attention/backends/ipex_attn.py,36,17
vllm/platforms/neuron.py,vllm/platforms/openvino.py,36,17
tests/spec_decode/test_spec_decode_worker.py,vllm/spec_decode/util.py,36,17
vllm/v1/engine/async_llm.py,vllm/v1/engine/core_client.py,35,110
tests/entrypoints/test_chat_utils.py,vllm/entrypoints/chat_utils.py,35,86
vllm/model_executor/models/blip2.py,vllm/model_executor/models/phi3v.py,35,53
tests/v1/core/test_scheduler.py,tests/v1/kv_connector/unit/utils.py,35,51
vllm/model_executor/models/blip2.py,vllm/model_executor/models/ultravox.py,35,45
vllm/attention/backends/abstract.py,vllm/attention/backends/torch_sdpa.py,35,45
vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,35,40
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/cutlass_moe.py,35,37
vllm/worker/cpu_model_runner.py,vllm/worker/neuron_model_runner.py,35,37
vllm/v1/core/single_type_kv_cache_manager.py,vllm/v1/kv_cache_interface.py,35,29
cmake/cpu_extension.cmake,csrc/cpu/cpu_types_x86.hpp,35,29
tests/model_executor/test_enabled_custom_ops.py,vllm/model_executor/custom_op.py,35,29
tests/models/language/generation/test_hybrid.py,vllm/model_executor/models/granitemoehybrid.py,35,23
vllm/distributed/device_communicators/all2all.py,vllm/distributed/device_communicators/cuda_communicator.py,35,23
tests/entrypoints/openai/test_vision.py,tests/entrypoints/openai/test_vision_embedding.py,35,23
docker/Dockerfile.cpu,requirements/cpu-build.txt,35,20
vllm/model_executor/layers/mamba/mamba_mixer.py,vllm/model_executor/models/mamba.py,35,20
Dockerfile.cpu,docs/source/getting_started/cpu-installation.rst,35,20
csrc/cpu/cpu_types_x86.hpp,csrc/cpu/torch_bindings.cpp,35,20
tests/v1/attention/test_attention_backends.py,tests/v1/attention/utils.py,35,20
csrc/quantization/gguf/gguf_kernel.cu,vllm/model_executor/layers/quantization/gguf.py,35,20
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,35,17
vllm/model_executor/models/aquila.py,vllm/model_executor/models/falcon.py,35,17
vllm/model_executor/layers/quantization/awq.py,vllm/model_executor/layers/quantization/gptq.py,35,17
vllm/model_executor/models/idefics2_vision_model.py,vllm/model_executor/models/intern_vit.py,35,17
vllm/model_executor/layers/quantization/quark/quark_moe.py,vllm/model_executor/layers/quantization/rtn.py,35,17
vllm/model_executor/models/aquila.py,vllm/model_executor/models/bloom.py,35,17
tests/models/language/pooling/test_embedding.py,tests/models/language/pooling/test_gte.py,35,14
tests/core/block/e2e/test_correctness.py,vllm/core/block/block_table.py,35,14
tests/spec_decode/test_multi_step_worker.py,vllm/spec_decode/ngram_worker.py,35,14
tests/tensorizer_loader/conftest.py,tests/tensorizer_loader/test_tensorizer.py,35,14
vllm/spec_decode/multi_step_worker.py,vllm/spec_decode/proposer_worker_base.py,35,14
tests/spec_decode/test_multi_step_worker.py,vllm/spec_decode/top1_proposer.py,35,14
tests/v1/attention/utils.py,tests/v1/spec_decode/test_tree_attention.py,35,14
tests/entrypoints/llm/test_guided_generate.py,vllm/model_executor/guided_decoding/guidance_decoding.py,35,14
docs/configuration/conserving_memory.md,docs/configuration/optimization.md,35,14
tests/compile/test_functionalization.py,tests/compile/test_silu_mul_quant_fusion.py,35,14
tests/compile/test_fusion_attn.py,vllm/compilation/fusion_attn.py,35,14
vllm/model_executor/models/minicpm.py,vllm/model_executor/models/minicpm3.py,35,14
docs/source/models/supported_models.rst,vllm/model_executor/models/__init__.py,34,123
tests/v1/spec_decode/test_eagle.py,vllm/v1/spec_decode/eagle.py,34,65
vllm/lora/models.py,vllm/lora/utils.py,34,49
vllm/platforms/hpu.py,vllm/platforms/xpu.py,34,47
vllm/attention/backends/abstract.py,vllm/attention/backends/xformers.py,34,47
tests/v1/worker/test_gpu_model_runner.py,vllm/v1/core/sched/output.py,34,43
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/rocm_flash_attn.py,34,41
vllm/spec_decode/interfaces.py,vllm/spec_decode/spec_decode_worker.py,34,35
vllm/model_executor/models/fuyu.py,vllm/model_executor/models/qwen2_audio.py,34,35
vllm/model_executor/models/blip2.py,vllm/model_executor/models/llava_next_video.py,34,32
csrc/moe/torch_bindings.cpp,vllm/model_executor/layers/fused_moe/fused_marlin_moe.py,34,32
vllm/model_executor/models/fuyu.py,vllm/model_executor/models/llava_next_video.py,34,32
docker/Dockerfile.cpu,requirements/cpu.txt,34,29
vllm/v1/core/block_pool.py,vllm/v1/core/single_type_kv_cache_manager.py,34,29
tests/kernels/test_marlin_gemm.py,vllm/model_executor/layers/quantization/utils/marlin_utils.py,34,26
vllm/model_executor/models/blip.py,vllm/model_executor/models/siglip.py,34,26
tests/compile/test_fusion.py,vllm/compilation/pass_manager.py,34,26
tests/v1/sample/test_rejection_sampler.py,vllm/v1/sample/sampler.py,34,26
tests/kernels/test_attention.py,tests/kernels/test_pos_encoding.py,34,26
tests/core/test_scheduler.py,tests/core/utils.py,34,24
vllm/v1/core/block_pool.py,vllm/v1/core/kv_cache_coordinator.py,34,24
vllm/model_executor/layers/quantization/bitsandbytes.py,vllm/model_executor/layers/quantization/experts_int8.py,34,23
csrc/moe/marlin_moe_ops.cu,csrc/moe/torch_bindings.cpp,34,23
tests/kernels/test_activation.py,tests/kernels/test_cache.py,34,23
tests/mq_llm_engine/utils.py,vllm/engine/multiprocessing/engine.py,34,21
csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu,csrc/quantization/cutlass_w8a8/scaled_mm_entry.cu,34,21
vllm/model_executor/models/keye.py,vllm/model_executor/models/paddleocr_vl.py,34,21
tests/spec_decode/e2e/conftest.py,vllm/spec_decode/batch_expansion.py,34,21
vllm/v1/attention/backends/rocm_aiter_fa.py,vllm/v1/attention/backends/xformers.py,34,21
tests/core/block/test_prefix_caching_block.py,vllm/core/block_manager_v2.py,34,18
vllm/model_executor/models/gpt_neox.py,vllm/model_executor/models/internlm.py,34,18
vllm/model_executor/models/falcon.py,vllm/model_executor/models/internlm.py,34,18
tests/models/test_llava.py,tests/models/test_phi3v.py,34,18
.github/workflows/clang-format.yml,.github/workflows/publish.yml,34,18
tests/core/test_block_manager.py,vllm/core/block_manager_v1.py,34,18
vllm/compilation/fusion.py,vllm/compilation/sequence_parallelism.py,34,18
docs/source/dev/offline_inference/llm_inputs.rst,vllm/inputs/data.py,34,18
vllm/model_executor/models/gpt_j.py,vllm/model_executor/models/internlm.py,34,18
tests/distributed/test_comm_ops.py,vllm/test_utils.py,34,15
tests/entrypoints/openai/test_lora_resolvers.py,vllm/entrypoints/openai/serving_models.py,34,15
vllm/model_executor/models/mamba.py,vllm/model_executor/models/mamba_cache.py,34,15
vllm/v1/attention/backends/mla/flashmla_sparse.py,vllm/v1/attention/backends/mla/indexer.py,34,15
csrc/mamba/causal_conv1d/causal_conv1d.cu,vllm/model_executor/layers/mamba/ops/causal_conv1d.py,34,15
vllm/model_executor/models/dots1.py,vllm/model_executor/models/glm4_moe.py,34,15
vllm/compilation/sequence_parallelism.py,vllm/compilation/vllm_inductor_pass.py,34,15
tests/core/block/test_block_manager_v2.py,vllm/core/block_manager_v2.py,34,15
tests/kernels/attention/test_attention_selector.py,tests/kernels/attention/test_rocm_attention_selector.py,34,15
tests/models/test_llava_next.py,tests/models/test_phi3v.py,34,15
tests/compile/test_fusion.py,vllm/model_executor/layers/quantization/ptpc_fp8.py,34,15
CMakeLists.txt,vllm/_custom_ops.py,33,201
CMakeLists.txt,csrc/torch_bindings.cpp,33,161
vllm/platforms/cpu.py,vllm/platforms/tpu.py,33,78
vllm/platforms/cpu.py,vllm/platforms/xpu.py,33,77
vllm/inputs/registry.py,vllm/multimodal/registry.py,33,54
tests/v1/core/test_scheduler.py,tests/v1/core/utils.py,33,45
vllm/model_executor/layers/quantization/experts_int8.py,vllm/model_executor/layers/quantization/gptq_marlin.py,33,39
vllm/spec_decode/spec_decode_worker.py,vllm/spec_decode/util.py,33,36
vllm/model_executor/models/chameleon.py,vllm/model_executor/models/qwen2_audio.py,33,33
vllm/model_executor/models/gpt_neox.py,vllm/model_executor/models/qwen.py,33,30
Dockerfile.rocm,docs/source/getting_started/amd-installation.rst,33,30
vllm/v1/attention/backends/mla/flashattn_mla.py,vllm/v1/attention/backends/mla/rocm_aiter_mla.py,33,30
vllm/model_executor/layers/mamba/mamba_mixer2.py,vllm/model_executor/models/zamba2.py,33,30
tests/v1/engine/test_output_processor.py,vllm/v1/engine/output_processor.py,33,30
vllm/model_executor/models/falcon.py,vllm/model_executor/models/qwen.py,33,30
tests/kernels/quantization/test_block_fp8.py,vllm/utils/deep_gemm.py,33,30
vllm/model_executor/models/ernie45_vl.py,vllm/model_executor/models/keye.py,33,27
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/bloom.py,33,27
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/falcon.py,33,27
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/gpt_j.py,33,27
vllm/model_executor/guided_decoding/outlines_logits_processors.py,vllm/model_executor/guided_decoding/xgrammar_decoding.py,33,24
vllm/compilation/inductor_pass.py,vllm/compilation/pass_manager.py,33,24
tests/kernels/test_activation.py,tests/kernels/test_attention.py,33,24
vllm/model_executor/models/gpt_bigcode.py,vllm/model_executor/models/opt.py,33,24
.github/workflows/publish.yml,.github/workflows/ruff.yml,33,21
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py,vllm/model_executor/layers/quantization/fbgemm_fp8.py,33,21
tests/compile/test_functionalization.py,vllm/compilation/pass_manager.py,33,21
csrc/quantization/gptq_marlin/gptq_marlin.cu,tests/kernels/test_marlin_gemm.py,33,21
tests/entrypoints/openai/test_tokenization.py,vllm/entrypoints/openai/serving_tokenization.py,33,21
tests/distributed/test_pynccl.py,vllm/distributed/communication_op.py,33,18
requirements/build.txt,requirements/cuda.txt,33,18
csrc/attention/attention_kernels.cu,csrc/attention/dtype_bfloat16.cuh,33,18
cacheflow/models/opt.py,cacheflow/worker/worker.py,33,18
vllm/distributed/device_communicators/all2all.py,vllm/distributed/device_communicators/base_device_communicator.py,33,18
vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,33,18
tests/spec_decode/e2e/test_ngram_correctness.py,vllm/spec_decode/batch_expansion.py,33,15
tests/models/decoder_only/language/test_mamba.py,vllm/model_executor/models/mamba.py,33,15
tests/compile/test_functionalization.py,tests/compile/test_fusion_attn.py,33,15
vllm/model_executor/models/aquila.py,vllm/model_executor/models/mistral.py,33,15
vllm/compilation/fusion.py,vllm/compilation/matcher_utils.py,33,15
tests/kernels/quantization/test_block_fp8.py,vllm/model_executor/layers/quantization/deepgemm.py,33,15
tests/v1/executor/test_executor.py,vllm/v1/executor/abstract.py,33,15
vllm/compilation/fusion.py,vllm/compilation/fusion_attn.py,33,15
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,33,15
csrc/cache.h,tests/kernels/attention/test_cache.py,33,15
tests/mq_llm_engine/test_error_handling.py,vllm/inputs/__init__.py,33,15
vllm/model_executor/layers/mamba/ops/ssd_combined.py,vllm/model_executor/models/bamba.py,33,15
vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py,vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py,33,15
tests/spec_decode/e2e/conftest.py,tests/spec_decode/e2e/test_logprobs.py,33,15
vllm/model_executor/models/paddleocr_vl.py,vllm/model_executor/models/siglip2navit.py,33,15
csrc/cpu/attention.cpp,vllm/attention/ops/paged_attn.py,33,15
vllm/entrypoints/openai/serving_chat.py,vllm/entrypoints/openai/serving_engine.py,32,163
vllm/platforms/interface.py,vllm/platforms/xpu.py,32,95
vllm/model_executor/models/llava.py,vllm/model_executor/models/pixtral.py,32,83
vllm/attention/backends/abstract.py,vllm/attention/backends/rocm_flash_attn.py,32,59
vllm/attention/backends/flashinfer.py,vllm/attention/backends/xformers.py,32,56
vllm/model_executor/models/fuyu.py,vllm/model_executor/models/llava_next.py,32,50
tests/samplers/test_sampler.py,vllm/model_executor/layers/sampler.py,32,50
tests/entrypoints/openai/test_metrics.py,vllm/v1/metrics/loggers.py,32,50
vllm/model_executor/models/blip2.py,vllm/model_executor/models/llava_next.py,32,49
vllm/model_executor/models/chameleon.py,vllm/model_executor/models/ultravox.py,32,43
vllm/inputs/registry.py,vllm/multimodal/base.py,32,43
vllm/model_executor/models/minicpmo.py,vllm/model_executor/models/minicpmv.py,32,43
tests/v1/tpu/worker/test_tpu_model_runner.py,tests/v1/worker/test_gpu_model_runner.py,32,41
tests/v1/core/test_prefix_caching.py,vllm/v1/core/block_pool.py,32,41
vllm/v1/engine/output_processor.py,vllm/v1/metrics/stats.py,32,40
requirements-rocm.txt,requirements.txt,32,37
vllm/model_executor/models/aria.py,vllm/model_executor/models/blip2.py,32,34
vllm/worker/tpu_model_runner.py,vllm/worker/tpu_worker.py,32,34
tests/lora/test_layers.py,vllm/lora/utils.py,32,34
vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,vllm/model_executor/layers/fused_moe/modular_kernel.py,32,31
vllm/worker/enc_dec_model_runner.py,vllm/worker/xpu_model_runner.py,32,28
vllm/v1/attention/backends/cpu_attn.py,vllm/v1/attention/backends/flex_attention.py,32,28
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/opt.py,32,28
vllm/model_executor/layers/mamba/mamba_mixer2.py,vllm/model_executor/models/falcon_h1.py,32,28
vllm/model_executor/models/gemma.py,vllm/model_executor/models/gemma2.py,32,28
tests/v1/tpu/worker/test_tpu_model_runner.py,vllm/v1/core/sched/output.py,32,28
vllm/multimodal/audio.py,vllm/multimodal/video.py,32,25
csrc/cache.h,tests/kernels/test_cache.py,32,25
vllm/model_executor/models/modernbert.py,vllm/model_executor/models/roberta.py,32,25
tests/v1/worker/test_gpu_input_batch.py,vllm/v1/worker/block_table.py,32,25
requirements-build.txt,requirements-cuda.txt,32,22
vllm/model_executor/models/gpt_j.py,vllm/model_executor/models/opt.py,32,22
vllm/v1/attention/backends/rocm_aiter_fa.py,vllm/v1/attention/backends/tree_attn.py,32,22
vllm/lora/layers/column_parallel_linear.py,vllm/lora/utils.py,32,22
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,vllm/model_executor/layers/fused_moe/fused_batched_moe.py,32,19
vllm/engine/multiprocessing/__init__.py,vllm/inputs/__init__.py,32,19
tests/distributed/test_custom_all_reduce.py,tests/distributed/test_pynccl.py,32,19
docs/source/dev/offline_inference/llm_inputs.rst,docs/source/models/vlm.rst,32,19
vllm/v1/attention/backends/gdn_attn.py,vllm/v1/attention/backends/mamba_attn.py,32,19
vllm/distributed/device_communicators/pynccl.py,vllm/distributed/device_communicators/pynccl_wrapper.py,32,19
tests/multi_step/test_correctness_async_llm.py,vllm/worker/multi_step_model_runner.py,32,16
vllm/model_executor/models/aquila.py,vllm/model_executor/models/mpt.py,32,16
vllm/core/block/block_table.py,vllm/core/interfaces.py,32,16
vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py,vllm/model_executor/layers/quantization/moe_wna16.py,32,16
tests/mq_llm_engine/test_error_handling.py,vllm/inputs/parse.py,32,16
csrc/quantization/gptq_marlin/gptq_marlin.cu,csrc/quantization/marlin/dense/marlin_cuda_kernel.cu,32,16
vllm/model_executor/models/internlm.py,vllm/model_executor/models/mistral.py,32,16
vllm/model_executor/model_loader/__init__.py,vllm/model_executor/model_loader/default_loader.py,32,16
csrc/quantization/gptq_marlin/gptq_marlin.cu,csrc/quantization/gptq_marlin/gptq_marlin_repack.cu,32,16
tests/core/block/test_prefix_caching_block.py,tests/core/utils.py,32,16
docs/source/dev/multimodal/multimodal_index.rst,vllm/inputs/parse.py,32,16
vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py,vllm/model_executor/layers/quantization/experts_int8.py,32,16
cacheflow/sequence.py,cacheflow/server/llm_server.py,32,16
CMakeLists.txt,csrc/ops.h,31,160
vllm/core/scheduler.py,vllm/sequence.py,31,123
vllm/model_executor/models/__init__.py,vllm/transformers_utils/configs/__init__.py,31,88
vllm/entrypoints/openai/serving_completion.py,vllm/entrypoints/openai/serving_embedding.py,31,79
vllm/attention/backends/abstract.py,vllm/attention/backends/flashinfer.py,31,61
vllm/attention/backends/flashinfer.py,vllm/attention/backends/torch_sdpa.py,31,54
vllm/model_executor/layers/quantization/gptq_marlin.py,vllm/model_executor/layers/quantization/utils/marlin_utils.py,31,48
vllm/model_executor/models/qwen3_omni_moe_thinker.py,vllm/model_executor/models/qwen3_vl.py,31,47
vllm/platforms/hpu.py,vllm/platforms/tpu.py,31,47
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/flash_attn.py,31,45
vllm/v1/attention/backends/flex_attention.py,vllm/v1/attention/backends/triton_attn.py,31,39
tests/models/test_transformers.py,vllm/model_executor/models/transformers.py,31,39
vllm/attention/backends/pallas.py,vllm/attention/backends/xformers.py,31,35
vllm/compilation/decorators.py,vllm/compilation/wrapper.py,31,35
vllm/model_executor/models/blip2.py,vllm/model_executor/models/qwen2_audio.py,31,35
tests/models/encoder_decoder/vision_language/test_mllama.py,vllm/model_executor/models/mllama.py,31,32
tests/v1/worker/test_gpu_input_batch.py,vllm/v1/sample/sampler.py,31,32
vllm/model_executor/models/bert.py,vllm/model_executor/models/gritlm.py,31,32
csrc/activation_kernels.cu,vllm/model_executor/layers/activation.py,31,32
csrc/quantization/gptq_marlin/gptq_marlin.cu,vllm/model_executor/layers/quantization/utils/marlin_utils.py,31,29
tests/mq_llm_engine/test_error_handling.py,vllm/engine/multiprocessing/client.py,31,29
vllm/model_executor/models/baichuan.py,vllm/model_executor/models/gpt_bigcode.py,31,29
vllm/model_executor/layers/pooler.py,vllm/model_executor/models/gritlm.py,31,29
vllm/model_executor/layers/quantization/bitsandbytes.py,vllm/model_executor/layers/quantization/moe_wna16.py,31,26
tests/lora/test_layers.py,tests/lora/test_lora_manager.py,31,26
vllm/model_executor/layers/quantization/gguf.py,vllm/model_executor/layers/quantization/quark/quark_moe.py,31,26
vllm/model_executor/models/falcon.py,vllm/model_executor/models/gpt_bigcode.py,31,23
vllm/compilation/pass_manager.py,vllm/compilation/sequence_parallelism.py,31,23
tests/tool_use/utils.py,vllm/entrypoints/openai/tool_parsers/__init__.py,31,23
docs/source/dev/multimodal/multimodal_index.rst,docs/source/models/vlm.rst,31,22
vllm/model_executor/models/falcon.py,vllm/model_executor/models/gpt2.py,31,22
vllm/model_executor/models/mllama4.py,vllm/model_executor/models/step3_vl.py,31,19
tests/v1/kv_connector/unit/test_remote_prefill_lifecycle.py,tests/v1/kv_connector/unit/utils.py,31,19
tests/lora/test_lora_checkpoints.py,vllm/lora/worker_manager.py,31,19
tests/multimodal/test_video.py,vllm/multimodal/video.py,31,19
tests/v1/core/test_async_scheduler.py,tests/v1/kv_connector/unit/utils.py,31,19
tests/v1/kv_connector/unit/test_multi_connector.py,vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py,31,19
tests/model_executor/test_guided_processors.py,vllm/model_executor/guided_decoding/xgrammar_decoding.py,31,19
vllm/model_executor/models/opt.py,vllm/model_executor/models/phi.py,31,19
vllm/model_executor/models/aquila.py,vllm/model_executor/models/gpt2.py,31,19
vllm/v1/engine/coordinator.py,vllm/v1/engine/utils.py,31,19
csrc/moe/moe_align_sum_kernels.cu,csrc/moe/moe_ops.h,31,16
requirements/rocm-build.txt,requirements/xpu.txt,31,16
vllm/model_executor/model_loader/bitsandbytes_loader.py,vllm/model_executor/model_loader/sharded_state_loader.py,31,16
vllm/model_executor/model_loader/default_loader.py,vllm/model_executor/model_loader/runai_streamer_loader.py,31,16
vllm/entrypoints/openai/serving_transcription.py,vllm/entrypoints/openai/speech_to_text.py,31,16
vllm/model_executor/models/mistral3.py,vllm/model_executor/models/tarsier.py,31,16
tests/models/language/pooling/mteb_utils.py,tests/models/language/pooling/test_gte.py,31,16
vllm/model_executor/models/internlm.py,vllm/model_executor/models/mpt.py,31,16
csrc/cpu/dnnl_helper.cpp,csrc/cpu/torch_bindings.cpp,31,16
vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py,vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py,31,16
vllm/platforms/rocm.py,vllm/platforms/xpu.py,30,102
vllm/v1/attention/backends/flash_attn.py,vllm/v1/attention/backends/flashinfer.py,30,95
vllm/model_executor/models/qwen2_5_vl.py,vllm/model_executor/models/qwen3_vl.py,30,80
vllm/v1/attention/backends/flash_attn.py,vllm/v1/attention/backends/triton_attn.py,30,70
vllm/model_executor/model_loader.py,vllm/model_executor/models/__init__.py,30,69
vllm/multimodal/profiling.py,vllm/multimodal/registry.py,30,50
vllm/entrypoints/context.py,vllm/entrypoints/openai/serving_responses.py,30,49
vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py,30,49
vllm/v1/executor/abstract.py,vllm/v1/executor/multiproc_executor.py,30,47
vllm/model_executor/models/clip.py,vllm/model_executor/models/llava_next.py,30,47
tests/v1/engine/test_engine_core_client.py,vllm/v1/engine/__init__.py,30,46
tests/lora/test_layers.py,vllm/lora/layers.py,30,43
tests/v1/worker/test_gpu_model_runner.py,vllm/v1/worker/block_table.py,30,40
vllm/model_executor/models/blip2.py,vllm/model_executor/models/paligemma.py,30,39
vllm/model_executor/models/bert.py,vllm/model_executor/models/bert_with_rope.py,30,30
vllm/multimodal/image.py,vllm/multimodal/video.py,30,30
vllm/model_executor/layers/fused_moe/modular_kernel.py,vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,30,30
tests/kernels/moe/test_cutlass_moe.py,vllm/model_executor/layers/fused_moe/cutlass_moe.py,30,27
vllm/entrypoints/openai/serving_pooling.py,vllm/entrypoints/openai/serving_tokenization.py,30,27
vllm/distributed/kv_transfer/kv_connector/v1/base.py,vllm/v1/worker/kv_connector_model_runner_mixin.py,30,27
vllm/v1/attention/backends/cpu_attn.py,vllm/v1/attention/backends/rocm_aiter_fa.py,30,26
vllm/model_executor/layers/mamba/mamba_mixer2.py,vllm/model_executor/layers/mamba/ops/ssd_combined.py,30,26
vllm/model_executor/guided_decoding/__init__.py,vllm/model_executor/guided_decoding/outlines_decoding.py,30,23
vllm/model_executor/guided_decoding/__init__.py,vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py,30,20
tests/v1/kv_connector/unit/test_remote_decode_lifecycle.py,tests/v1/kv_connector/unit/utils.py,30,20
vllm/model_executor/layers/rejection_sampler.py,vllm/spec_decode/batch_expansion.py,30,20
vllm/model_executor/models/mpt.py,vllm/model_executor/models/opt.py,30,20
vllm/model_executor/models/aquila.py,vllm/model_executor/models/gpt_bigcode.py,30,20
vllm/core/block/cpu_gpu_block_allocator.py,vllm/core/block_manager_v1.py,30,20
vllm/model_executor/layers/quantization/gguf.py,vllm/model_executor/layers/quantization/rtn.py,30,20
tests/kernels/moe/test_silu_mul_fp8_quant_deep_gemm.py,vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,30,20
vllm/lora/layers/fused_moe.py,vllm/lora/punica_wrapper/punica_base.py,30,20
vllm/model_executor/model_loader/tensorizer.py,vllm/model_executor/model_loader/tensorizer_loader.py,30,20
csrc/moe/marlin_moe_ops.h,csrc/moe/torch_bindings.cpp,30,20
tests/compile/test_fusion.py,tests/compile/test_fusion_attn.py,30,20
vllm/model_executor/models/ernie45_vl.py,vllm/model_executor/models/paddleocr_vl.py,30,20
vllm/lora/layers/base.py,vllm/lora/utils.py,30,20
vllm/model_executor/models/jina_vl.py,vllm/model_executor/models/modernbert.py,30,17
tests/spec_decode/e2e/conftest.py,tests/spec_decode/e2e/test_ngram_correctness.py,30,17
Dockerfile.ppc64le,Dockerfile.tpu,30,17
tests/compile/piecewise/test_multiple_graphs.py,tests/compile/piecewise/test_toy_llama.py,30,17
docs/source/dev/multimodal/multimodal_index.rst,vllm/engine/multiprocessing/__init__.py,30,17
tests/v1/core/test_single_type_kv_cache_manager.py,vllm/v1/core/block_pool.py,30,17
csrc/quantization/gptq_marlin/gptq_marlin.cu,csrc/quantization/marlin/sparse/marlin_24_cuda_kernel.cu,30,17
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py,vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py,30,17
cacheflow/worker/worker.py,simple_server.py,30,17
tests/spec_decode/test_multi_step_worker.py,tests/spec_decode/test_spec_decode_worker.py,30,17
tests/spec_decode/test_spec_decode_worker.py,vllm/spec_decode/top1_proposer.py,30,17
vllm/attention/backends/blocksparse_attn.py,vllm/attention/backends/hpu_attn.py,30,17
vllm/entrypoints/context.py,vllm/entrypoints/openai/parser/responses_parser.py,30,17
vllm/model_executor/layers/mamba/ops/causal_conv1d.py,vllm/model_executor/layers/mamba/ops/mamba_ssm.py,30,17
vllm/compilation/fix_functionalization.py,vllm/compilation/fusion.py,30,17
vllm/model_executor/layers/mamba/mamba_mixer.py,vllm/model_executor/models/plamo2.py,30,17
vllm/v1/structured_output/backend_types.py,vllm/v1/structured_output/backend_xgrammar.py,30,17
tests/spec_decode/test_multi_step_worker.py,vllm/spec_decode/batch_expansion.py,30,17
