entity,soc
vllm/engine/arg_utils.py,12008
vllm/v1/worker/gpu_model_runner.py,11370
vllm/config.py,10289
vllm/entrypoints/llm.py,9706
vllm/model_executor/models/llama.py,9208
vllm/model_executor/models/llava.py,9123
vllm/model_executor/models/qwen2_vl.py,8792
vllm/model_executor/models/phi3v.py,8710
vllm/entrypoints/openai/api_server.py,8590
vllm/envs.py,8506
tests/conftest.py,8467
vllm/model_executor/models/minicpmv.py,8402
vllm/model_executor/models/qwen.py,8342
vllm/model_executor/models/chameleon.py,8279
vllm/model_executor/models/baichuan.py,8277
vllm/model_executor/models/qwen2.py,8239
vllm/model_executor/models/pixtral.py,8215
vllm/model_executor/models/mixtral.py,8145
vllm/model_executor/models/molmo.py,8132
vllm/model_executor/models/chatglm.py,8131
tests/models/registry.py,8103
vllm/model_executor/models/internvl.py,8072
vllm/model_executor/models/gpt_j.py,8048
vllm/model_executor/models/deepseek_v2.py,8043
vllm/sequence.py,8032
vllm/model_executor/models/gpt_neox.py,7993
vllm/_custom_ops.py,7988
vllm/model_executor/models/falcon.py,7980
vllm/model_executor/models/llava_next.py,7968
vllm/model_executor/models/internlm2.py,7955
vllm/model_executor/models/gemma.py,7897
vllm/model_executor/models/blip2.py,7866
vllm/model_executor/models/fuyu.py,7856
vllm/model_executor/models/ultravox.py,7793
vllm/model_executor/models/phi.py,7793
vllm/model_executor/models/registry.py,7761
vllm/model_executor/models/gpt2.py,7750
vllm/model_executor/models/gpt_bigcode.py,7740
vllm/model_executor/models/bloom.py,7694
vllm/model_executor/models/olmo.py,7684
vllm/model_executor/models/starcoder2.py,7671
vllm/model_executor/models/minicpm.py,7638
vllm/model_executor/models/opt.py,7615
vllm/model_executor/models/stablelm.py,7602
vllm/model_executor/models/orion.py,7588
vllm/model_executor/models/mpt.py,7554
vllm/model_executor/models/paligemma.py,7545
vllm/engine/llm_engine.py,7533
vllm/model_executor/models/qwen2_moe.py,7517
vllm/entrypoints/openai/serving_chat.py,7506
vllm/model_executor/models/dbrx.py,7498
vllm/model_executor/models/commandr.py,7496
vllm/entrypoints/openai/serving_engine.py,7493
vllm/entrypoints/openai/protocol.py,7476
vllm/model_executor/models/qwen2_audio.py,7419
vllm/model_executor/models/jamba.py,7362
vllm/model_executor/models/arctic.py,7358
vllm/model_executor/models/interfaces.py,7357
vllm/model_executor/models/llava_next_video.py,7338
vllm/model_executor/models/gemma2.py,7336
vllm/v1/engine/async_llm.py,7319
vllm/model_executor/models/jais.py,7310
vllm/model_executor/models/whisper.py,7308
vllm/model_executor/models/llava_onevision.py,7290
vllm/model_executor/models/deepseek_vl2.py,7254
vllm/model_executor/layers/fused_moe/layer.py,7240
vllm/model_executor/models/idefics3.py,7220
vllm/v1/attention/backends/flash_attn.py,7217
vllm/model_executor/models/phimoe.py,7196
vllm/model_executor/models/nemotron.py,7164
vllm/platforms/cuda.py,7145
vllm/entrypoints/openai/serving_completion.py,7142
vllm/multimodal/registry.py,7137
vllm/v1/worker/gpu_worker.py,7134
vllm/model_executor/models/deepseek.py,7126
vllm/attention/layer.py,7092
vllm/model_executor/models/solar.py,7082
vllm/model_executor/models/granite.py,7074
vllm/model_executor/models/exaone.py,7070
vllm/entrypoints/chat_utils.py,7056
vllm/model_executor/layers/quantization/fp8.py,7053
vllm/model_executor/models/granitemoe.py,7042
vllm/v1/engine/llm_engine.py,6994
vllm/model_executor/models/aria.py,6982
vllm/model_executor/models/persimmon.py,6941
vllm/model_executor/layers/fused_moe/fused_moe.py,6889
tests/utils.py,6884
vllm/platforms/interface.py,6866
vllm/multimodal/processing.py,6853
vllm/model_executor/models/olmoe.py,6808
vllm/transformers_utils/config.py,6787
vllm/v1/engine/core.py,6745
vllm/model_executor/models/utils.py,6736
vllm/v1/worker/tpu_model_runner.py,6634
vllm/platforms/rocm.py,6632
vllm/v1/engine/processor.py,6619
vllm/model_executor/models/mamba.py,6594
vllm/multimodal/inputs.py,6569
vllm/utils.py,6567
tests/models/multimodal/processing/test_common.py,6482
vllm/platforms/cpu.py,6472
vllm/model_executor/models/clip.py,6465
setup.py,6446
tests/models/utils.py,6423
vllm/model_executor/models/bert.py,6414
tests/kernels/utils.py,6403
vllm/model_executor/layers/quantization/gptq_marlin.py,6400
vllm/inputs/preprocess.py,6354
vllm/executor/executor_base.py,6348
tests/lora/test_layers.py,6320
vllm/worker/model_runner.py,6307
vllm/entrypoints/openai/run_batch.py,6306
vllm/attention/selector.py,6303
vllm/attention/backends/abstract.py,6298
vllm/model_executor/models/siglip.py,6295
vllm/model_executor/models/qwen2_5_vl.py,6295
tests/distributed/test_pipeline_parallel.py,6285
vllm/model_executor/models/olmo2.py,6254
vllm/distributed/parallel_state.py,6253
vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors_moe.py,6248
vllm/engine/protocol.py,6242
vllm/model_executor/models/qwen2_rm.py,6236
tests/multimodal/test_processing.py,6208
vllm/lora/models.py,6197
vllm/v1/worker/gpu_input_batch.py,6193
vllm/model_executor/layers/quantization/modelopt.py,6190
vllm/entrypoints/openai/serving_embedding.py,6183
tests/entrypoints/openai/test_serving_chat.py,6170
vllm/v1/core/kv_cache_utils.py,6100
vllm/transformers_utils/tokenizer.py,6092
vllm/multimodal/utils.py,6085
vllm/platforms/tpu.py,6078
vllm/outputs.py,6072
vllm/model_executor/layers/linear.py,6066
vllm/platforms/xpu.py,6061
vllm/v1/request.py,6030
tests/tokenization/test_detokenize.py,6028
tests/entrypoints/test_chat_utils.py,6003
vllm/v1/core/kv_cache_manager.py,5996
vllm/entrypoints/openai/cli_args.py,5994
vllm/sampling_params.py,5991
vllm/v1/engine/core_client.py,5990
tests/v1/core/test_kv_cache_utils.py,5987
vllm/model_executor/models/mllama4.py,5979
vllm/entrypoints/openai/serving_score.py,5955
vllm/model_executor/model_loader/tensorizer.py,5954
vllm/model_executor/layers/quantization/awq_marlin.py,5951
vllm/model_executor/models/interfaces_base.py,5908
vllm/model_executor/model_loader/weight_utils.py,5906
tests/v1/engine/test_engine_core_client.py,5902
vllm/model_executor/model_loader/utils.py,5888
vllm/model_executor/models/mistral3.py,5881
vllm/model_executor/layers/quantization/compressed_tensors/compressed_tensors.py,5875
vllm/forward_context.py,5874
vllm/v1/engine/output_processor.py,5873
vllm/v1/executor/multiproc_executor.py,5870
vllm/v1/kv_cache_interface.py,5849
tests/entrypoints/openai/test_chat.py,5843
vllm/model_executor/models/internlm2_ve.py,5842
vllm/model_executor/models/minicpm3.py,5832
vllm/entrypoints/openai/serving_tokenization.py,5817
vllm/entrypoints/openai/serving_pooling.py,5813
vllm/entrypoints/api_server.py,5813
tests/v1/core/test_prefix_caching.py,5813
vllm/v1/engine/__init__.py,5807
vllm/model_executor/layers/quantization/utils/fp8_utils.py,5798
vllm/multimodal/profiling.py,5796
vllm/logger.py,5784
tests/v1/engine/test_async_llm.py,5776
vllm/model_executor/models/minicpmo.py,5775
vllm/v1/attention/backends/mla/common.py,5774
vllm/entrypoints/openai/serving_models.py,5761
tests/compile/piecewise/test_toy_llama.py,5760
vllm/inputs/data.py,5757
vllm/engine/metrics.py,5747
vllm/lora/worker_manager.py,5736
tests/compile/test_basic_correctness.py,5732
vllm/model_executor/layers/quantization/gptq.py,5729
vllm/model_executor/models/gemma3_mm.py,5728
vllm/model_executor/layers/quantization/gguf.py,5727
vllm/model_executor/models/roberta.py,5716
vllm/entrypoints/utils.py,5716
vllm/model_executor/layers/fused_moe/__init__.py,5709
tests/engine/test_arg_utils.py,5702
vllm/model_executor/models/gritlm.py,5687
vllm/v1/outputs.py,5683
vllm/model_executor/layers/quantization/bitsandbytes.py,5682
tests/v1/worker/test_gpu_input_batch.py,5676
vllm/model_executor/models/h2ovl.py,5667
vllm/model_executor/models/adapters.py,5662
vllm/model_executor/models/qwen_vl.py,5659
vllm/model_executor/layers/quantization/utils/w8a8_utils.py,5651
tests/lora/test_llama_tp.py,5651
vllm/model_executor/layers/vocab_parallel_embedding.py,5650
vllm/model_executor/models/vision.py,5649
vllm/model_executor/layers/pooler.py,5645
vllm/model_executor/layers/layernorm.py,5641
vllm/model_executor/layers/quantization/quark/quark_moe.py,5623
vllm/attention/backends/utils.py,5622
vllm/compilation/backends.py,5618
vllm/v1/utils.py,5615
vllm/v1/spec_decode/eagle.py,5610
vllm/model_executor/models/blip.py,5608
tests/v1/engine/test_output_processor.py,5604
tests/models/multimodal/processing/test_internvl.py,5601
vllm/v1/worker/block_table.py,5597
vllm/model_executor/models/skyworkr1v.py,5586
vllm/model_executor/models/phi4mm.py,5574
vllm/v1/metrics/loggers.py,5572
vllm/model_executor/models/minimax_text_01.py,5570
vllm/entrypoints/openai/tool_parsers/abstract_tool_parser.py,5562
pyproject.toml,5559
vllm/model_executor/layers/activation.py,5552
vllm/model_executor/layers/quantization/experts_int8.py,5551
vllm/model_executor/layers/quantization/awq.py,5547
csrc/quantization/machete/generate.py,5547
vllm/multimodal/image.py,5544
vllm/model_executor/models/aya_vision.py,5542
vllm/entrypoints/openai/tool_parsers/mistral_tool_parser.py,5542
tests/quantization/test_compressed_tensors.py,5540
vllm/model_executor/layers/quantization/utils/marlin_utils.py,5539
vllm/executor/ray_distributed_executor.py,5537
vllm/v1/engine/detokenizer.py,5536
vllm/attention/ops/paged_attn.py,5535
tests/tool_use/test_jamba_tool_parser.py,5535
vllm/model_executor/models/idefics2_vision_model.py,5526
tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_gemma_embedding.py,5526
tests/kernels/quant_utils.py,5523
tests/entrypoints/openai/tool_parsers/utils.py,5521
vllm/entrypoints/openai/tool_parsers/hermes_tool_parser.py,5516
tools/profiler/visualize_layerwise_profile.py,5512
vllm/v1/executor/abstract.py,5509
vllm/entrypoints/openai/tool_parsers/granite_20b_fc_tool_parser.py,5499
vllm/model_executor/models/glm4v.py,5493
tests/samplers/test_no_bad_words.py,5491
vllm/model_executor/layers/logits_processor.py,5490
vllm/v1/metrics/stats.py,5486
vllm/model_executor/layers/quantization/moe_wna16.py,5486
vllm/entrypoints/openai/tool_parsers/internlm2_tool_parser.py,5483
.buildkite/test-pipeline.yaml,5473
vllm/model_executor/layers/quantization/utils/quant_utils.py,5472
tests/lora/utils.py,5472
vllm/v1/core/sched/scheduler.py,5466
vllm/entrypoints/openai/tool_parsers/jamba_tool_parser.py,5465
vllm/model_executor/models/qwen2_5_omni_thinker.py,5463
vllm/lora/utils.py,5441
tests/model_executor/test_enabled_custom_ops.py,5440
vllm/model_executor/layers/fused_moe/fused_marlin_moe.py,5437
tests/quantization/test_register_quantization_config.py,5437
vllm/model_executor/models/intern_vit.py,5436
vllm/model_executor/models/bamba.py,5436
vllm/model_executor/custom_op.py,5427
vllm/model_executor/models/plamo2.py,5424
tests/v1/core/test_scheduler.py,5424
tests/distributed/test_comm_ops.py,5424
vllm/multimodal/parse.py,5421
vllm/v1/attention/backends/flashinfer.py,5418
vllm/transformers_utils/processor.py,5413
tests/tool_use/utils.py,5410
vllm/platforms/__init__.py,5408
tests/compile/test_full_graph.py,5393
vllm/model_executor/models/qwen3_moe.py,5392
vllm/entrypoints/openai/tool_parsers/granite_tool_parser.py,5387
vllm/model_executor/utils.py,5377
vllm/model_executor/models/nvlm_d.py,5375
vllm/compilation/decorators.py,5375
vllm/model_executor/layers/quantization/base_config.py,5373
vllm/v1/sample/metadata.py,5372
vllm/model_executor/layers/mamba/mamba_mixer.py,5371
tests/lora/test_qwen2vl.py,5362
vllm/tracing.py,5360
vllm/executor/ray_utils.py,5358
vllm/model_executor/layers/quantization/ipex_quant.py,5351
vllm/entrypoints/openai/tool_parsers/llama_tool_parser.py,5351
vllm/model_executor/models/granite_speech.py,5346
vllm/pooling_params.py,5344
vllm/connections.py,5341
vllm/_ipex_ops.py,5336
vllm/logits_process.py,5333
vllm/entrypoints/openai/tool_parsers/pythonic_tool_parser.py,5328
vllm/distributed/device_communicators/custom_all_reduce.py,5328
vllm/multimodal/video.py,5325
vllm/distributed/utils.py,5323
vllm/engine/async_llm_engine.py,5318
vllm/v1/sample/ops/topk_topp_sampler.py,5317
csrc/cutlass_extensions/vllm_cutlass_library_extension.py,5314
vllm/model_executor/models/kimi_vl.py,5308
vllm/entrypoints/logger.py,5297
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_wNa16.py,5292
vllm/usage/usage_lib.py,5281
vllm/model_executor/layers/quantization/fbgemm_fp8.py,5277
vllm/model_executor/models/ovis.py,5276
vllm/model_executor/models/nemotron_nas.py,5273
vllm/worker/worker.py,5270
vllm/entrypoints/openai/logits_processors.py,5264
vllm/model_executor/layers/utils.py,5261
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_fp8.py,5260
vllm/transformers_utils/tokenizers/mistral.py,5257
tests/lora/conftest.py,5256
vllm/distributed/kv_transfer/kv_connector/factory.py,5252
vllm/inputs/parse.py,5247
tests/tool_use/test_parallel_tool_calls.py,5245
vllm/v1/serial_utils.py,5242
vllm/model_executor/models/gemma3.py,5241
vllm/beam_search.py,5235
tests/tool_use/test_tool_calls.py,5231
vllm/model_executor/model_loader/__init__.py,5230
vllm/multimodal/base.py,5226
vllm/multimodal/audio.py,5225
tests/lora/test_lora_manager.py,5221
vllm/model_executor/models/qwen3.py,5220
vllm/compilation/wrapper.py,5219
vllm/distributed/device_communicators/pynccl.py,5215
tests/v1/engine/test_engine_core.py,5210
tests/vllm_test_utils/vllm_test_utils/blame.py,5206
vllm/model_executor/models/__init__.py,5201
vllm/model_executor/layers/quantization/compressed_tensors/utils.py,5201
vllm/v1/worker/utils.py,5196
vllm/plugins/__init__.py,5195
tests/vllm_test_utils/vllm_test_utils/monitor.py,5194
vllm/model_executor/layers/quantization/utils/marlin_utils_fp8.py,5193
vllm/model_executor/models/zamba2.py,5191
tests/quantization/test_quark.py,5187
vllm/model_executor/layers/quantization/gptq_marlin_24.py,5182
vllm/compilation/inductor_pass.py,5181
vllm/model_executor/models/glm4.py,5176
vllm/model_executor/layers/quantization/quark/quark.py,5172
vllm/v1/sample/sampler.py,5168
vllm/model_executor/layers/quantization/tpu_int8.py,5156
vllm/model_executor/models/modernbert.py,5155
vllm/model_executor/layers/quantization/hqq_marlin.py,5152
vllm/model_executor/layers/quantization/deepspeedfp.py,5151
vllm/executor/uniproc_executor.py,5145
tests/test_config.py,5143
vllm/lora/request.py,5138
vllm/lora/punica_wrapper/punica_gpu.py,5130
tests/lora/test_utils.py,5130
vllm/model_executor/layers/quantization/kernels/scaled_mm/__init__.py,5129
vllm/model_executor/models/mamba2.py,5124
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_int8.py,5112
vllm/model_executor/layers/resampler.py,5111
vllm/distributed/device_communicators/shm_broadcast.py,5111
tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_llava.py,5111
vllm/distributed/communication_op.py,5110
vllm/scalar_type.py,5109
vllm/compilation/vllm_inductor_pass.py,5107
vllm/model_executor/layers/quantization/utils/marlin_utils_test.py,5106
vllm/model_executor/layers/quantization/quark/utils.py,5105
vllm/model_executor/layers/quantization/kernels/scaled_mm/cutlass.py,5102
vllm/assets/video.py,5100
vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_fp8.py,5097
vllm/distributed/device_communicators/pynccl_wrapper.py,5097
vllm/model_executor/layers/quantization/kernels/scaled_mm/ScaledMMLinearKernel.py,5095
vllm/model_executor/layers/quantization/kernels/mixed_precision/marlin.py,5090
vllm/transformers_utils/detokenizer_utils.py,5083
vllm/model_executor/layers/mamba/ops/causal_conv1d.py,5079
vllm/lora/punica_wrapper/punica_base.py,5079
vllm/model_executor/models/grok1.py,5073
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_24.py,5071
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_24.py,5069
vllm/v1/worker/tpu_worker.py,5064
vllm/model_executor/parameter.py,5061
vllm/model_executor/layers/quantization/kernels/mixed_precision/__init__.py,5058
vllm/lora/peft_helper.py,5058
vllm/model_executor/layers/quantization/kernels/scaled_mm/xla.py,5054
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a16_fp8.py,5048
vllm/model_executor/layers/quantization/kernels/mixed_precision/MPLinearKernel.py,5044
tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/my_opt.py,5043
vllm/model_executor/layers/quantization/compressed_tensors/triton_scaled_mm.py,5041
vllm/entrypoints/launcher.py,5041
vllm/model_executor/layers/quantization/quark/schemes/quark_w8a8_int8.py,5040
vllm/transformers_utils/configs/eagle.py,5038
vllm/model_executor/models/granitemoehybrid.py,5036
tests/compile/backend.py,5032
vllm/transformers_utils/s3_utils.py,5031
vllm/model_executor/models/module_mapping.py,5028
vllm/model_executor/layers/quantization/kernels/scaled_mm/triton.py,5028
vllm/v1/attention/backends/mla/flashmla.py,5025
vllm/model_executor/layers/quantization/schema.py,5018
vllm/compilation/fix_functionalization.py,5017
vllm/distributed/kv_transfer/kv_pipe/pynccl_pipe.py,5015
vllm/model_executor/models/transformers.py,5014
vllm/compilation/fx_utils.py,5014
vllm/distributed/device_communicators/tpu_communicator.py,5010
vllm/model_executor/layers/quantization/utils/machete_utils.py,5006
vllm/lora/punica_wrapper/utils.py,5004
vllm/distributed/kv_transfer/kv_pipe/mooncake_pipe.py,5001
vllm/multimodal/hasher.py,4996
tests/distributed/test_pp_cudagraph.py,4996
vllm/model_executor/layers/quantization/kernels/mixed_precision/exllama.py,4993
vllm/model_executor/layers/quantization/kernels/mixed_precision/machete.py,4991
vllm/transformers_utils/configs/ultravox.py,4984
tests/models/test_initialization.py,4980
vllm/transformers_utils/utils.py,4978
tests/compile/test_wrapper.py,4978
vllm/device_allocator/cumem.py,4976
vllm/v1/attention/backends/utils.py,4971
vllm/multimodal/__init__.py,4970
vllm/distributed/kv_transfer/kv_lookup_buffer/base.py,4962
vllm/distributed/kv_transfer/kv_lookup_buffer/simple_buffer.py,4961
vllm/lora/punica_wrapper/punica_cpu.py,4953
vllm/assets/base.py,4948
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_scheme.py,4946
vllm/distributed/device_communicators/xpu_communicator.py,4946
vllm/model_executor/models/falcon_h1.py,4943
vllm/model_executor/models/deepseek_mtp.py,4943
vllm/model_executor/layers/quantization/__init__.py,4939
vllm/model_executor/models/bert_with_rope.py,4937
vllm/distributed/kv_transfer/kv_pipe/base.py,4936
vllm/distributed/device_communicators/cuda_wrapper.py,4929
vllm/transformers_utils/configs/mlp_speculator.py,4928
vllm/profiler/layerwise_profile.py,4925
vllm/model_executor/models/minimax_vl_01.py,4923
vllm/model_executor/layers/quantization/quark/schemes/quark_scheme.py,4923
vllm/model_executor/layers/quantization/utils/layer_utils.py,4918
tests/entrypoints/openai/test_async_tokenization.py,4914
vllm/model_executor/models/granitemoeshared.py,4906
vllm/profiler/utils.py,4901
vllm/transformers_utils/configs/medusa.py,4900
tests/entrypoints/openai/test_vision.py,4868
vllm/transformers_utils/configs/__init__.py,4843
vllm/v1/attention/backends/triton_attn.py,4841
vllm/model_executor/layers/fused_moe/modular_kernel.py,4832
tests/v1/spec_decode/test_eagle.py,4830
vllm/model_executor/layers/mamba/mamba_mixer2.py,4823
tests/test_inputs.py,4814
tests/lora/test_worker.py,4799
vllm/v1/attention/backends/mla/rocm_aiter_mla.py,4786
vllm/model_executor/models/llama4.py,4778
vllm/distributed/kv_transfer/kv_connector/v1/nixl_connector.py,4759
vllm/model_executor/models/medusa.py,4744
vllm/inputs/__init__.py,4731
vllm/v1/attention/backends/pallas.py,4727
vllm/v1/attention/backends/mla/triton_mla.py,4695
vllm/model_executor/models/mlp_speculator.py,4689
tests/kernels/moe/test_moe.py,4689
vllm/model_executor/models/mimo_mtp.py,4678
tests/entrypoints/openai/test_chat_template.py,4662
vllm/model_executor/models/llama_eagle3.py,4657
tests/v1/kv_connector/unit/utils.py,4654
benchmarks/kernels/benchmark_paged_attention.py,4643
vllm/model_executor/layers/fused_moe/deep_gemm_moe.py,4639
tests/basic_correctness/test_basic_correctness.py,4637
vllm/entrypoints/score_utils.py,4631
tests/multimodal/test_utils.py,4627
vllm/model_executor/layers/fused_moe/utils.py,4625
tests/compile/test_functionalization.py,4617
vllm/model_executor/models/mimo.py,4615
vllm/model_executor/layers/fused_moe/cutlass_moe.py,4602
tests/models/multimodal/processing/test_h2ovl.py,4590
tests/lora/test_quant_model.py,4589
tests/kernels/moe/test_pplx_moe.py,4578
vllm/v1/structured_output/__init__.py,4572
tests/entrypoints/openai/tool_parsers/test_pythonic_tool_parser.py,4571
vllm/v1/core/encoder_cache_manager.py,4567
tools/profiler/print_layerwise_table.py,4564
tests/entrypoints/openai/test_serving_models.py,4564
tests/compile/test_fusion.py,4551
tests/entrypoints/openai/test_audio.py,4538
tests/test_logger.py,4536
tests/quantization/test_configs.py,4533
vllm/v1/sample/rejection_sampler.py,4526
examples/offline_inference/vision_language.py,4525
tests/entrypoints/openai/test_video.py,4524
tests/v1/sample/test_sampler.py,4522
tests/quantization/test_fp8.py,4516
tests/distributed/test_pynccl.py,4515
vllm/entrypoints/cli/serve.py,4506
tests/entrypoints/llm/test_generate.py,4504
tests/model_executor/test_model_load_with_params.py,4498
tests/v1/worker/test_gpu_model_runner.py,4492
tests/v1/engine/test_llm_engine.py,4487
tests/lora/test_mixtral.py,4484
vllm/model_executor/models/minicpm_eagle.py,4483
tests/models/test_registry.py,4473
tests/lora/test_lora_checkpoints.py,4472
vllm/__init__.py,4469
vllm/model_executor/__init__.py,4467
vllm/model_executor/layers/fused_moe/fused_batched_moe.py,4448
examples/offline_inference/vision_language_multi_image.py,4444
vllm/model_executor/layers/fused_moe/rocm_aiter_fused_moe.py,4443
vllm/model_executor/layers/fused_moe/triton_deep_gemm_moe.py,4442
tests/entrypoints/openai/test_lora_resolvers.py,4442
vllm/distributed/kv_transfer/kv_connector/v1/base.py,4439
tests/models/multimodal/processing/test_qwen2_vl.py,4439
vllm/v1/engine/logprobs.py,4438
tests/lora/test_chatglm3_tp.py,4438
vllm/reasoning/abs_reasoning_parsers.py,4435
vllm/model_executor/layers/fused_moe/pplx_prepare_finalize.py,4434
tests/models/test_transformers.py,4432
vllm/core/scheduler.py,4431
vllm/v1/core/block_pool.py,4430
vllm/attention/__init__.py,4428
tests/compile/piecewise/test_simple.py,4428
vllm/v1/sample/ops/penalties.py,4418
tests/test_sequence.py,4418
tests/kernels/moe/test_cutlass_moe.py,4415
tests/v1/entrypoints/openai/test_completion.py,4414
vllm/entrypoints/openai/serving_transcription.py,4413
tests/entrypoints/llm/test_chat.py,4413
tests/v1/sample/utils.py,4409
tests/distributed/test_expert_parallel.py,4405
vllm/model_executor/models/mixtral_quant.py,4383
tests/lora/test_lora_huggingface.py,4383
vllm/benchmarks/datasets.py,4382
tests/models/multimodal/processing/test_llava_onevision.py,4380
tests/models/multimodal/processing/test_llava_next.py,4380
tests/entrypoints/openai/test_basic.py,4376
vllm/model_executor/models/llama_eagle.py,4372
vllm/model_executor/model_loader/bitsandbytes_loader.py,4370
benchmarks/benchmark_serving_structured_output.py,4368
tests/models/multimodal/processing/test_phi3v.py,4367
tests/v1/entrypoints/llm/test_struct_output_generate.py,4365
vllm/v1/worker/lora_model_runner_mixin.py,4362
vllm/distributed/kv_transfer/kv_connector/utils.py,4362
tests/tokenization/test_tokenizer_registry.py,4361
tests/entrypoints/openai/test_root_path.py,4355
vllm/entrypoints/cli/openai.py,4348
vllm/compilation/compiler_interface.py,4348
tests/models/multimodal/processing/test_idefics3.py,4340
tests/lora/test_minicpmv_tp.py,4337
tests/distributed/test_sequence_parallel.py,4334
tests/distributed/test_custom_all_reduce.py,4330
vllm/model_executor/models/moonvit.py,4327
vllm/model_executor/models/glm4_1v.py,4325
tests/distributed/test_shm_broadcast.py,4324
vllm/compilation/fusion.py,4321
tests/v1/sample/test_rejection_sampler.py,4315
tests/v1/kv_connector/unit/test_nixl_connector.py,4311
tests/plugins_tests/test_platform_plugins.py,4311
tests/models/multimodal/generation/vlm_utils/model_utils.py,4310
tests/v1/engine/utils.py,4308
vllm/entrypoints/openai/tool_parsers/utils.py,4307
benchmarks/kernels/benchmark_rope.py,4304
tests/kv_transfer/test_send_recv.py,4303
tests/models/test_oot_registration.py,4301
tests/tool_use/test_chat_completions.py,4297
tests/basic_correctness/test_cumem.py,4297
vllm/v1/core/sched/output.py,4294
vllm/entrypoints/openai/serving_classification.py,4294
tests/kernels/moe/test_batched_moe.py,4293
vllm/transformers_utils/configs/nemotron.py,4284
vllm/config/model.py,4284
tests/v1/engine/test_engine_args.py,4278
tests/models/language/pooling/test_gritlm.py,4276
vllm/v1/structured_output/backend_xgrammar.py,4274
tests/models/language/pooling/test_embedding.py,4273
tests/kernels/attention/test_attention.py,4273
vllm/attention/ops/prefix_prefill.py,4266
tests/models/multimodal/generation/vlm_utils/types.py,4263
vllm/distributed/kv_transfer/kv_connector/v1/multi_connector.py,4261
tests/compile/test_pass_manager.py,4261
vllm/model_executor/models/qwen3_vl.py,4259
vllm/compilation/collective_fusion.py,4258
tests/samplers/test_beam_search.py,4257
vllm/model_executor/layers/quantization/utils/mxfp4_utils.py,4255
tests/distributed/test_utils.py,4253
vllm/model_executor/layers/fused_moe/prepare_finalize.py,4241
tests/quantization/test_lm_head.py,4241
vllm/v1/engine/parallel_sampling.py,4237
vllm/engine/metrics_types.py,4231
tools/report_build_time_ninja.py,4229
tests/models/multimodal/generation/vlm_utils/core.py,4226
tests/kernels/core/test_pos_encoding.py,4222
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_connector.py,4220
tests/entrypoints/openai/test_metrics.py,4216
vllm/model_executor/models/aimv2.py,4215
tests/models/language/generation/test_hybrid.py,4215
tests/samplers/test_ignore_eos.py,4214
tests/entrypoints/openai/test_cli_args.py,4209
tests/entrypoints/openai/test_tokenization.py,4205
tests/reasoning/utils.py,4203
vllm/distributed/device_communicators/base_device_communicator.py,4196
benchmarks/kernels/benchmark_machete.py,4196
vllm/v1/structured_output/utils.py,4193
tests/entrypoints/openai/test_models.py,4192
tests/tokenization/test_get_eos.py,4190
vllm/model_executor/layers/quantization/ptpc_fp8.py,4189
tests/tpu/test_custom_dispatcher.py,4188
vllm/scripts.py,4186
vllm/model_executor/models/qwen3_next.py,4186
vllm/model_executor/layers/quantization/kernels/scaled_mm/aiter.py,4182
tests/entrypoints/conftest.py,4182
tests/entrypoints/openai/test_prompt_validation.py,4181
vllm/transformers_utils/configs/jais.py,4177
vllm/v1/worker/worker_base.py,4174
tests/test_regression.py,4174
vllm/model_executor/layers/fused_moe/moe_align_block_size.py,4171
vllm/distributed/device_communicators/all2all.py,4171
vllm/reasoning/granite_reasoning_parser.py,4170
tests/entrypoints/openai/test_lora_adapters.py,4168
tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_platform.py,4163
tests/kernels/attention/test_triton_unified_attention.py,4163
tests/entrypoints/llm/test_prompt_validation.py,4163
vllm/model_executor/model_loader/tensorizer_loader.py,4161
benchmarks/benchmark_prefix_caching.py,4161
tests/entrypoints/openai/test_return_tokens_as_ids.py,4159
vllm/distributed/kv_transfer/kv_connector/v1/shared_storage_connector.py,4149
tests/samplers/test_ranks.py,4149
vllm/model_executor/models/phi4mm_utils.py,4148
tests/v1/e2e/test_spec_decode.py,4147
vllm/model_executor/models/telechat2.py,4140
vllm/model_executor/models/smolvlm.py,4139
vllm/distributed/device_communicators/cuda_communicator.py,4138
vllm/model_executor/models/phi4mm_audio.py,4135
vllm/model_executor/layers/mamba/ops/mamba_ssm.py,4133
tests/tokenization/test_cached_tokenizer.py,4132
vllm/model_executor/models/mllama.py,4125
vllm/benchmarks/serve.py,4125
vllm/model_executor/model_loader/default_loader.py,4124
vllm/benchmarks/throughput.py,4124
tests/entrypoints/openai/test_shutdown.py,4124
vllm/v1/structured_output/backend_guidance.py,4123
vllm/executor/msgspec_utils.py,4121
use_existing_torch.py,4119
tests/basic_correctness/test_cpu_offload.py,4119
benchmarks/backend_request_func.py,4118
vllm/transformers_utils/tokenizer_base.py,4113
vllm/transformers_utils/configs/chatglm.py,4108
vllm/compilation/monitor.py,4108
vllm/entrypoints/openai/tool_parsers/deepseekv3_tool_parser.py,4107
cmake/hipify.py,4106
vllm/reasoning/qwen3_reasoning_parser.py,4104
vllm/model_executor/models/phi3.py,4102
vllm/spec_decode/spec_decode_worker.py,4099
tests/entrypoints/llm/test_accuracy.py,4097
vllm/transformers_utils/tokenizers/__init__.py,4095
tests/weight_loading/test_weight_loading.py,4094
vllm/assets/audio.py,4093
tests/detokenizer/test_stop_strings.py,4092
tests/models/multimodal/generation/test_phi4mm.py,4091
tests/v1/e2e/test_cascade_attention.py,4090
vllm/model_executor/layers/quantization/gptq_bitblas.py,4089
tests/kernels/attention/test_merge_attn_states.py,4089
vllm/model_executor/layers/quantization/bitblas.py,4088
tests/entrypoints/openai/test_run_batch.py,4088
tests/models/multimodal/generation/test_granite_speech.py,4087
tests/models/language/generation/test_common.py,4087
tests/quantization/test_cpu_offload.py,4086
vllm/model_executor/models/fairseq2_llama.py,4084
vllm/model_executor/layers/quantization/kv_cache.py,4084
vllm/model_executor/layers/fused_moe/moe_permute_unpermute.py,4084
tests/tool_use/test_chat_completion_request_validations.py,4083
vllm/reasoning/deepseek_r1_reasoning_parser.py,4082
tests/entrypoints/openai/test_completion_with_function_calling.py,4082
vllm/v1/engine/coordinator.py,4081
vllm/model_executor/layers/quantization/compressed_tensors/schemes/__init__.py,4081
tests/models/multimodal/generation/test_qwen2_vl.py,4080
vllm/triton_utils/__init__.py,4077
vllm/model_executor/layers/quantization/utils/gptq_utils.py,4075
vllm/model_executor/layers/quantization/utils/int8_utils.py,4073
tests/tpu/test_compilation.py,4071
tests/entrypoints/llm/test_collective_rpc.py,4069
vllm/model_executor/models/glm.py,4068
vllm/attention/ops/triton_flash_attention.py,4068
tests/tokenization/test_tokenizer.py,4068
tests/kv_transfer/test_lookup_buffer.py,4067
tests/kernels/moe/test_moe_permute_unpermute.py,4066
tests/entrypoints/offline_mode/test_offline_mode.py,4066
tests/distributed/test_same_node.py,4066
vllm/model_executor/layers/quantization/utils/marlin_utils_test_24.py,4063
vllm/assets/image.py,4063
vllm/lora/punica_wrapper/punica_selector.py,4062
vllm/entrypoints/cli/main.py,4062
vllm/transformers_utils/processors/ovis.py,4061
vllm/v1/structured_output/backend_types.py,4059
tests/entrypoints/openai/test_chat_echo.py,4059
tests/lora/test_peft_helper.py,4058
vllm/v1/structured_output/request.py,4057
vllm/attention/ops/flashmla.py,4055
vllm/entrypoints/cli/benchmark/main.py,4054
vllm/v1/core/sched/interface.py,4052
vllm/model_executor/layers/quantization/torchao.py,4052
vllm/transformers_utils/chat_templates/registry.py,4051
vllm/attention/ops/rocm_aiter_mla.py,4050
tests/models/language/pooling/embed_utils.py,4050
vllm/transformers_utils/processors/__init__.py,4047
vllm/compilation/counter.py,4044
vllm/attention/ops/triton_decode_attention.py,4041
tests/v1/tpu/test_basic.py,4039
tests/tpu/test_quantization_accuracy.py,4039
tests/models/multimodal/pooling/test_dse_qwen2_vl.py,4039
vllm/model_executor/layers/quantization/utils/marlin_utils_fp4.py,4037
vllm/model_executor/layers/quantization/auto_round.py,4036
vllm/entrypoints/cli/run_batch.py,4035
vllm/model_executor/models/keye.py,4034
tests/v1/test_serial_utils.py,4033
vllm/lora/punica_wrapper/punica_tpu.py,4032
tests/entrypoints/openai/test_oot_registration.py,4032
tests/v1/tpu/test_perf.py,4030
vllm/model_executor/layers/quantization/kernels/mixed_precision/bitblas.py,4028
vllm/entrypoints/cli/types.py,4026
vllm/entrypoints/cli/collect_env.py,4026
vllm/compilation/sequence_parallelism.py,4026
vllm/model_executor/layers/fused_moe/moe_pallas.py,4023
vllm/lora/ops/triton_ops/utils.py,4019
tests/models/multimodal/generation/test_pixtral.py,4019
tests/distributed/test_multi_node_assignment.py,4017
tests/entrypoints/openai/test_chunked_prompt.py,4015
vllm/attention/ops/rocm_aiter_paged_attn.py,4011
tools/check_spdx_header.py,4011
tests/test_scalartype.py,4011
vllm/triton_utils/importing.py,4008
tests/models/multimodal/generation/test_whisper.py,4007
vllm/transformers_utils/configs/deepseek_vl2.py,4006
tests/multimodal/test_inputs.py,4005
vllm/entrypoints/openai/tool_parsers/phi4mini_tool_parser.py,4004
tests/kernels/core/test_rotary_embedding.py,4003
vllm/attention/utils/fa_utils.py,4002
tests/engine/test_short_mm_context.py,4001
benchmarks/cutlass_benchmarks/w8a8_benchmarks.py,4001
vllm/v1/executor/ray_distributed_executor.py,3999
vllm/model_executor/layers/quantization/awq_triton.py,3998
tests/quantization/test_experts_int8.py,3994
tests/distributed/test_pipeline_partition.py,3994
vllm/model_executor/layers/quantization/utils/bitblas_utils.py,3993
tests/distributed/test_torchrun_example.py,3992
vllm/model_executor/model_loader/runai_streamer_loader.py,3988
vllm/version.py,3984
tests/kernels/mamba/test_causal_conv1d.py,3984
tests/tool_use/conftest.py,3983
vllm/distributed/kv_events.py,3982
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16_nvfp4.py,3981
tests/plugins/vllm_add_dummy_model/vllm_add_dummy_model/__init__.py,3981
vllm/model_executor/layers/quantization/utils/__init__.py,3980
tests/models/multimodal/generation/vlm_utils/custom_inputs.py,3979
vllm/model_executor/layers/quantization/kernels/mixed_precision/allspark.py,3978
tests/plugins/vllm_add_dummy_platform/setup.py,3977
vllm/v1/core/sched/utils.py,3973
vllm/lora/ops/torch_ops/lora_ops.py,3973
vllm/lora/ops/torch_ops/__init__.py,3973
tests/kernels/attention/test_flashinfer.py,3973
tests/kernels/attention/test_flash_attn.py,3973
tests/quantization/test_ipex_quant.py,3972
vllm/model_executor/layers/fused_moe/moe_torch_iterative.py,3971
vllm/compilation/noop_elimination.py,3971
tests/kernels/quantization/test_triton_scaled_mm.py,3970
tests/multimodal/utils.py,3969
vllm/model_executor/layers/lightning_attn.py,3968
vllm/logging_utils/formatter.py,3968
tests/test_embedded_commit.py,3968
vllm/model_executor/model_loader/sharded_state_loader.py,3966
vllm/transformers_utils/configs/falcon.py,3964
tests/kernels/attention/test_cascade_flash_attn.py,3963
vllm/transformers_utils/__init__.py,3962
tests/vllm_test_utils/setup.py,3962
tests/plugins/vllm_add_dummy_model/setup.py,3961
tests/distributed/test_distributed_oot.py,3961
tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_attention_backend.py,3960
examples/offline_inference/audio_language.py,3960
vllm/distributed/kv_transfer/kv_transfer_state.py,3956
tests/entrypoints/llm/test_gpu_utilization.py,3956
vllm/model_executor/layers/sampler.py,3954
tests/kernels/allclose_default.py,3953
tests/distributed/test_ca_buffer_sharing.py,3951
vllm/entrypoints/openai/tool_parsers/llama4_pythonic_tool_parser.py,3947
tests/kernels/core/test_fused_quant_layernorm.py,3945
vllm/v1/sample/tpu/sampler.py,3940
tests/models/multimodal/generation/vlm_utils/builders.py,3940
vllm/model_executor/models/voxtral.py,3936
vllm/distributed/device_communicators/cpu_communicator.py,3935
benchmarks/kernels/benchmark_lora.py,3933
vllm/v1/metrics/prometheus.py,3931
vllm/attention/ops/triton_merge_attn_states.py,3931
tests/models/quantization/test_awq.py,3931
vllm/benchmarks/latency.py,3927
tests/kernels/quantization/test_machete_mm.py,3923
vllm/utils/__init__.py,3918
tests/entrypoints/test_api_server_process_manager.py,3918
vllm/v1/sample/tpu/metadata.py,3916
vllm/v1/spec_decode/metrics.py,3915
vllm/transformers_utils/configs/kimi_vl.py,3906
vllm/lora/resolver.py,3904
vllm/lora/ops/triton_ops/lora_kernel_metadata.py,3903
tests/distributed/conftest.py,3903
vllm/worker/cpu_model_runner.py,3900
vllm/v1/metrics/ray_wrappers.py,3898
vllm/distributed/kv_transfer/kv_lookup_buffer/mooncake_store.py,3898
vllm/plugins/lora_resolvers/filesystem_resolver.py,3896
vllm/compilation/torch25_custom_graph_pass.py,3896
benchmarks/benchmark_prioritization.py,3892
vllm/attention/ops/merge_attn_states.py,3891
vllm/v1/metrics/reader.py,3890
vllm/logging_utils/dump_input.py,3887
vllm/entrypoints/ssl.py,3887
benchmarks/cutlass_benchmarks/sparse_benchmarks.py,3887
tests/lora/test_resolver.py,3886
tools/enforce_regex_import.py,3884
vllm/attention/backends/flash_attn.py,3869
examples/offline_inference/multilora_inference.py,3837
vllm/model_executor/models/nano_nemotron_vl.py,3814
benchmarks/benchmark_throughput.py,3804
vllm/model_executor/models/ernie45_vl.py,3786
vllm/attention/backends/rocm_flash_attn.py,3781
examples/offline_inference/lora_with_quantization_inference.py,3771
benchmarks/kernels/benchmark_rmsnorm.py,3770
vllm/model_executor/models/gpt_oss.py,3758
benchmarks/fused_kernels/layernorm_rms_benchmarks.py,3756
tests/compile/test_fusion_attn.py,3747
vllm/model_executor/models/hunyuan_v1.py,3741
vllm/model_executor/models/florence2.py,3733
vllm/model_executor/models/step3_vl.py,3729
benchmarks/kernels/utils.py,3725
vllm/inputs/registry.py,3720
tests/spec_decode/utils.py,3720
vllm/model_executor/models/phi3_small.py,3709
tests/samplers/test_sampler.py,3709
benchmarks/benchmark_latency.py,3709
vllm/v1/attention/backends/flex_attention.py,3673
tests/v1/sample/test_logprobs.py,3666
tests/models/multimodal/generation/test_common.py,3644
vllm/worker/xpu_model_runner.py,3638
tests/kernels/attention/test_attention_selector.py,3638
vllm/worker/worker_base.py,3636
vllm/model_executor/models/interns1.py,3632
vllm/attention/backends/xformers.py,3620
vllm/model_executor/models/tarsier.py,3606
benchmarks/kernels/benchmark_moe.py,3605
tests/worker/test_model_runner.py,3583
vllm/engine/output_processor/multi_step.py,3564
vllm/model_executor/models/hyperclovax_vision.py,3553
vllm/model_executor/models/apertus.py,3548
vllm/model_executor/models/nemotron_vl.py,3540
vllm/model_executor/models/lfm2.py,3537
tests/spec_decode/test_spec_decode_worker.py,3533
vllm/lora/layers.py,3528
vllm/model_executor/models/seed_oss.py,3524
benchmarks/benchmark_serving.py,3515
vllm/model_executor/models/glm4_moe.py,3511
tests/v1/tpu/worker/test_tpu_model_runner.py,3511
vllm/model_executor/models/step3_text.py,3510
vllm/model_executor/models/bart.py,3509
vllm/model_executor/models/bailing_moe.py,3506
vllm/spec_decode/draft_model_runner.py,3489
vllm/model_executor/models/exaone4.py,3485
vllm/model_executor/models/dots1.py,3480
vllm/model_executor/models/dots_ocr.py,3477
vllm/worker/enc_dec_model_runner.py,3472
vllm/model_executor/models/ovis2_5.py,3466
tests/v1/attention/utils.py,3466
tests/v1/test_oracle.py,3459
vllm/worker/multi_step_model_runner.py,3457
tests/spec_decode/test_multi_step_worker.py,3452
tests/core/test_scheduler.py,3445
vllm/model_executor/models/ernie45_moe.py,3444
vllm/model_executor/models/nemotron_h.py,3436
tests/samplers/test_rejection_sampler.py,3432
vllm/v1/core/single_type_kv_cache_manager.py,3429
tests/kernels/attention/test_mha_attn.py,3419
tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/__init__.py,3413
vllm/attention/backends/flashinfer.py,3411
tests/lora/test_lora_functions.py,3406
docs/mkdocs/hooks/generate_examples.py,3405
tests/kernels/attention/test_cache.py,3404
vllm/config/vllm.py,3402
tests/samplers/test_logprobs.py,3392
tests/models/multimodal/processing/test_llama4.py,3389
tests/kernels/moe/test_nvfp4_moe.py,3388
tests/lora/test_add_lora.py,3385
vllm/worker/cpu_worker.py,3379
vllm/spec_decode/multi_step_worker.py,3377
vllm/model_executor/layers/quantization/mxfp4.py,3374
vllm/engine/multiprocessing/client.py,3370
tests/kernels/attention/test_prefix_prefill.py,3364
vllm/v1/attention/backends/cpu_attn.py,3362
vllm/v1/attention/backends/rocm_aiter_fa.py,3358
tests/tool_use/test_tool_choice_required.py,3355
tests/v1/engine/conftest.py,3354
tests/lora/test_punica_ops.py,3347
vllm/model_executor/models/cohere2_vision.py,3340
vllm/model_executor/models/ernie45_vl_moe.py,3339
tests/v1/spec_decode/test_ngram.py,3338
tests/models/language/generation/test_mistral.py,3329
.pre-commit-config.yaml,3329
tests/v1/attention/test_attention_backends.py,3308
vllm/model_executor/models/gemma3n.py,3305
vllm/entrypoints/openai/serving_responses.py,3302
tests/kernels/attention/test_rocm_attention_selector.py,3300
tests/async_engine/test_async_llm_engine.py,3298
vllm/worker/tpu_model_runner.py,3295
vllm/attention/backends/torch_sdpa.py,3294
tests/kernels/attention/test_flashmla.py,3288
tests/metrics/test_metrics.py,3282
vllm/model_executor/sampling_metadata.py,3279
tests/entrypoints/openai/correctness/test_transcription_api_correctness.py,3277
tests/compile/test_async_tp.py,3276
vllm/engine/multiprocessing/engine.py,3275
tests/v1/attention/test_mla_backends.py,3265
tests/kernels/attention/test_triton_decode_attention.py,3265
tests/models/multimodal/processing/test_phi4mm.py,3264
tests/models/multimodal/processing/test_smolvlm.py,3263
tests/spec_decode/e2e/conftest.py,3262
vllm/model_executor/models/midashenglm.py,3257
vllm/model_executor/layers/rotary_embedding.py,3257
tests/entrypoints/openai/tool_parsers/test_llama4_pythonic_tool_parser.py,3257
tests/compile/test_silu_mul_quant_fusion.py,3255
vllm/model_executor/models/eagle.py,3250
vllm/worker/neuron_model_runner.py,3248
tests/models/quantization/test_fp8.py,3239
tests/compile/piecewise/test_full_cudagraph.py,3237
tests/compile/test_sequence_parallelism.py,3236
tests/entrypoints/openai/test_completion.py,3230
docs/mkdocs/hooks/url_schemes.py,3230
vllm/config/compilation.py,3222
tests/models/multimodal/processing/test_tensor_schema.py,3222
tests/entrypoints/openai/test_embedding.py,3219
vllm/worker/cache_engine.py,3212
tests/core/utils.py,3212
tests/test_utils.py,3211
tests/kernels/quantization/test_block_fp8.py,3211
vllm/v1/attention/backends/rocm_attn.py,3210
vllm/model_executor/models/qwen3_next_mtp.py,3194
tests/models/language/pooling/test_nomic_max_model_len.py,3189
tests/models/multimodal/processing/test_minimax_vl_01.py,3186
vllm/model_executor/model_loader/gguf_loader.py,3177
vllm/model_executor/models/arcee.py,3176
vllm/model_executor/models/teleflm.py,3174
tests/models/multimodal/pooling/test_intern_vit.py,3167
vllm/v1/spec_decode/medusa.py,3159
benchmarks/kernels/benchmark_marlin.py,3158
docs/mkdocs/hooks/remove_announcement.py,3155
vllm/model_executor/model_loader/base_loader.py,3154
tests/kernels/quantization/test_cutlass_scaled_mm.py,3154
vllm/spec_decode/batch_expansion.py,3150
tests/models/test_vision.py,3140
tests/v1/kv_connector/unit/test_remote_decode_lifecycle.py,3137
vllm/model_executor/models/longcat_flash.py,3135
vllm/v1/attention/backends/mla/flashmla_sparse.py,3134
tests/test_cache_block_hashing.py,3134
tests/kernels/mamba/test_mamba_ssm_ssd.py,3132
vllm/model_executor/layers/fused_moe/config.py,3131
vllm/lora/ops/triton_ops/lora_shrink_op.py,3131
vllm/lora/ops/triton_ops/lora_expand_op.py,3131
vllm/config/multimodal.py,3131
vllm/worker/xpu_worker.py,3129
tests/kernels/quantization/test_marlin_gemm.py,3129
vllm/model_executor/models/phi4_multimodal.py,3127
tests/quantization/test_gptq_dynamic.py,3127
tests/v1/kv_connector/unit/test_remote_prefill_lifecycle.py,3121
tests/entrypoints/openai/correctness/test_lmeval.py,3116
vllm/spec_decode/util.py,3111
tests/spec_decode/test_batch_expansion.py,3109
tests/models/language/pooling/test_truncation_control.py,3107
tests/entrypoints/openai/test_openai_schema.py,3105
vllm/distributed/kv_transfer/__init__.py,3103
vllm/compilation/activation_quant_fusion.py,3102
tests/core/block/test_prefix_caching_block.py,3102
tests/models/language/pooling/test_scoring.py,3100
vllm/worker/model_runner_base.py,3096
tests/v1/sample/test_sampling_params_e2e.py,3094
tests/tpu/lora/test_lora.py,3093
csrc/moe/marlin_moe_wna16/generate_kernels.py,3093
tests/entrypoints/openai/test_transcription_validation.py,3091
vllm/model_executor/models/glm4_moe_mtp.py,3090
tests/kernels/moe/test_deepep_deepgemm_moe.py,3090
tests/v1/shutdown/test_startup_error.py,3089
tests/v1/shutdown/test_forward_error.py,3089
tests/kernels/core/test_activation.py,3089
tests/core/test_chunked_prefill_scheduler.py,3089
vllm/v1/spec_decode/ngram_proposer.py,3088
vllm/model_executor/models/ernie_mtp.py,3088
tests/worker/test_model_input.py,3088
tests/kernels/core/test_layernorm.py,3088
tests/v1/shutdown/test_delete.py,3087
vllm/env_override.py,3086
tests/entrypoints/openai/test_chat_with_tool_reasoning.py,3085
tests/v1/e2e/test_correctness_sliding_window.py,3084
csrc/quantization/gptq_marlin/generate_kernels.py,3083
tests/v1/spec_decode/test_max_len.py,3082
vllm/config/parallel.py,3081
tests/v1/tpu/test_mha_attn.py,3081
tests/plugins_tests/test_scheduler_plugins.py,3080
tests/models/multimodal/generation/test_interleaved.py,3077
tests/kernels/core/test_uva.py,3076
tests/v1/sample/test_logprobs_e2e.py,3074
tests/tpu/test_moe_pallas.py,3071
vllm/entrypoints/openai/speech_to_text.py,3068
vllm/engine/output_processor/single_step.py,3068
tests/kernels/moe/test_triton_moe_ptpc_fp8.py,3068
tests/kernels/attention/test_mla_decode_cpu.py,3068
vllm/model_executor/layers/mamba/ops/ssd_combined.py,3066
tests/entrypoints/openai/test_completion_with_prompt_embeds.py,3064
vllm/model_executor/layers/mamba/ops/ssd_chunk_state.py,3063
tests/v1/core/test_scheduler_e2e.py,3063
tests/kernels/moe/test_pplx_cutlass_moe.py,3058
tests/kernels/attention/conftest.py,3056
tests/v1/entrypoints/conftest.py,3054
tests/kernels/quantization/test_int8_kernel.py,3052
vllm/model_executor/layers/quantization/quark/schemes/quark_w4a4_mxfp4.py,3051
tests/kernels/mamba/test_mamba_ssm.py,3050
vllm/model_executor/layers/fused_moe/batched_deep_gemm_moe.py,3049
tests/multi_step/test_correctness_async_llm.py,3049
tests/entrypoints/llm/test_encode.py,3048
vllm/v1/attention/backends/tree_attn.py,3045
tests/kernels/attention/test_lightning_attn.py,3045
tests/v1/kv_connector/nixl_integration/test_accuracy.py,3044
tests/models/multimodal/pooling/test_phi3v.py,3044
tests/models/multimodal/pooling/test_llava_next.py,3044
tests/models/multimodal/generation/vlm_utils/case_filtering.py,3042
tests/kernels/mamba/test_mamba_mixer2.py,3042
tests/kernels/quantization/test_nvfp4_quant.py,3039
tests/models/multimodal/generation/test_ultravox.py,3037
tests/kernels/quantization/test_nvfp4_scaled_mm.py,3037
vllm/model_executor/models/terratorch.py,3036
benchmarks/kernels/graph_machete_bench.py,3036
vllm/v1/attention/backends/mla/cutlass_mla.py,3034
vllm/collect_env.py,3034
tests/kernels/quantization/test_block_int8.py,3034
tests/entrypoints/openai/test_chat_logit_bias_validation.py,3033
tests/models/language/pooling/test_classification.py,3031
vllm/worker/hpu_model_runner.py,3030
vllm/model_executor/layers/mamba/ops/ssd_chunk_scan.py,3028
tests/kernels/quantization/test_gguf.py,3027
tests/kernels/quantization/test_fp8_quant.py,3026
vllm/worker/hpu_worker.py,3023
vllm/model_executor/models/siglip2navit.py,3023
vllm/model_executor/layers/quantization/marlin.py,3023
tests/kernels/quantization/test_int8_quant.py,3022
tests/multimodal/test_video.py,3021
tests/kernels/quantization/test_awq_triton.py,3020
vllm/attention/ops/chunked_prefill_paged_decode.py,3019
tests/v1/tpu/test_multimodal.py,3019
tests/v1/structured_output/test_utils.py,3018
tests/multimodal/test_image.py,3018
vllm/distributed/kv_transfer/kv_connector/v1/__init__.py,3017
vllm/multimodal/cache.py,3014
tests/worker/test_swap.py,3014
tests/v1/tpu/test_sampler.py,3014
tests/v1/metrics/test_ray_metrics.py,3012
tests/v1/kv_connector/unit/test_multi_connector.py,3012
vllm/model_executor/layers/mamba/ops/ssd_state_passing.py,3010
vllm/lora/ops/xla_ops/lora_ops.py,3010
tests/tokenization/test_mistral_tokenizer.py,3010
tests/tokenization/test_tokenizer_group.py,3008
vllm/v1/attention/backends/mamba2_attn.py,3006
tests/v1/tpu/test_pallas.py,3004
vllm/v1/spec_decode/utils.py,3002
vllm/v1/attention/backends/mla/flashattn_mla.py,3002
vllm/model_executor/model_loader/dummy_loader.py,3001
vllm/lora/ops/xla_ops/__init__.py,3001
tests/models/quantization/test_nvfp4.py,3001
tests/kernels/test_fused_quant_activation.py,3000
vllm/model_executor/layers/mamba/ops/ssd_bmm.py,2999
tests/v1/tpu/test_topk_topp_sampler.py,2999
vllm/model_executor/layers/rejection_sampler.py,2996
tests/v1/entrypoints/openai/test_multi_api_servers.py,2995
tests/models/test_utils.py,2994
vllm/v1/sample/ops/bad_words.py,2993
vllm/attention/backends/blocksparse_attn.py,2993
tests/v1/entrypoints/openai/test_chat_completion.py,2992
tests/plugins/lora_resolvers/test_filesystem_resolver.py,2991
tests/models/quantization/test_modelopt.py,2990
tests/detokenizer/test_stop_reason.py,2990
tests/v1/kv_connector/nixl_integration/toy_proxy_server.py,2989
tests/reasoning/test_qwen3_reasoning_parser.py,2986
tests/prefix_caching/test_prefix_caching.py,2986
vllm/model_executor/layers/fused_moe/deepep_ht_prepare_finalize.py,2985
tests/worker/test_encoder_decoder_model_runner.py,2984
tests/reasoning/test_deepseekr1_reasoning_parser.py,2984
tests/reasoning/test_granite_reasoning_parser.py,2983
tests/quantization/test_torchao.py,2983
tests/multimodal/test_hasher.py,2983
tests/v1/kv_connector/nixl_integration/test_edge_cases.py,2982
vllm/model_executor/models/deepseek_eagle.py,2981
tests/spec_decode/test_scorer.py,2981
tests/quantization/test_ptpc_fp8.py,2981
tests/entrypoints/openai/test_sleep.py,2981
tests/entrypoints/openai/test_vision_embedding.py,2980
tests/multimodal/test_cache.py,2979
tests/models/multimodal/generation/vlm_utils/runners.py,2979
examples/offline_inference/prithvi_geospatial_mae.py,2979
vllm/attention/ops/triton_unified_attention.py,2978
tests/test_outputs.py,2978
tests/v1/core/utils.py,2976
tests/models/quantization/test_gguf.py,2975
examples/offline_inference/profiling.py,2975
vllm/lora/ops/triton_ops/kernel_utils.py,2973
tests/entrypoints/openai/test_tensorizer_entrypoint.py,2972
vllm/entrypoints/cli/benchmark/throughput.py,2971
vllm/entrypoints/cli/benchmark/latency.py,2971
vllm/entrypoints/cli/benchmark/base.py,2971
vllm/model_executor/layers/mamba/linear_attn.py,2970
tests/v1/sample/test_topk_topp_sampler.py,2970
examples/offline_inference/llm_engine_example.py,2969
vllm/entrypoints/cli/benchmark/serve.py,2968
tests/test_triton_utils.py,2968
tests/kernels/quantization/test_rocm_skinny_gemms.py,2968
tests/kernels/quantization/nvfp4_utils.py,2968
tests/models/quantization/test_gptq_marlin_24.py,2966
tests/quantization/test_auto_round.py,2964
vllm/core/block_manager.py,2962
vllm/model_executor/layers/quantization/utils/nvfp4_emulation_utils.py,2961
vllm/config/speculative.py,2959
tests/models/quantization/test_gptq_marlin.py,2959
tests/distributed/test_events.py,2959
vllm/model_executor/models/qwen3_vl_moe.py,2958
tests/models/language/generation/test_phimoe.py,2957
tests/benchmarks/test_serve_cli.py,2957
tests/models/quantization/test_gptq_bitblas.py,2956
tests/models/quantization/test_bitblas.py,2956
tests/models/language/generation/test_granite.py,2956
tests/kernels/moe/test_deepep_moe.py,2956
tests/encoder_decoder/test_e2e_correctness.py,2956
examples/offline_inference/profiling_tpu/profiling.py,2956
vllm/worker/neuron_worker.py,2955
vllm/transformers_utils/configs/moonvit.py,2955
vllm/v1/engine/exceptions.py,2953
tests/v1/shutdown/test_processor_error.py,2953
tests/kernels/test_triton_flash_attention.py,2953
vllm/v1/spec_decode/metadata.py,2952
tests/kv_transfer/test_module.py,2950
vllm/model_executor/layers/quantization/utils/allspark_utils.py,2949
tests/benchmarks/test_throughput_cli.py,2948
tests/benchmarks/test_latency_cli.py,2948
tests/basic_correctness/test_preemption.py,2948
tools/check_triton_import.py,2946
tests/models/quantization/test_mxfp4.py,2946
tests/tracing/test_tracing.py,2945
tests/kernels/quantization/test_gptq.py,2945
tests/kernels/quantization/test_ggml.py,2945
tests/kernels/moe/test_modular_kernel_combinations.py,2945
tests/test_version.py,2944
tests/kernels/quantization/test_cutlass_2of4_sparse.py,2944
tests/entrypoints/test_ssl_cert_refresher.py,2944
tests/kernels/moe/test_rocm_aiter_topk.py,2942
tests/tensorizer_loader/test_tensorizer.py,2941
tests/kernels/core/test_permute_cols.py,2941
vllm/transformers_utils/detokenizer.py,2940
tests/test_seed_behavior.py,2940
tests/test_vllm_port.py,2939
tests/kernels/quantization/test_awq.py,2939
tests/standalone_tests/lazy_imports.py,2938
tests/model_executor/test_weight_utils.py,2938
tests/kernels/quantization/test_allspark_gemm.py,2938
tests/detokenizer/test_disable_detokenization.py,2938
vllm/v1/attention/backends/mla/indexer.py,2932
tools/pre_commit/mypy.py,2925
tests/core/block/test_block_table.py,2921
tests/lora/test_baichuan.py,2918
vllm/v1/worker/kv_connector_model_runner_mixin.py,2917
vllm/attention/backends/pallas.py,2917
tests/entrypoints/openai/test_pooling.py,2915
vllm/spec_decode/ngram_worker.py,2914
tests/core/block/e2e/test_correctness_sliding_window.py,2908
vllm/worker/utils.py,2905
vllm/utils/deep_gemm.py,2904
vllm/attention/backends/ipex_attn.py,2902
vllm/model_executor/layers/fused_moe/deepep_ll_prepare_finalize.py,2900
tests/mq_llm_engine/utils.py,2888
tests/basic_correctness/test_chunked_prefill.py,2888
vllm/v1/attention/backends/gdn_attn.py,2886
tests/v1/spec_decode/test_tree_attention.py,2886
tests/async_engine/api_server_async_engine.py,2886
tests/kernels/moe/modular_kernel_tools/common.py,2884
vllm/model_executor/layers/mamba/short_conv.py,2878
tests/lora/test_phi.py,2878
examples/offline_inference/mlpspeculator.py,2878
tests/kernels/moe/utils.py,2877
tests/core/test_scheduler_encoder_decoder.py,2877
vllm/model_executor/models/llama4_eagle.py,2868
vllm/transformers_utils/configs/mpt.py,2867
vllm/spec_decode/metrics.py,2867
tests/samplers/test_seeded_generate.py,2861
vllm/model_executor/layers/fused_moe/batched_triton_or_deep_gemm_moe.py,2856
vllm/spec_decode/interfaces.py,2855
tests/tool_use/test_xlam_tool_parser.py,2854
tests/core/block/e2e/conftest.py,2854
examples/online_serving/api_client.py,2848
vllm/v1/attention/backends/xformers.py,2846
vllm/model_executor/layers/quantization/rtn.py,2846
vllm/model_executor/models/config.py,2845
vllm/lora/lora.py,2845
vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_connector.py,2835
examples/online_serving/openai_embedding_client.py,2833
vllm/core/evictor.py,2832
vllm/model_executor/layers/fused_moe/flashinfer_trtllm_moe.py,2831
benchmarks/kernels/benchmark_quant.py,2827
benchmarks/kernels/benchmark_layernorm.py,2827
vllm/v1/attention/backends/mla/flashinfer_mla.py,2824
vllm/model_executor/layers/quantization/utils/flashinfer_fp4_moe.py,2823
tests/core/block/test_naive_block.py,2820
vllm/config/cache.py,2819
vllm/spec_decode/top1_proposer.py,2818
vllm/engine/multiprocessing/__init__.py,2818
vllm/config/__init__.py,2818
vllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py,2811
examples/online_serving/openai_chat_completion_client_for_multimodal.py,2811
benchmarks/cutlass_benchmarks/utils.py,2810
tests/kernels/moe/modular_kernel_tools/mk_objects.py,2808
vllm/reasoning/basic_parsers.py,2807
vllm/core/block/prefix_caching_block.py,2804
tests/engine/test_multiproc_workers.py,2803
vllm/reasoning/olmo3_reasoning_parser.py,2799
vllm/entrypoints/renderer.py,2799
vllm/core/interfaces.py,2798
tests/tool_use/test_seed_oss_tool_parser.py,2796
tests/kernels/attention/test_flashinfer_trtllm_attention.py,2793
vllm/model_executor/models/jina_vl.py,2791
vllm/spec_decode/smaller_tp_proposer_worker.py,2787
vllm/entrypoints/context.py,2782
tests/spec_decode/test_metrics.py,2778
vllm/v1/attention/backends/short_conv_attn.py,2776
tests/v1/test_utils.py,2776
tests/samplers/test_logits_processor.py,2774
vllm/core/block/naive_block.py,2773
vllm/platforms/hpu.py,2772
vllm/worker/tpu_worker.py,2770
vllm/v1/kv_offload/cpu.py,2770
vllm/model_executor/layers/fused_moe/flashinfer_cutlass_moe.py,2770
vllm/worker/pooling_model_runner.py,2769
vllm/model_executor/layers/batch_invariant.py,2769
vllm/v1/worker/cpu_model_runner.py,2767
vllm/model_executor/layers/mamba/mamba_utils.py,2767
vllm/engine/output_processor/interfaces.py,2765
vllm/worker/cpu_enc_dec_model_runner.py,2762
vllm/attention/backends/hpu_attn.py,2761
vllm/entrypoints/openai/tool_parsers/__init__.py,2759
tests/tool_use/test_qwen3coder_tool_parser.py,2758
vllm/core/block/block_table.py,2749
vllm/model_executor/layers/fused_moe/gpt_oss_triton_kernels_moe.py,2748
tests/spec_decode/e2e/test_ngram_correctness.py,2748
tests/async_engine/test_api_server.py,2746
tests/models/multimodal/processing/test_nemotron_vl.py,2745
vllm/attention/ops/blocksparse_attention/interface.py,2743
tests/core/block/e2e/test_correctness.py,2743
vllm/platforms/neuron.py,2741
vllm/v1/core/kv_cache_coordinator.py,2738
vllm/v1/attention/backends/mamba1_attn.py,2733
vllm/compilation/pass_manager.py,2733
tests/spec_decode/e2e/test_medusa_correctness.py,2733
tests/entrypoints/llm/test_lazy_outlines.py,2733
vllm/core/block/cpu_gpu_block_allocator.py,2732
tests/spec_decode/e2e/test_mlp_correctness.py,2732
vllm/v1/engine/utils.py,2731
benchmarks/benchmark_utils.py,2731
vllm/model_executor/layers/rotary_embedding/__init__.py,2730
tests/kernels/attention/test_aiter_flash_attn.py,2728
tests/entrypoints/llm/test_guided_generate.py,2728
vllm/model_executor/layers/quantization/utils/flashinfer_utils.py,2726
vllm/spec_decode/medusa_worker.py,2724
vllm/model_executor/layers/quantization/aqlm.py,2723
vllm/model_executor/models/gemma3n_mm.py,2722
vllm/utils/flashinfer.py,2721
vllm/v1/worker/cpu_worker.py,2720
vllm/model_executor/models/longcat_flash_mtp.py,2719
vllm/distributed/device_communicators/custom_all_reduce_utils.py,2719
vllm/reasoning/gptoss_reasoning_parser.py,2713
vllm/model_executor/models/mamba_cache.py,2713
tests/mq_llm_engine/test_error_handling.py,2713
tests/spec_decode/test_utils.py,2712
vllm/model_executor/layers/quantization/neuron_quant.py,2709
vllm/model_executor/guided_decoding/__init__.py,2707
vllm/core/block/interfaces.py,2706
tests/multi_step/test_correctness_llm.py,2703
vllm/reasoning/hunyuan_a13b_reasoning_parser.py,2702
tests/lora/test_tokenizer_group.py,2702
tests/kernels/moe/parallel_utils.py,2701
vllm/model_executor/layers/fused_moe/flashinfer_cutlass_prepare_finalize.py,2700
vllm/transformers_utils/configs/exaone.py,2699
vllm/model_executor/model_loader/loader.py,2699
tests/samplers/test_typical_acceptance_sampler.py,2698
vllm/model_executor/models/interns1_vit.py,2696
vllm/spec_decode/mlp_speculator_worker.py,2694
examples/offline_inference/save_sharded_state.py,2694
vllm/attention/backends/placeholder_attn.py,2692
tests/kernels/moe/modular_kernel_tools/make_feature_matrix.py,2692
vllm/model_executor/model_loader/neuron.py,2691
tests/spec_decode/e2e/test_multistep_correctness.py,2690
vllm/model_executor/model_loader/tpu.py,2686
vllm/distributed/eplb/eplb_state.py,2684
tests/spec_decode/e2e/test_eagle_correctness.py,2684
vllm/worker/multi_step_worker.py,2683
vllm/model_executor/layers/spec_decode_base_sampler.py,2683
tests/kernels/moe/test_moe_align_block_size.py,2683
vllm/spec_decode/proposer_worker_base.py,2682
vllm/distributed/kv_transfer/kv_connector/v1/p2p/p2p_nccl_engine.py,2681
vllm/engine/output_processor/util.py,2680
vllm/reasoning/step3_reasoning_parser.py,2677
vllm/model_executor/layers/fused_moe/trtllm_moe.py,2675
tests/spec_decode/e2e/test_compatibility.py,2675
vllm/prompt_adapter/utils.py,2674
vllm/lora/layers/base_linear.py,2674
vllm/model_executor/layers/rotary_embedding/common.py,2672
benchmarks/overheads/benchmark_hashing.py,2672
vllm/transformers_utils/configs/arctic.py,2669
vllm/model_executor/layers/quantization/qqq.py,2669
vllm/core/block/common.py,2667
tests/v1/logits_processors/test_custom_offline.py,2664
tests/spec_decode/e2e/test_integration_dist_tp2.py,2663
vllm/model_executor/guided_decoding/xgrammar_decoding.py,2661
.buildkite/lm-eval-harness/test_lm_eval_correctness.py,2657
vllm/entrypoints/openai/tool_parsers/qwen3xml_tool_parser.py,2656
tests/entrypoints/openai/test_score.py,2656
vllm/model_executor/layers/typical_acceptance_sampler.py,2654
vllm/v1/worker/tpu_input_batch.py,2653
vllm/distributed/device_communicators/all_reduce_utils.py,2648
vllm/compilation/cuda_graph.py,2647
vllm/v1/pool/metadata.py,2646
vllm/model_executor/layers/fused_moe/cpu_fused_moe.py,2646
vllm/config/pooler.py,2646
vllm/model_executor/layers/mla.py,2645
tests/model_executor/test_guided_processors.py,2645
tests/spec_decode/e2e/test_logprobs.py,2642
vllm/attention/layers/cross_attention.py,2641
examples/offline_inference/vision_language_embedding.py,2640
vllm/entrypoints/openai/tool_parsers/minimax_tool_parser.py,2639
vllm/distributed/device_communicators/quick_all_reduce.py,2637
tests/entrypoints/openai/test_rerank.py,2635
tests/models/multimodal/pooling/test_jinavl_reranker.py,2634
.buildkite/nightly-benchmarks/scripts/convert-results-json-to-markdown.py,2634
vllm/executor/multiproc_worker_utils.py,2633
tests/spec_decode/e2e/test_integration.py,2633
vllm/lora/layers/vocal_parallel_embedding.py,2630
vllm/entrypoints/openai/tool_parsers/openai_tool_parser.py,2630
examples/offline_inference/encoder_decoder.py,2629
.buildkite/nightly-benchmarks/scripts/summary-nightly-results.py,2628
tests/distributed/test_context_parallel.py,2627
examples/online_serving/openai_pooling_client.py,2627
examples/online_serving/openai_cross_encoder_score.py,2627
examples/online_serving/openai_chat_embedding_client_for_multimodal.py,2627
vllm/spec_decode/target_model_runner.py,2626
vllm/model_executor/guided_decoding/outlines_logits_processors.py,2626
vllm/entrypoints/openai/tool_parsers/step3_tool_parser.py,2626
vllm/attention/layers/chunked_local_attention.py,2626
vllm/engine/output_processor/stop_checker.py,2625
tests/tensorizer_loader/conftest.py,2624
benchmarks/kernels/benchmark_aqlm.py,2624
vllm/entrypoints/openai/tool_parsers/hunyuan_a13b_tool_parser.py,2623
vllm/entrypoints/openai/tool_parsers/glm4_moe_tool_parser.py,2623
tests/prefix_caching/test_disable_sliding_window.py,2623
vllm/attention/backends/triton_mla.py,2619
examples/online_serving/openai_chat_completion_with_reasoning_streaming.py,2618
examples/online_serving/openai_chat_completion_with_reasoning.py,2618
vllm/model_executor/layers/rotary_embedding/base.py,2616
tests/test_sampling_params.py,2616
tests/spec_decode/e2e/test_seed.py,2616
vllm/lora/ops/triton_ops/__init__.py,2615
tests/spec_decode/test_ngram_worker.py,2615
vllm/entrypoints/openai/tool_parsers/seed_oss_tool_parser.py,2614
vllm/entrypoints/openai/tool_parsers/kimi_k2_tool_parser.py,2613
vllm/config/scheduler.py,2613
vllm/transformers_utils/configs/dbrx.py,2612
vllm/entrypoints/openai/tool_parsers/qwen3coder_tool_parser.py,2612
benchmarks/benchmark_long_document_qa_throughput.py,2612
vllm/entrypoints/openai/tool_parsers/deepseekv31_tool_parser.py,2611
.buildkite/nightly-benchmarks/scripts/generate-nightly-markdown.py,2611
vllm/worker/cpu_pooling_model_runner.py,2610
vllm/lora/layers/row_parallel_linear.py,2610
vllm/lora/fully_sharded_layers.py,2609
vllm/model_executor/guided_decoding/outlines_decoding.py,2607
tests/spec_decode/e2e/test_integration_dist_tp4.py,2600
vllm/transformers_utils/configs/solar.py,2599
tests/core/test_num_computed_tokens_update.py,2598
vllm/attention/ops/ipex_attn.py,2597
examples/offline_inference/structured_outputs.py,2597
examples/offline_inference/rlhf.py,2595
tests/kernels/moe/modular_kernel_tools/profile_modular_kernel.py,2593
vllm/model_executor/layers/fla/ops/layernorm_guard.py,2591
vllm/distributed/device_communicators/ray_communicator.py,2591
vllm/model_executor/layers/fused_moe/deep_gemm_utils.py,2590
tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/prithvi_processor.py,2586
vllm/v1/cudagraph_dispatcher.py,2585
vllm/prompt_adapter/models.py,2585
vllm/prompt_adapter/request.py,2583
examples/offline_inference/neuron_int8_quantization.py,2581
examples/offline_inference/neuron.py,2581
vllm/spec_decode/mqa_scorer.py,2580
vllm/entrypoints/harmony_utils.py,2580
vllm/lora/layers/column_parallel_linear.py,2579
tests/mq_llm_engine/test_load.py,2579
vllm/model_executor/layers/quantization/input_quant_fp8.py,2578
tests/quantization/test_bitsandbytes.py,2578
vllm/distributed/eplb/rebalance_execute.py,2577
vllm/transformers_utils/processors/deepseek_vl2.py,2575
vllm/v1/worker/gpu_ubatch_wrapper.py,2572
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a4_nvfp4.py,2571
vllm/config/lora.py,2571
tests/entrypoints/llm/test_generate_multiple_loras.py,2569
tests/core/test_serialization.py,2568
examples/offline_inference/tpu.py,2568
vllm/model_executor/layers/quantization/utils/marlin_utils_test_qqq.py,2567
tests/v1/logits_processors/test_custom_online.py,2567
tests/spec_decode/test_dynamic_spec_decode.py,2567
vllm/lora/layers/logits_processor.py,2566
tests/quantization/utils.py,2566
vllm/v1/sample/logits_processor/__init__.py,2565
vllm/transformers_utils/configs/step3_vl.py,2564
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_fp8.py,2562
vllm/distributed/tpu_distributed_utils.py,2562
tests/mq_llm_engine/test_abort.py,2562
examples/online_serving/openai_chat_completion_structured_outputs.py,2562
vllm/transformers_utils/configs/midashenglm.py,2561
examples/online_serving/gradio_openai_chatbot_webserver.py,2558
examples/offline_inference/torchrun_example.py,2558
vllm/lora/layers/base.py,2557
tests/entrypoints/openai/test_encoder_decoder.py,2556
vllm/v1/structured_output/backend_outlines.py,2555
vllm/model_executor/pooling_metadata.py,2553
vllm/lora/lora_weights.py,2552
vllm/core/block/utils.py,2552
tests/v1/logits_processors/test_correctness.py,2552
vllm/model_executor/layers/rotary_embedding/mrope.py,2551
vllm/adapter_commons/request.py,2551
vllm/model_executor/models/transformers_pooling.py,2550
vllm/model_executor/models/keye_vl1_5.py,2550
examples/online_serving/gradio_webserver.py,2549
vllm/prompt_adapter/worker_manager.py,2548
vllm/prompt_adapter/layers.py,2548
tests/prompt_adapter/test_pa_lora.py,2548
tests/prompt_adapter/test_multi_adapter_inference.py,2548
tests/prompt_adapter/test_bloom.py,2548
vllm/plugins/io_processors/__init__.py,2547
tests/kernels/test_onednn.py,2546
vllm/v1/structured_output/backend_lm_format_enforcer.py,2545
examples/offline_inference/chat_with_tools.py,2544
vllm/v1/sample/logits_processor/interface.py,2541
tests/async_engine/test_request_tracker.py,2541
vllm/reasoning/glm4_moe_reasoning_parser.py,2540
vllm/transformers_utils/runai_utils.py,2537
vllm/distributed/kv_transfer/kv_connector/base.py,2537
vllm/core/placeholder_block_space_manager.py,2536
examples/online_serving/openai_completion_client.py,2536
examples/online_serving/jinaai_rerank_client.py,2536
examples/online_serving/cohere_rerank_client.py,2536
examples/offline_inference/prefix_caching.py,2536
vllm/attention/ops/blocksparse_attention/blocksparse_attention_kernel.py,2535
tests/models/language/pooling_mteb_test/test_bge_reranker_v2_gemma.py,2535
examples/online_serving/opentelemetry/dummy_client.py,2535
tests/model_executor/model_loader/tensorizer_loader/conftest.py,2534
vllm/plugins/io_processors/interface.py,2532
vllm/attention/ops/blocksparse_attention/utils.py,2530
vllm/model_executor/guided_decoding/utils.py,2529
vllm/adapter_commons/utils.py,2529
tests/engine/test_computed_prefix_blocks.py,2528
examples/online_serving/openai_chat_completion_client.py,2528
examples/online_serving/openai_chat_completion_client_with_tools.py,2526
vllm/model_executor/layers/fla/ops/chunk_o.py,2525
vllm/model_executor/guided_decoding/lm_format_enforcer_decoding.py,2525
vllm/v1/worker/ubatch_utils.py,2524
vllm/v1/core/sched/async_scheduler.py,2524
vllm/adapter_commons/models.py,2524
vllm/distributed/device_communicators/symm_mem.py,2522
vllm/attention/ops/nki_flash_attn.py,2522
tests/v1/kv_connector/unit/test_output_aggreagator.py,2522
examples/online_serving/disaggregated_serving/disagg_proxy_demo.py,2522
vllm/model_executor/guided_decoding/guided_fields.py,2521
vllm/adapter_commons/worker_manager.py,2520
tests/v1/executor/test_executor.py,2519
benchmarks/disagg_benchmarks/disagg_prefill_proxy_server.py,2517
vllm/distributed/kv_transfer/kv_connector/simple_connector.py,2516
vllm/model_executor/models/rvl.py,2515
benchmarks/cutlass_benchmarks/weight_shapes.py,2515
vllm/config/observability.py,2514
tests/worker/test_profile.py,2514
tests/core/block/test_cpu_gpu_block_allocator.py,2514
benchmarks/disagg_benchmarks/visualize_benchmark_results.py,2514
benchmarks/disagg_benchmarks/round_robin_proxy.py,2514
tests/v1/tracing/test_tracing.py,2511
vllm/distributed/device_communicators/hpu_communicator.py,2510
vllm/config/kv_transfer.py,2510
vllm/compilation/piecewise_backend.py,2510
tests/test_sharded_state_loader.py,2510
vllm/model_executor/layers/rotary_embedding/deepseek_scaling_rope.py,2509
vllm/attention/ops/hpu_paged_attn.py,2508
benchmarks/kernels/weight_shapes.py,2508
tests/core/block/test_block_manager.py,2507
vllm/lora/layers/replicated_linear.py,2505
tests/v1/logits_processors/utils.py,2504
vllm/model_executor/layers/quantization/kernels/scaled_mm/cpu.py,2503
vllm/adapter_commons/layers.py,2503
vllm/utils/gc_utils.py,2502
vllm/lora/punica_wrapper/punica_xpu.py,2501
vllm/attention/layers/encoder_only_attention.py,2501
tests/kernels/attention/test_cutlass_mla_decode.py,2501
vllm/executor/mp_distributed_executor.py,2500
tests/v1/e2e/test_min_tokens.py,2500
tests/kernels/moe/modular_kernel_tools/parallel_utils.py,2500
tests/models/language/pooling_mteb_test/mteb_utils.py,2499
examples/offline_inference/simple_profiling.py,2499
vllm/model_executor/layers/quantization/quark/schemes/__init__.py,2498
vllm/model_executor/layers/quantization/compressed_tensors/transform/module.py,2498
vllm/model_executor/layers/fla/ops/fused_recurrent.py,2498
vllm/model_executor/layers/fla/ops/chunk_scaled_dot_kkt.py,2498
vllm/model_executor/layers/fla/ops/chunk_delta_h.py,2498
vllm/compilation/multi_output_match.py,2498
tests/entrypoints/test_renderer.py,2498
.buildkite/nightly-benchmarks/scripts/download-tokenizer.py,2497
examples/online_serving/kv_events_subscriber.py,2496
.buildkite/check-wheel-size.py,2496
vllm/model_executor/layers/rotary_embedding/dual_chunk_rope.py,2494
vllm/model_executor/layers/quantization/petit.py,2494
vllm/model_executor/layers/fla/ops/l2norm.py,2494
vllm/lora/punica_wrapper/punica_hpu.py,2494
vllm/distributed/__init__.py,2493
vllm/config/load.py,2493
tools/check_init_lazy_imports.py,2493
tests/kernels/quantization/test_cutlass_w4a8.py,2490
tests/core/block/test_common.py,2490
vllm/transformers_utils/configs/nvlm_d.py,2487
tests/quantization/test_blackwell_moe.py,2487
.buildkite/nightly-benchmarks/scripts/get-lmdeploy-modelname.py,2487
vllm/transformers_utils/configs/cohere2.py,2486
vllm/transformers_utils/configs/radio.py,2485
vllm/transformers_utils/configs/ovis.py,2485
vllm/model_executor/layers/quantization/kernels/mixed_precision/cutlass.py,2485
vllm/distributed/device_communicators/shm_object_storage.py,2485
vllm/model_executor/layers/rotary_embedding/llama4_vision_rope.py,2484
vllm/model_executor/models/radio.py,2480
vllm/model_executor/layers/rotary_embedding/ernie45_vl_rope.py,2480
tests/models/language/generation_ppl_test/ppl_utils.py,2480
vllm/v1/sample/logits_processor/state.py,2479
vllm/transformers_utils/processors/ovis2_5.py,2479
vllm/distributed/device_communicators/pynccl_allocator.py,2479
tests/models/multimodal/generation/test_phi4_multimodal.py,2478
examples/offline_inference/rlhf_utils.py,2478
vllm/entrypoints/tool_server.py,2477
vllm/logprobs.py,2476
vllm/distributed/kv_transfer/kv_connector/v1/metrics.py,2476
vllm/benchmarks/lib/endpoint_request_func.py,2476
tests/model_executor/conftest.py,2476
.buildkite/generate_index.py,2475
tests/v1/distributed/test_async_llm_dp.py,2474
tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/types.py,2474
vllm/utils/tensor_schema.py,2473
tests/v1/kv_connector/unit/test_kv_load_failure_recovery.py,2473
vllm/v1/sample/logits_processor/builtin.py,2472
vllm/transformers_utils/configs/telechat2.py,2471
vllm/model_executor/layers/fused_moe/topk_weight_and_reduce.py,2471
vllm/model_executor/layers/quantization/compressed_tensors/transform/linear.py,2470
vllm/model_executor/layers/fla/ops/utils.py,2470
vllm/model_executor/layers/fla/ops/cumsum.py,2470
vllm/model_executor/layers/fla/ops/chunk.py,2470
tests/v1/worker/test_worker_memory_snapshot.py,2470
benchmarks/kernels/benchmark_shapes.py,2470
vllm/utils/jsontree.py,2469
vllm/transformers_utils/configs/mllama.py,2468
vllm/model_executor/layers/fla/ops/solve_tril.py,2468
vllm/config/device.py,2468
vllm/v1/kv_offload/factory.py,2467
vllm/model_executor/layers/quantization/compressed_tensors/transform/schemes/linear_qutlass_nvfp4.py,2467
vllm/model_executor/layers/rotary_embedding/phi3_long_rope_scaled_rope.py,2466
vllm/model_executor/layers/fla/ops/wy_fast.py,2466
vllm/worker/multi_step_tpu_worker.py,2465
vllm/logging_utils/__init__.py,2465
vllm/multimodal/evs.py,2464
vllm/model_executor/layers/rotary_embedding/ntk_scaling_rope.py,2464
vllm/model_executor/layers/rotary_embedding/linear_scaling_rope.py,2464
vllm/model_executor/layers/fused_moe/routing_simulator.py,2463
tests/core/block/conftest.py,2463
vllm/transformers_utils/configs/speculators/base.py,2462
vllm/model_executor/models/swin.py,2461
vllm/model_executor/layers/quantization/utils/petit_utils.py,2461
tests/evals/gsm8k/gsm8k_eval.py,2461
tests/entrypoints/pooling/openai/test_embedding_dimensions.py,2460
vllm/v1/core/sched/request_queue.py,2459
vllm/transformers_utils/configs/internvl.py,2459
tests/vllm_test_utils/vllm_test_utils/__init__.py,2458
tests/kernels/moe/test_count_expert_num_tokens.py,2458
vllm/v1/kv_offload/lru_manager.py,2457
vllm/transformers_utils/configs/h2ovl.py,2457
vllm/transformers_utils/configs/dotsocr.py,2456
vllm/transformers_utils/config_parser_base.py,2455
tests/transformers_utils/test_config_parser_registry.py,2455
vllm/v1/kv_offload/abstract.py,2454
vllm/model_executor/layers/quantization/kernels/mixed_precision/dynamic_4bit.py,2454
vllm/model_executor/layers/quantization/kernels/mixed_precision/conch.py,2454
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a8_int.py,2454
vllm/_bc_linter.py,2454
tests/benchmarks/test_random_dataset.py,2454
vllm/ray/ray_env.py,2453
find_cuda_init.py,2453
tests/v1/kv_offload/test_cpu_manager.py,2452
vllm/lora/punica_wrapper/__init__.py,2450
tests/v1/distributed/test_internal_lb_dp.py,2450
tests/tool_use/mistral/utils.py,2450
vllm/engine/async_timeout.py,2446
docs/source/conf.py,2375
tests/kernels/test_attention.py,2330
tests/kernels/test_cache.py,2289
tests/entrypoints/openai/test_serving_engine.py,2175
tests/models/decoder_only/vision_language/test_models.py,2167
tests/utils_/test_utils.py,2143
docs/models/supported_models.md,2121
examples/offline_inference/basic/embed.py,2098
vllm/model_executor/models/prithvi_geospatial_mae.py,2084
vllm/model_executor/models/qwen3_omni_moe_thinker.py,2072
examples/offline_inference/basic/score.py,2053
tests/v1/spec_decode/test_mtp.py,2046
vllm/compilation/fusion_attn.py,2024
tests/kernels/test_pos_encoding.py,2012
tests/v1/attention/test_sparse_mla_backends.py,2004
vllm/attention/backends/mla/common.py,1978
docs/source/generate_examples.py,1952
CMakeLists.txt,1928
tests/compile/test_config.py,1918
tests/entrypoints/openai/tool_parsers/test_hermes_tool_parser.py,1912
tests/kernels/moe/test_block_fp8.py,1910
benchmarks/kernels/benchmark_grouped_gemm_cutlass.py,1907
tests/models/multimodal/processing/test_mllama4.py,1903
tests/kernels/moe/test_flashinfer.py,1900
tests/kernels/moe/test_flashinfer_moe.py,1873
tests/models/multimodal/test_mapping.py,1871
vllm/v1/engine/mm_input_cache.py,1867
tests/kernels/moe/test_gpt_oss_triton_kernels.py,1865
vllm/v1/kv_offload/worker/cpu_gpu.py,1862
vllm/v1/kv_offload/spec.py,1860
vllm/reasoning/mistral_reasoning_parser.py,1859
tests/kernels/test_activation.py,1859
tests/kernels/moe/test_deepgemm.py,1856
vllm/v1/attention/backends/linear_attn.py,1849
examples/offline_inference/basic/classify.py,1838
tests/kernels/core/test_mrope.py,1836
tests/models/multimodal/processing/test_glm4_1v.py,1834
examples/offline_inference/data_parallel.py,1826
tests/engine/test_executor.py,1822
tests/entrypoints/openai/tool_parsers/test_llama3_json_tool_parser.py,1819
tools/pre_commit/check_pickle_imports.py,1804
examples/offline_inference/encoder_decoder_multimodal.py,1804
tests/kernels/test_encoder_decoder_attn.py,1802
tests/entrypoints/openai/test_serving_responses.py,1789
vllm/v1/attention/backends/mamba_attn.py,1786
tests/lora/test_transfomers_model.py,1783
tests/kernels/attention/test_flashmla_sparse.py,1782
vllm/model_executor/models/lfm2_moe.py,1774
vllm/model_executor/layers/attention_layer_base.py,1774
benchmarks/benchmark_ngram_proposer.py,1774
tests/kernels/attention/test_pack_unpack_triton.py,1771
tests/models/language/pooling/mteb_utils.py,1770
tests/multimodal/test_registry.py,1768
examples/others/tensorize_vllm_model.py,1765
tests/tool_use/test_minimax_tool_parser.py,1756
tests/kernels/moe/test_silu_mul_fp8_quant_deep_gemm.py,1747
tests/distributed/test_kvlayout.py,1747
tests/compile/piecewise/test_multiple_graphs.py,1746
vllm/entrypoints/openai/tool_parsers/xlam_tool_parser.py,1744
tests/v1/cudagraph/test_cudagraph_mode.py,1744
vllm/config/utils.py,1742
tests/models/multimodal/generation/test_voxtral.py,1742
vllm/v1/core/scheduler.py,1737
tests/mistral_tool_use/utils.py,1737
tests/models/multimodal/pooling/test_prithvi_mae.py,1735
examples/offline_inference/qwen2_5_omni/only_thinker.py,1730
tests/compile/test_fusion_all_reduce.py,1728
vllm/transformers_utils/configs/mistral.py,1726
tests/kernels/attention/test_deepgemm_attention.py,1723
tests/reasoning/test_mistral_reasoning_parser.py,1720
vllm/v1/worker/xpu_worker.py,1717
tests/models/multimodal/pooling/test_radio.py,1717
tests/models/language/pooling/test_jina.py,1717
tests/tool_use/test_glm4_moe_tool_parser.py,1712
tests/kernels/moe/test_cutlass_grouped_gemm.py,1711
tests/entrypoints/openai/tool_parsers/test_hunyuan_a13b_tool_parser.py,1710
tests/v1/core/test_single_type_kv_cache_manager.py,1707
vllm/attention/ops/pallas_kv_cache_update.py,1705
vllm/worker/openvino_model_runner.py,1703
csrc/torch_bindings.cpp,1702
tests/tool_use/test_kimi_k2_tool_parser.py,1701
tests/compile/test_decorator.py,1701
vllm/model_executor/warmup/deep_gemm_warmup.py,1699
tests/reasoning/test_base_thinking_reasoning_parser.py,1697
examples/offline_inference/basic/chat.py,1696
benchmarks/kernels/benchmark_moe_permute_unpermute.py,1695
examples/offline_inference/embed_matryoshka_fy.py,1692
tests/kernels/moe/test_block_int8.py,1690
vllm/v1/worker/ubatching.py,1688
benchmarks/kernels/benchmark_cutlass_fp4_moe.py,1688
vllm/test_utils.py,1687
examples/offline_inference/embed_jina_embeddings_v3.py,1687
tests/kernels/moe/test_batched_deepgemm.py,1686
tests/plugins_tests/test_io_processor_plugins.py,1685
tests/v1/worker/test_utils.py,1680
tests/kernels/quantization/test_fp8_quant_group.py,1673
tests/v1/kv_connector/unit/test_offloading_connector.py,1670
vllm/attention/ops/common.py,1668
tests/kernels/test_cutlass.py,1668
benchmarks/benchmark_block_pool.py,1667
vllm/entrypoints/openai/tool_parsers/longcat_tool_parser.py,1666
tests/tool_use/test_openai_tool_parser.py,1666
vllm/attention/backends/dual_chunk_flash_attn.py,1664
tests/models/decoder_only/audio_language/test_ultravox.py,1661
vllm/model_executor/layers/rotary_embedding/rocm_aiter_rope_ops.py,1660
vllm/transformers_utils/configs/qwen3_next.py,1659
tests/kernels/test_flex_attention.py,1659
tests/kernels/test_blocksparse_attention.py,1658
tests/tool_use/test_deepseekv31_tool_parser.py,1657
tests/test_pooling_params.py,1654
docs/mkdocs/hooks/generate_argparse.py,1652
tests/kernels/moe/test_grouped_topk.py,1651
benchmarks/kernels/benchmark_w8a8_block_fp8.py,1651
tests/models/quantization/test_bitsandbytes.py,1649
tests/v1/cudagraph/test_cudagraph_dispatch.py,1647
tests/kernels/test_apply_repetition_penalties.py,1647
tests/entrypoints/openai/test_skip_tokenizer.py,1646
examples/offline_inference/load_sharded_state.py,1646
vllm/transformers_utils/tokenizer_group.py,1645
tests/compile/silly_attention.py,1645
tests/kernels/test_flash_attn.py,1641
tests/v1/kv_offload/test_cpu_gpu.py,1640
csrc/ops.h,1640
tests/kernels/moe/test_mxfp4_moe.py,1639
tests/v1/core/test_async_scheduler.py,1638
tests/models/language/pooling/test_reward.py,1638
tests/kernels/quantization/test_silu_mul_nvfp4_quant.py,1634
tests/entrypoints/openai/test_optional_middleware.py,1628
examples/offline_inference/neuron_speculation.py,1627
tests/tokenization/test_do_lower_case.py,1626
tests/model_executor/model_loader/tensorizer_loader/test_tensorizer.py,1624
vllm/distributed/eplb/rebalance_algo.py,1623
tests/entrypoints/openai/test_embedding_dimensions.py,1623
examples/online_serving/prompt_embed_inference_with_openai_client.py,1621
benchmarks/kernels/benchmark_bitblas.py,1621
tests/v1/tpu/test_spmd_model_weight_loading.py,1620
tests/entrypoints/openai/test_translation_validation.py,1620
tests/v1/tpu/test_tpu_qkv_linear.py,1619
vllm/transformers_utils/configs/olmo3.py,1616
tests/kernels/quantization/test_flashinfer_nvfp4_scaled_mm.py,1616
tests/v1/e2e/test_kv_sharing_fast_prefill.py,1615
tests/lora/test_long_context.py,1613
vllm/model_executor/models/decilm.py,1611
examples/offline_inference/basic/generate.py,1610
vllm/model_executor/warmup/kernel_warmup.py,1605
tests/entrypoints/pooling/openai/test_embedding.py,1601
vllm/model_executor/models/constant_size_cache.py,1600
vllm/distributed/kv_transfer/kv_connector/v1/p2p/tensor_memory_pool.py,1599
vllm/attention/backends/rocm_aiter_mla.py,1598
tests/spec_decode/conftest.py,1598
tests/v1/engine/test_fast_incdec_prefix_err.py,1597
tests/models/language/pooling_mteb_test/test_jina.py,1596
tests/models/language/generation/test_gemma.py,1596
examples/offline_inference/mistral-small.py,1596
examples/offline_inference/eagle.py,1595
vllm/distributed/eplb/__init__.py,1594
tests/v1/attention/test_attention_splitting.py,1594
tests/test_routing_simulator.py,1594
tests/models/language/pooling/test_pooler_config_init_behaviour.py,1593
tests/models/language/pooling_mteb_test/test_qwen3_reranker.py,1592
tests/models/language/pooling_mteb_test/test_mxbai_rerank.py,1592
tests/entrypoints/openai/test_response_api_with_harmony.py,1592
vllm/v1/worker/xpu_model_runner.py,1591
tests/spec_decode/e2e/test_mtp_correctness.py,1591
tests/models/language/pooling_mteb_test/test_gte.py,1591
tests/models/language/pooling_mteb_test/test_baai.py,1591
tests/kernels/quantization/test_flashinfer_scaled_mm.py,1591
tests/entrypoints/pooling/llm/test_classify.py,1591
vllm/transformers_utils/configs/nemotron_h.py,1590
tests/models/language/pooling/test_mm_classifier_conversion.py,1590
examples/pyproject.toml,1589
examples/online_serving/openai_chat_completion_client_with_tools_required.py,1589
tests/v1/engine/test_processor_multi_modal_uuids.py,1588
tests/models/language/pooling_mteb_test/test_cross_encoder.py,1587
vllm/transformers_utils/configs/deepseek_v3.py,1585
vllm/lora/layers/__init__.py,1585
tests/quantization/test_rtn.py,1585
tests/v1/kv_offload/test_cpu_offloading.py,1583
tests/v1/entrypoints/openai/responses/test_image.py,1583
tests/v1/core/test_encoder_cache_manager.py,1583
tests/kernels/test_moe.py,1583
tests/entrypoints/pooling/openai/test_rerank.py,1583
.buildkite/pyproject.toml,1583
tests/lora/test_llm_with_multi_loras.py,1580
examples/online_serving/openai_chat_completion_tool_calls_with_reasoning.py,1580
tests/evals/gsm8k/test_gsm8k_correctness.py,1577
tests/entrypoints/openai/test_return_token_ids.py,1576
tests/entrypoints/pooling/llm/test_encode.py,1575
tests/entrypoints/pooling/llm/test_embedding.py,1575
tests/config/test_mp_reducer.py,1575
tests/compile/test_noop_elimination.py,1575
benchmarks/kernels/deepgemm/benchmark_fp8_block_dense_gemm.py,1575
examples/offline_inference/neuron_eagle.py,1574
tests/models/language/pooling_mteb_test/test_st_projector.py,1573
tests/models/decoder_only/vision_language/vlm_utils/model_utils.py,1573
tests/entrypoints/pooling/llm/test_reward.py,1573
benchmarks/pyproject.toml,1573
tests/distributed/test_eplb_execute.py,1572
tests/models/test_terratorch.py,1571
vllm/attention/backends/flashmla.py,1570
tests/v1/kv_connector/unit/test_kv_connector_lifecyle.py,1570
tests/reasoning/test_hunyuan_reasoning_parser.py,1570
tests/models/language/pooling/test_token_classification.py,1570
tests/quantization/test_modelopt.py,1569
examples/offline_inference/disaggregated-prefill-v1/prefill_example.py,1568
examples/offline_inference/disaggregated-prefill-v1/decode_example.py,1568
tests/test_logits_processor.py,1567
tests/v1/generation/test_batch_invariance.py,1566
tests/models/multimodal/generation/test_maverick.py,1566
tests/models/language/pooling_mteb_test/test_snowflake_arctic_embed.py,1565
tests/models/language/pooling_mteb_test/test_nomic.py,1565
tests/models/language/pooling_mteb_test/test_intfloat.py,1565
tests/v1/attention/test_attention_backends_selection.py,1564
tests/kernels/test_prefix_prefill.py,1564
tests/entrypoints/openai/test_token_in_token_out.py,1564
tests/models/language/generation/test_bart.py,1563
examples/online_serving/openai_chat_completion_structured_outputs_with_reasoning.py,1563
tests/v1/tpu/test_kv_cache_update_kernel.py,1562
tests/v1/core/test_kv_sharing.py,1562
tests/models/multimodal/processing/test_mllama.py,1561
tests/entrypoints/pooling/llm/test_score.py,1561
examples/online_serving/streamlit_openai_chatbot_webserver.py,1561
tests/v1/kv_connector/unit/test_shared_storage_connector.py,1560
tests/reasoning/test_seedoss_reasoning_parser.py,1560
tests/models/decoder_only/vision_language/test_pixtral.py,1560
vllm/lora/layers/utils.py,1559
vllm/v1/worker/ubatch_splitting.py,1556
examples/offline_inference/qwen_1m.py,1556
vllm/attention/ops/triton_reshape_and_cache_flash.py,1555
tests/v1/tpu/test_tpu_int8.py,1555
tests/models/language/pooling/test_gte.py,1555
tests/reasoning/test_olmo3_reasoning_parser.py,1554
vllm/model_executor/layers/fla/ops/op.py,1553
tests/reasoning/test_glm4_moe_reasoning_parser.py,1553
tests/models/language/pooling/test_auto_prefix_cache_support.py,1553
vllm/model_executor/layers/shared_fused_moe/__init__.py,1552
vllm/entrypoints/cli/__init__.py,1552
tests/plugins_tests/conftest.py,1550
examples/online_serving/openai_transcription_client.py,1550
tests/entrypoints/openai/test_truncation.py,1549
benchmarks/benchmark_dataset.py,1549
tests/distributed/test_expert_placement.py,1548
vllm/v1/executor/utils.py,1547
tests/distributed/test_eplb_algo.py,1546
vllm/config/structured_outputs.py,1545
tests/v1/metrics/test_metrics_reader.py,1545
tests/v1/entrypoints/openai/test_completion_with_image_embeds.py,1545
tests/v1/attention/test_chunked_local_attention.py,1545
tests/kernels/moe/modular_kernel_tools/cli_args.py,1545
tests/distributed/test_node_count.py,1545
tests/core/conftest.py,1545
tests/worker/conftest.py,1543
tests/entrypoints/pooling/openai/test_score.py,1543
tests/entrypoints/openai/conftest.py,1543
tests/distributed/test_shm_storage.py,1543
tests/detokenizer/conftest.py,1543
tests/async_engine/conftest.py,1543
tests/models/decoder_only/vision_language/test_phi3v.py,1542
tests/distributed/test_nccl_symm_mem_allreduce.py,1542
tests/distributed/test_symm_mem_allreduce.py,1541
tests/mq_llm_engine/conftest.py,1540
tests/multimodal/test_audio.py,1539
vllm/model_executor/layers/shared_fused_moe/shared_fused_moe.py,1538
vllm/model_executor/layers/quantization/utils/mxfp8_utils.py,1538
tests/entrypoints/pooling/openai/test_classification.py,1538
examples/offline_inference/context_extension.py,1538
vllm/benchmarks/lib/ready_checker.py,1536
tests/entrypoints/test_context.py,1536
vllm/reasoning/seedoss_reasoning_parser.py,1535
tests/models/multimodal/generation/test_qwen2_5_vl.py,1535
tests/lora/test_gemma.py,1534
tests/kernels/attention/test_encoder_decoder_attn.py,1534
tests/entrypoints/openai/test_default_mm_loras.py,1534
tools/validate_config.py,1533
examples/online_serving/openai_chat_completion_structured_outputs_structural_tag.py,1533
tests/entrypoints/pooling/correctness/test_mteb_score.py,1532
tests/entrypoints/pooling/correctness/test_mteb_embed.py,1532
tests/engine/conftest.py,1532
vllm/model_executor/layers/mamba/mamba2_metadata.py,1531
tests/models/language/pooling/test_snowflake_arctic_embed.py,1531
tests/model_executor/model_loader/test_registry.py,1531
tests/evals/gsm8k/conftest.py,1531
vllm/compilation/post_cleanup.py,1530
tests/entrypoints/pooling/openai/test_embedding_long_text.py,1530
tests/distributed/test_shm_buffer.py,1530
tests/speculative_decoding/speculators/test_eagle3.py,1529
tests/test_envs.py,1528
vllm/model_executor/layers/rotary_embedding/yarn_scaling_rope.py,1527
tests/compile/conftest.py,1527
examples/offline_inference/disaggregated_prefill.py,1527
vllm/model_executor/model_loader/neuronx_distributed.py,1526
vllm/model_executor/layers/quantization/inc.py,1526
tests/tools/test_config_validator.py,1526
tests/neuron/1_core/test_prefix_prefill.py,1526
tests/entrypoints/openai/test_response_api_mcp_tools.py,1526
vllm/model_executor/layers/quantization/utils/nvfp4_moe_support.py,1525
tests/v1/entrypoints/openai/responses/test_basic.py,1525
tests/entrypoints/pooling/openai/test_vision_embedding.py,1525
tests/entrypoints/pooling/openai/test_pooling.py,1525
vllm/entrypoints/tool.py,1524
tests/v1/metrics/test_engine_logger_apis.py,1524
vllm/model_executor/layers/fla/ops/index.py,1523
vllm/lora/layers/qkv_x_parallel_linear.py,1523
examples/online_serving/ray_serve_deepseek.py,1523
examples/offline_inference/rlhf_colocate.py,1523
vllm/reasoning/__init__.py,1522
tests/v1/metrics/test_stats.py,1522
tests/distributed/test_quick_all_reduce.py,1522
vllm/model_executor/models/transformers_moe.py,1521
vllm/model_executor/layers/rotary_embedding/llama3_rope.py,1521
vllm/model_executor/layers/rotary_embedding/dynamic_ntk_scaling_rope.py,1521
vllm/model_executor/layers/rotary_embedding/dynamic_ntk_alpha_rope.py,1521
tests/v1/entrypoints/openai/responses/conftest.py,1521
tests/quantization/reference_mxfp4.py,1521
tests/models/multimodal/pooling/test_clip.py,1521
tests/model_executor/model_loader/test_sharded_state_loader.py,1521
examples/others/lmcache/cpu_offload_lmcache.py,1521
examples/online_serving/openai_classification_client.py,1521
vllm/model_executor/models/ernie45.py,1520
vllm/transformers_utils/configs/speculators/algos.py,1519
tests/v1/kv_connector/nixl_integration/test_disagg_accuracy.py,1519
tests/models/language/pooling/test_nomic.py,1519
tests/kernels/quantization/test_per_token_group_quant.py,1519
tests/kernels/attention/test_flashinfer_mla_decode.py,1519
tests/v1/entrypoints/openai/responses/test_structured_output.py,1518
tests/v1/entrypoints/openai/responses/test_stateful.py,1518
tests/neuron/1_core/test_block_table.py,1518
tests/lora/test_lora_allowed_token_ids.py,1518
tests/kernels/test_attention_selector.py,1518
tests/kernels/quantization/test_hadacore.py,1518
tests/evals/gsm8k/__init__.py,1518
vllm/model_executor/model_loader/online_quantization.py,1517
vllm/attention/backends/cpu_mla.py,1517
tests/v1/e2e/test_context_length.py,1517
tests/entrypoints/pooling/openai/test_truncation.py,1517
vllm/distributed/device_communicators/mnnvl_compat.py,1516
vllm/attention/utils/kv_sharing_utils.py,1516
tests/models/multimodal/generation/test_florence2.py,1516
tests/lora/test_default_mm_loras.py,1516
examples/online_serving/retrieval_augmented_generation_with_llamaindex.py,1516
examples/online_serving/retrieval_augmented_generation_with_langchain.py,1516
examples/others/lmcache/disagg_prefill_lmcache_v1/disagg_proxy_server.py,1515
examples/offline_inference/prompt_embed_inference.py,1515
tests/entrypoints/openai/test_classification.py,1514
tests/config/test_config_generation.py,1514
examples/others/lmcache/kv_cache_sharing_lmcache_v1.py,1514
examples/online_serving/utils.py,1514
examples/offline_inference/batch_llm_inference.py,1514
examples/offline_inference/automatic_prefix_caching.py,1514
vllm/v1/kv_offload/worker/worker.py,1513
tools/profiler/nsys_profile_tools/gputrc2graph.py,1513
tests/v1/kv_offload/test_worker.py,1513
tests/plugins/vllm_add_dummy_platform/vllm_add_dummy_platform/dummy_custom_ops.py,1513
tests/lora/test_transformers_model.py,1513
examples/others/lmcache/disagg_prefill_lmcache_v0.py,1513
vllm/ray/lazy_utils.py,1512
tests/model_executor/model_loader/runai_model_streamer/test_runai_utils.py,1512
tests/distributed/test_torchrun_example_moe.py,1512
tools/generate_cmake_presets.py,1511
tests/utils_/test_tensor_schema.py,1511
tests/utils_/test_gc_utils.py,1511
tests/model_executor/model_loader/fastsafetensors_loader/test_weight_utils.py,1511
tests/evals/gpt_oss/test_gpqa_correctness.py,1511
vllm/worker/multi_step_neuronx_distributed_model_runner.py,1510
vllm/worker/multi_step_neuron_model_runner.py,1510
vllm/v1/kv_offload/backends/cpu.py,1510
vllm/v1/kv_offload/backend.py,1510
vllm/lora/ops/ipex_ops/lora_ops.py,1510
vllm/lora/ops/ipex_ops/__init__.py,1510
vllm/logging_utils/log_time.py,1510
tests/evals/gpt_oss/conftest.py,1510
tests/evals/gpt_oss/__init__.py,1510
tests/entrypoints/openai/test_collective_rpc.py,1510
tests/cuda/test_cuda_context.py,1510
tests/models/language/pooling/test_multilabel_classification_support.py,1509
tests/detokenizer/test_min_tokens.py,1509
vllm/v1/sample/ops/logprobs.py,1508
vllm/model_executor/layers/mamba/ops/layernorm_gated.py,1508
tests/kernels/test_shuffle_rows.py,1508
tests/detokenizer/test_stop_string_while_stop_model_terminates.py,1508
vllm/benchmarks/lib/utils.py,1507
tests/v1/utils.py,1507
tests/v1/distributed/test_hybrid_lb_dp.py,1507
tests/v1/distributed/test_external_lb_dp.py,1507
tests/tool_use/mistral/test_mistral_tool_calls.py,1507
tests/tool_use/mistral/conftest.py,1507
tests/models/multimodal/generation/test_mllama.py,1507
tests/model_executor/model_loader/runai_model_streamer/test_weight_utils.py,1507
tests/models/language/pooling/test_baai.py,1506
tests/spec_decode/test_memory_usage.py,1504
tests/v1/test_async_llm_dp.py,1502
vllm/model_executor/guided_decoding/guidance_decoding.py,1501
vllm/third_party/pynvml.py,1500
vllm/worker/neuronx_distributed_model_runner.py,1499
tests/detokenizer/test_stop_checker.py,1496
benchmarks/kernels/bench_fp8_gemm.py,1496
tests/v1/core/test_specialized_manager.py,1495
tests/models/decoder_only/vision_language/test_qwen2_vl.py,1495
vllm/compilation/cuda_piecewise_backend.py,1490
tests/neuron/1_core/test_neuron_model_runner.py,1490
tests/models/encoder_decoder/vision_language/test_mllama.py,1486
tests/neuron/2_core/test_mistral.py,1485
tests/neuron/1_core/test_rotary_embedding.py,1485
tests/kernels/core/test_opcheck.py,1485
tests/neuron/2_core/test_multi_lora.py,1484
examples/offline_inference/neuron_multimodal.py,1481
tests/neuron/2_core/test_eagle.py,1479
vllm/model_executor/guided_decoding/guidance_logits_processors.py,1478
vllm/distributed/device_communicators/neuron_communicator.py,1478
tests/neuron/1_core/test_neuron_quant.py,1478
tests/neuron/1_core/test_cache.py,1478
tests/neuron/2_core/test_comm_ops.py,1476
tests/neuron/1_core/test_logits_processor.py,1476
tests/neuron/1_core/test_layernorm.py,1476
tests/neuron/1_core/test_activation.py,1476
tests/runai_model_streamer_test/test_runai_model_streamer_loader.py,1475
vllm/model_executor/models/minimax_cache.py,1471
vllm/distributed/kv_transfer/kv_connector/mooncake_store_connector.py,1471
vllm/distributed/kv_transfer/kv_connector/lmcache_connector.py,1469
vllm/compilation/base_piecewise_backend.py,1469
tests/kernels/attention/test_blocksparse_attention.py,1468
tests/models/quantization/test_aqlm.py,1467
tests/engine/test_multi_step_output_processor.py,1467
vllm/distributed/kv_transfer/kv_connector_agent.py,1465
vllm/transformers_utils/configs/skyworkr1v.py,1464
vllm/transformers_utils/configs/minimax_vl_01.py,1463
vllm/transformers_utils/configs/minimax_text_01.py,1463
vllm/worker/multi_step_hpu_worker.py,1459
tests/engine/test_stop_strings.py,1459
examples/offline_inference/basic/basic.py,1459
tests/models/embedding/vision_language/test_llava_next.py,1453
tests/entrypoints/openai/correctness/test_mteb.py,1453
tests/kernels/test_cutlass_mla_decode.py,1451
examples/offline_inference/reproducibility.py,1451
tests/fastsafetensors_loader/test_fastsafetensors_loader.py,1449
vllm/transformers_utils/chat_templates/__init__.py,1448
tests/v1/shutdown/utils.py,1446
tests/kernels/quantization/test_aqlm.py,1446
vllm/worker/openvino_worker.py,1444
tests/engine/test_options.py,1444
tests/build_cython.py,1444
.buildkite/lm-eval-harness/conftest.py,1444
vllm/jsontree.py,1443
tests/kv_transfer/test_disagg.py,1443
vllm/benchmarks/endpoint_request_func.py,1441
tests/models/decoder_only/language/test_gguf.py,1441
tests/fastsafetensors_loader/test_weight_utils.py,1441
tests/v1/test_metrics_reader.py,1440
tests/models/decoder_only/vision_language/vlm_utils/core.py,1440
examples/offline_inference/metrics.py,1440
examples/online_serving/openai_embedding_matryoshka_fy.py,1439
vllm/benchmarks/utils.py,1438
tests/models/language/generation/test_granitemoehybrid.py,1438
tests/mistral_tool_use/test_mistral_tool_calls.py,1438
tests/mistral_tool_use/conftest.py,1438
tests/models/embedding/vision_language/test_phi3v.py,1436
tests/kernels/test_flashinfer.py,1436
tests/model_executor/test_logits_processor.py,1432
tests/runai_model_streamer_test/test_weight_utils.py,1431
tests/models/embedding/utils.py,1427
tests/lora/data/long_context_test_data.py,1427
tests/models/decoder_only/vision_language/test_awq.py,1417
tests/kernels/test_gguf.py,1417
tests/models/decoder_only/vision_language/vlm_utils/types.py,1407
benchmarks/kernels/benchmark_reshape_and_cache_flash.py,1394
vllm/v1/stats/common.py,1383
tests/kernels/test_layernorm.py,1372
tests/models/decoder_only/vision_language/vlm_utils/case_filtering.py,1367
tests/models/embedding/vision_language/test_dse_qwen2_vl.py,1364
tests/models/embedding/language/test_gritlm.py,1364
tests/models/decoder_only/vision_language/vlm_utils/builders.py,1359
tests/models/decoder_only/vision_language/vlm_utils/runners.py,1355
tests/models/encoder_decoder/vision_language/test_florence2.py,1340
benchmarks/benchmark_guided.py,1339
tests/kernels/test_triton_scaled_mm.py,1338
tests/kernels/test_machete_mm.py,1337
vllm/entrypoints/openai/reasoning_parsers/deepseek_r1_reasoning_parser.py,1335
tests/lora/test_lora_bias_e2e.py,1335
tests/models/encoder_decoder/language/test_bart.py,1333
vllm/entrypoints/openai/reasoning_parsers/abs_reasoning_parsers.py,1332
tests/kernels/test_cascade_flash_attn.py,1331
tests/models/decoder_only/language/test_modelopt.py,1330
tests/kernels/test_cutlass_2of4_sparse.py,1330
tests/kernels/test_fused_quant_layernorm.py,1329
tests/entrypoints/openai/reasoning_parsers/test_deepseekr1_reasoning_parser.py,1328
tests/entrypoints/openai/reasoning_parsers/utils.py,1325
vllm/transformers_utils/tokenizer_group/__init__.py,1320
tests/lora/test_jamba.py,1317
benchmarks/benchmark_serving_guided.py,1317
vllm/transformers_utils/tokenizer_group/ray_tokenizer_group.py,1314
examples/offline_inference/distributed.py,1311
vllm/platforms/openvino.py,1310
vllm/model_executor/model_loader/openvino.py,1288
vllm/transformers_utils/tokenizer_group/tokenizer_group.py,1287
tests/models/embedding/language/test_embedding.py,1285
tests/kernels/test_mamba_ssm.py,1278
tests/kernels/test_int8_quant.py,1276
docs/source/models/supported_models.md,1272
examples/offline_inference/vision_language_pooling.py,1259
vllm/model_executor/models/glm4_vision_encoder.py,1242
docs/contributing/model/transcription.md,1239
vllm/attention/backends/registry.py,1234
tests/kernels/test_marlin_gemm.py,1229
tests/compile/utils.py,1228
tests/models/decoder_only/language/test_mamba.py,1226
tests/models/decoder_only/language/test_models.py,1224
tests/multimodal/test_processor_kwargs.py,1217
tests/kernels/conftest.py,1209
benchmarks/kernels/bench_per_token_quant_fp8.py,1206
vllm/model_executor/models/xverse.py,1205
benchmarks/kernels/benchmark_reshape_and_cache.py,1197
docs/contributing/model/multimodal.md,1193
tests/engine/output_processor/test_multi_step.py,1192
collect_env.py,1182
tests/models/embedding/language/test_cls_models.py,1178
vllm/v1/attention/backends/rocm_aiter_unified_attn.py,1174
tests/kernels/test_causal_conv1d.py,1170
tests/models/decoder_only/language/test_fp8.py,1168
tests/kernels/test_fp8_quant.py,1164
tests/engine/test_skip_tokenizer_init.py,1147
tests/models/decoder_only/language/test_mistral.py,1140
vllm/transformers_utils/tokenizer_group/base_tokenizer_group.py,1137
tests/engine/test_custom_executor.py,1132
benchmarks/kernels/benchmark_trtllm_prefill_attention.py,1127
benchmarks/kernels/benchmark_trtllm_decode_attention.py,1123
vllm/v1/engine/mm_input_mapper.py,1118
vllm/profiler/__init__.py,1118
tests/models/decoder_only/language/test_jamba.py,1115
vllm/executor/gpu_executor.py,1107
tests/kernels/test_block_fp8.py,1099
tests/models/decoder_only/language/test_granite.py,1097
tests/kernels/test_awq_triton.py,1095
tests/models/embedding/language/test_scoring.py,1093
tests/engine/test_detokenization.py,1091
vllm/model_executor/layers/quantization/quark/schemes/quark_ocp_mx.py,1090
vllm/lora/ops/triton_ops/sgmv_shrink.py,1090
vllm/lora/ops/triton_ops/sgmv_expand.py,1090
vllm/attention/backends/openvino.py,1090
tests/model_executor/weight_utils.py,1090
tests/kernels/test_utils.py,1090
tests/entrypoints/openai/test_accuracy.py,1089
docs/source/models/supported_models.rst,1088
tests/models/encoder_decoder/vision_language/test_broadcast.py,1087
benchmarks/kernels/benchmark_device_communicators.py,1087
vllm/attention/backends/mla/utils.py,1084
tests/engine/test_stop_reason.py,1084
vllm/model_executor/layers/quantization/fp_quant.py,1082
tests/models/decoder_only/vision_language/test_h2ovl.py,1080
tests/kernels/test_awq.py,1080
tests/kernels/test_awq_marlin.py,1073
examples/offline_inference/florence2_inference.py,1072
vllm/compilation/reshapes.py,1068
tests/kv_transfer/disagg_test.py,1064
vllm/executor/ray_gpu_executor.py,1062
tests/models/decoder_only/vision_language/vlm_utils/custom_inputs.py,1062
vllm/transformers_utils/dynamic_module.py,1056
examples/online_serving/structured_outputs/structured_outputs.py,1056
tests/engine/output_processor/test_stop_checker.py,1054
vllm/transformers_utils/configs/lfm2_moe.py,1053
vllm/model_executor/models/deepseek_v3.py,1051
tests/kernels/test_ggml.py,1051
tests/models/decoder_only/vision_language/test_intern_vit.py,1050
tests/models/encoder_decoder/audio_language/test_whisper.py,1046
examples/offline_inference/gguf_inference.py,1045
tests/entrypoints/llm/test_init.py,1044
vllm/distributed/kv_transfer/kv_transfer_agent.py,1043
tests/kv_transfer/module_test.py,1043
tests/kernels/test_triton_decode_attention.py,1041
tests/models/decoder_only/language/test_phimoe.py,1040
tests/models/decoder_only/language/test_gptq_marlin_24.py,1039
tests/models/decoder_only/language/test_gptq_marlin.py,1039
python_only_dev.py,1039
examples/offline_inference/scoring.py,1039
examples/offline_inference/embedding.py,1039
examples/offline_inference/cpu_offload.py,1039
examples/offline_inference/cli.py,1039
examples/offline_inference/classification.py,1039
examples/offline_inference/chat.py,1039
examples/offline_inference/basic_with_model_default_sampling.py,1039
examples/offline_inference/arctic.py,1039
examples/offline_inference/aqlm_example.py,1039
tests/kernels/test_permute_cols.py,1037
tests/kernels/test_rotary_embedding.py,1036
tests/kernels/test_gptq.py,1036
tests/kernels/test_aqlm.py,1036
vllm/entrypoints/openai/reasoning_parsers/__init__.py,1033
tests/models/decoder_only/language/test_aqlm.py,1031
vllm/entrypoints/openai/serving_rerank.py,1029
docs/contributing/model/basic.md,1028
examples/other/tensorize_vllm_model.py,1026
vllm/lora/ops/triton_ops/bgmv_shrink.py,1025
vllm/lora/ops/triton_ops/bgmv_expand_slice.py,1025
vllm/lora/ops/triton_ops/bgmv_expand.py,1025
tests/neuron/test_prefix_prefill.py,1024
tests/runai_model_streamer/test_weight_utils.py,1023
tests/runai_model_streamer/test_runai_model_streamer_loader.py,1023
examples/offline_inference/pixtral.py,1023
vllm/transformers_utils/configs/olmo2.py,1021
vllm/v1/worker/dp_utils.py,1017
tests/v1/test_stats.py,1016
examples/online_serving/multi_instance_data_parallel.py,1016
vllm/triton_utils/custom_cache_manager.py,1015
examples/offline_inference/whisper.py,1015
tests/lora/test_punica_ops_variation.py,1014
tests/lora/test_punica_ops_sizes.py,1014
tests/kernels/test_mha_attn.py,1013
tests/standalone_tests/lazy_torch_compile.py,1011
examples/offline_inference/basic.py,1011
benchmarks/multi_turn/benchmark_serving_multi_turn.py,1011
docs/design/logits_processors.md,991
tests/kernels/moe/test_ocp_mx_moe.py,989
vllm/executor/cpu_executor.py,978
vllm/compilation/base_static_graph.py,978
examples/online_serving/pooling/openai_chat_embedding_client_for_multimodal.py,978
docs/features/custom_logitsprocs.md,976
vllm/compilation/partition_rules.py,974
vllm/model_executor/layers/fused_moe/shared_fused_moe.py,973
vllm/model_executor/models/paddleocr_vl.py,970
.gitignore,970
examples/offline_inference/logits_processor/custom.py,966
examples/offline_inference/kv_load_failure_recovery/rogue_shared_storage_connector.py,966
examples/offline_inference/logits_processor/custom_req_init.py,965
examples/offline_inference/logits_processor/custom_req.py,965
tests/ci_envs.py,964
vllm/model_executor/layers/quantization/utils/ocp_mx_utils.py,960
format.sh,959
benchmarks/kernels/benchmark_per_token_group_quant.py,958
benchmarks/multi_turn/bench_dataset.py,952
vllm/utils/cache.py,950
vllm/model_executor/models/flex_olmo.py,950
vllm/config/speech_to_text.py,950
benchmarks/multi_turn/convert_sharegpt_to_openai.py,949
vllm/config/kv_events.py,947
examples/online_serving/pooling/cohere_rerank_client.py,943
docs/serving/openai_compatible_server.md,930
docs/source/serving/openai_compatible_server.md,911
docs/source/index.rst,893
csrc/cache_kernels.cu,886
vllm/model_executor/models/openpangu.py,881
vllm/model_executor/models/ouro.py,867
vllm/model_executor/models/deepseek_ocr.py,837
docs/source/index.md,820
Dockerfile,805
docs/source/contributing/model/multimodal.md,735
docs/features/multimodal_inputs.md,722
docs/features/reasoning_outputs.md,719
vllm/worker/embedding_model_runner.py,682
vllm/model_executor/models/afmoe.py,678
vllm/model_executor/models/minimax_m2.py,664
docs/deployment/docker.md,662
docs/features/tool_calling.md,650
docs/source/getting_started/quickstart.md,644
README.md,643
.buildkite/run-cpu-test.sh,641
docs/api/README.md,636
docs/source/models/pooling_models.md,631
vllm/v1/engine/input_processor.py,628
requirements/test.in,622
requirements/test.txt,621
docs/models/pooling_models.md,612
vllm/model_executor/models/hunyuan_vision.py,605
docs/source/models/generative_models.md,605
docs/design/plugin_system.md,603
.github/CODEOWNERS,588
csrc/cache.h,580
vllm/executor/neuron_executor.py,577
tests/entrypoints/test_openai_server.py,575
.buildkite/test-amd.yaml,570
csrc/moe/torch_bindings.cpp,568
vllm/model_executor/model_loader.py,561
requirements-dev.txt,554
docs/source/features/structured_outputs.md,546
vllm/model_executor/models/transformers/base.py,543
tests/compile/test_qk_norm_rope_fusion.py,538
docs/models/generative_models.md,537
docs/README.md,533
requirements-common.txt,532
csrc/attention/attention_kernels.cu,530
docs/getting_started/quickstart.md,523
docs/features/lora.md,520
vllm/model_executor/models/isaac.py,519
vllm/model_executor/models/kimi_linear.py,518
docs/source/serving/distributed_serving.md,513
docs/features/quantization/int4.md,511
docker/Dockerfile,509
vllm/entrypoints/pooling/score/serving.py,503
docs/features/compatibility_matrix.md,500
docs/features/quantization/quark.md,499
csrc/quantization/gptq_marlin/gptq_marlin.cu,494
docs/source/getting_started/installation.rst,491
.github/workflows/mypy.yaml,488
docs/features/quantization/README.md,484
docs/features/structured_outputs.md,479
.github/mergify.yml,474
vllm/model_executor/models/nemotron_parse.py,472
vllm/entrypoints/pooling/pooling/serving.py,467
docs/getting_started/installation/cpu.md,465
vllm/model_executor/models/glmasr.py,462
docs/features/quantization/int8.md,458
docs/features/quantization/fp8.md,457
requirements/docs.txt,456
docs/.nav.yml,452
csrc/cpu/torch_bindings.cpp,451
requirements/common.txt,450
csrc/pybind.cpp,449
vllm/tokenizers/registry.py,448
docs/deployment/frameworks/helm.md,443
docs/features/quantization/quantized_kvcache.md,441
docs/usage/troubleshooting.md,439
vllm/core/block_manager_v2.py,438
docs/source/features/compatibility_matrix.md,438
csrc/cpu/attention.cpp,437
vllm/model_executor/weight_utils.py,434
docs/source/getting_started/installation.md,434
docs/contributing/model/README.md,431
docs/usage/v1_guide.md,428
docs/source/contributing/profiling/profiling_index.md,424
docs/requirements-docs.txt,422
vllm/model_executor/models/mistral.py,421
tests/models/test_llava.py,420
vllm/model_executor/layers/attention.py,417
vllm/model_executor/models/qwen2_cls.py,416
docs/features/quantization/supported_hardware.md,412
tests/core/test_block_manager.py,410
docs/source/models/vlm.rst,410
docs/source/models/adding_model.rst,410
.readthedocs.yaml,410
docs/features/spec_decode.md,404
tests/lora/test_llama.py,401
docs/getting_started/installation/README.md,399
vllm/model_executor/models/mimo_v2_flash.py,398
docs/design/arch_overview.md,396
docs/configuration/conserving_memory.md,396
csrc/layernorm_kernels.cu,396
docs/deployment/frameworks/haystack.md,395
docs/deployment/k8s.md,394
vllm/model_executor/models/aquila.py,391
vllm/engine/ray_utils.py,389
csrc/activation_kernels.cu,387
.github/workflows/ruff.yml,386
docs/source/deployment/docker.md,385
vllm/model_executor/models/internlm.py,379
vllm/model_executor/parallel_utils/communication_op.py,378
docs/source/features/reasoning_outputs.md,378
cmake/cpu_extension.cmake,374
docs/contributing/benchmarks.md,373
vllm/model_executor/models/openpangu_mtp.py,372
docs/source/dev/multimodal/multimodal_index.rst,372
docs/source/contributing/dockerfile/dockerfile.md,370
docs/source/serving/multimodal_inputs.md,367
docs/deployment/nginx.md,364
vllm/executor/multiproc_gpu_executor.py,362
docs/features/quantization/bitblas.md,362
docs/deployment/frameworks/skypilot.md,362
vllm/model_executor/models/transformers/multimodal.py,361
csrc/pos_encoding_kernels.cu,361
vllm/model_executor/models/iquest_loopcoder.py,360
docs/getting_started/installation/gpu.md,359
docs/deployment/frameworks/retrieval_augmented_generation.md,359
examples/llm_engine_example.py,357
docs/source/features/quantization/index.md,356
docs/features/quantization/gptqmodel.md,356
docs/features/quantization/gguf.md,356
docs/features/quantization/auto_awq.md,356
docs/deployment/frameworks/cerebrium.md,356
vllm/reasoning/minimax_m2_reasoning_parser.py,355
vllm/model_executor/layers/quantization/squeezellm.py,354
docs/deployment/integrations/production-stack.md,352
docs/source/contributing/model/index.md,351
vllm/v1/core/scheduler_output.py,350
vllm/executor/xpu_executor.py,348
vllm/model_executor/layers/mamba/abstract.py,347
vllm/model_executor/layers/fused_moe/unquantized_fused_moe_method.py,347
docs/source/deployment/frameworks/index.md,347
requirements-test.txt,346
docs/deployment/frameworks/autogen.md,343
Dockerfile.rocm,343
vllm/executor/openvino_executor.py,342
docs/deployment/frameworks/litellm.md,341
tests/models/test_marlin.py,340
tests/models/multimodal/processing/test_transformers.py,339
docs/source/getting_started/quickstart.rst,339
docs/serving/integrations/langchain.md,339
docs/Makefile,337
docs/deployment/frameworks/dstack.md,336
tests/compile/distributed/test_sequence_parallelism.py,334
docs/source/models/extensions/index.md,333
docs/design/mm_processing.md,331
docs/source/getting_started/installation/cpu/x86.inc.md,327
csrc/cpu/cache.cpp,327
tests/tool_use/test_ernie45_moe_tool_parser.py,326
docs/source/serving/metrics.md,326
docs/source/deployment/integrations/index.md,326
docs/source/serving/integrations/index.md,323
benchmarks/kernels/benchmark_mrope.py,322
vllm/model_executor/models/phi4flash.py,321
docs/source/autodoc2_docstring_parser.py,317
docs/source/api/summary.md,317
docs/getting_started/installation/intel_gaudi.md,317
vllm/model_executor/input_metadata.py,316
vllm/executor/distributed_gpu_executor.py,316
tests/kernels/test_mamba_ssm_ssd.py,315
tests/kernels/test_mamba_mixer2.py,315
tests/entrypoints/openai/tool_parsers/test_olmo3_tool_parser.py,313
docs/models/extensions/runai_model_streamer.md,313
docs/source/serving/engine_args.md,312
docs/source/serving/offline_inference.md,310
docs/contributing/model/registration.md,310
tests/neuron/test_logits_processor.py,307
tests/lora/test_ultravox.py,306
docs/contributing/profiling.md,306
vllm/executor/tpu_executor.py,305
docs/source/features/quantization/supported_hardware.md,305
tests/lora/test_layer_variation.py,304
vllm/core/block_manager_v1.py,303
docs/features/disagg_prefill.md,301
docs/deployment/frameworks/streamlit.md,300
docs/design/moe_kernel_features.md,299
docs/source/models/enabling_multimodal_inputs.rst,297
vllm/model_executor/models/deepencoder.py,296
docs/source/deployment/frameworks/helm.md,296
vllm/v1/worker/gpu/attn_utils.py,294
vllm/model_executor/models/opencua.py,293
vllm/model_executor/models/lfm2_vl.py,293
tests/v1/engine/test_process_multi_modal_uuids.py,292
docs/source/design/kernel/paged_attention.md,289
examples/offline_inference_vision_language.py,288
docs/source/design/arch_overview.md,288
.buildkite/run-xpu-test.sh,288
docs/design/io_processor_plugins.md,285
vllm/v1/attention/backends/mla/rocm_aiter_mla_sparse.py,284
docs/source/serving/env_vars.md,284
vllm/model_executor/models/yi.py,282
docs/deployment/frameworks/dify.md,281
docs/deployment/frameworks/chatbox.md,281
docs/deployment/frameworks/anything-llm.md,279
csrc/dispatch_utils.h,279
vllm/model_executor/models/bagel.py,278
docs/serving/distributed_serving.md,278
tests/entrypoints/test_guided_processors.py,277
docs/contributing/model/tests.md,276
csrc/quantization/marlin/dense/marlin_cuda_kernel.cu,276
csrc/rocm/attention.cu,274
mkdocs.yaml,272
vllm/model_executor/models/molmo2.py,271
examples/offline_inference/spec_decode.py,271
tests/v1/kv_connector/unit/test_backwards_compatibility.py,270
tests/config/test_multimodal_config.py,269
csrc/moe/moe_ops.h,269
tests/v1/attention/test_rocm_attention_backends_selection.py,268
docs/deployment/frameworks/lws.md,268
docs/source/contributing/overview.md,267
vllm/distributed/kv_transfer/kv_connector/v1/mooncake_connector.py,266
requirements.txt,266
docs/design/kernel/paged_attention.md,266
requirements/nightly_torch_test.txt,265
csrc/quantization/cutlass_w8a8/scaled_mm_entry.cu,265
.github/workflows/publish.yml,265
docs/features/quantization/bnb.md,263
vllm/model_executor/models/whisper_utils.py,262
docs/source/getting_started/cpu-installation.rst,262
vllm/model_executor/models/voxtral_streaming.py,261
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/vllm_v1_adapter.py,261
tests/async_engine/test_chat_template.py,260
benchmarks/kernels/benchmark_activation.py,260
docs/usage/metrics.md,259
docs/configuration/optimization.md,259
benchmarks/kernels/benchmark_cutlass_moe_fp8.py,259
vllm/model_executor/neuron_model_loader.py,258
vllm/model_executor/models/audioflamingo3.py,258
vllm/distributed/kv_transfer/kv_connector/v1/decode_bench_connector.py,258
tests/compile/fullgraph/test_full_graph.py,257
.buildkite/scripts/hardware_ci/run-cpu-test.sh,257
.buildkite/run-openvino-test.sh,257
docs/source/getting_started/installation/cpu/arm.inc.md,256
vllm/utils/torch_utils.py,255
tests/models/test_llava_next.py,255
tests/distributed/test_basic_distributed_correctness.py,254
docs/features/quantization/torchao.md,254
tests/async_engine/test_openapi_server_ray.py,252
vllm/model_executor/models/plamo3.py,251
vllm/model_executor/models/kanana_v.py,251
vllm/entrypoints/pooling/classify/serving.py,250
docs/source/getting_started/amd-installation.rst,250
docs/models/hardware_supported_models/tpu.md,250
vllm/entrypoints/pooling/embed/protocol.py,249
vllm/entrypoints/openai/parser/responses_parser.py,249
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_mp_connector.py,249
docs/design/custom_op.md,249
vllm/lora/punica.py,248
docs/assets/contributing/dockerfile-stages-dependency.png,246
vllm/entrypoints/sagemaker/routes.py,243
tests/models/multimodal/generation/test_vit_backend_functionality.py,243
tests/kernels/test_sampler.py,242
csrc/cpu/cpu_types_x86.hpp,242
tests/models/test_phi3v.py,240
docs/source/models/adding_model.md,240
.buildkite/run-neuron-test.sh,240
docs/deployment/frameworks/open-webui.md,239
benchmarks/README.md,239
.github/workflows/yapf.yml,239
docs/getting_started/installation/cpu/arm.inc.md,238
vllm/entrypoints/pooling/embed/serving.py,237
docs/getting_started/installation/cpu/x86.inc.md,237
docs/source/getting_started/installation/ai_accelerator.md,236
docs/source/features/quantization/auto_awq.md,236
cacheflow/worker/worker.py,236
.buildkite/release-pipeline.yaml,236
examples/offline_inference_distributed.py,234
vllm/tokenizers/__init__.py,233
tools/mypy.sh,233
tests/v1/structured_output/test_reasoning_structured_output.py,232
examples/multilora_inference.py,232
docs/source/getting_started/troubleshooting.md,232
docs/getting_started/installation/.nav.yml,232
vllm/executor/ray_xpu_executor.py,231
docs/source/features/lora.md,231
.buildkite/run-gh200-test.sh,231
docs/source/deployment/frameworks/skypilot.md,230
vllm/config/attention.py,229
tests/models/decoder_only/vision_language/mm_processor_kwargs/test_qwen.py,229
tests/compile/fullgraph/test_full_cudagraph.py,229
examples/llava_example.py,229
docs/features/automatic_prefix_caching.md,229
csrc/moe/topk_softmax_kernels.cu,229
cmake/utils.cmake,229
vllm/entrypoints/serve/tokenize/serving.py,228
vllm/reasoning/deepseek_v3_reasoning_parser.py,226
tests/distributed/test_multimodal_broadcast.py,226
csrc/reduction_utils.cuh,226
Dockerfile.cpu,226
vllm/model_executor/models/transformers/moe.py,225
vllm/entrypoints/pooling/pooling/protocol.py,225
docs/make.bat,225
docs/source/_templates/sections/header.html,224
.buildkite/test_areas/kernels.yaml,224
.buildkite/run-hpu-test.sh,224
tests/compile/test_fusions_e2e.py,223
docs/source/contributing/model/basic.md,223
docs/source/api/model/index.md,223
tests/entrypoints/openai/test_chat_error.py,222
docs/getting_started/installation/ai_accelerator.md,222
docs/design/cuda_graphs.md,222
docker/Dockerfile.cpu,222
.buildkite/run-tpu-test.sh,222
vllm/v1/attention/backends/flash_attn_diffkv.py,221
docs/source/models/pooling_models.rst,221
docs/source/features/disagg_prefill.md,221
docs/source/_static/custom.css,221
docs/configuration/engine_args.md,221
vllm/model_executor/guided_logits_processors.py,220
vllm/model_executor/guided_decoding.py,220
docs/source/serving/serve_args.md,220
.github/workflows/lint-and-deploy.yaml,220
vllm/model_executor/layers/kda.py,219
vllm/entrypoints/pooling/classify/protocol.py,219
docs/source/community/blog.md,218
docs/serving/offline_inference.md,218
docs/{source/contributing/profiling/profiling_index.md => contributing/profiling.md},217
docs/{source/_static/custom.js => mkdocs/javascript/run_llm_widget.js},217
docs/{source => }/training/trl.md,217
docs/{source => }/training/rlhf.md,217
docs/{source => }/serving/usage_stats.md,217
docs/{source => }/serving/openai_compatible_server.md,217
docs/{source => }/serving/offline_inference.md,217
docs/{source => }/serving/metrics.md,217
docs/{source => }/serving/integrations/llamaindex.md,217
docs/{source => }/serving/integrations/langchain.md,217
docs/{source => }/serving/distributed_serving.md,217
docs/{source => }/performance/optimization.md,217
docs/{source => }/performance/benchmarks.md,217
docs/{source => }/models/pooling_models.md,217
docs/{source => }/models/generative_models.md,217
docs/{source => }/models/extensions/tensorizer.md,217
docs/{source => }/models/extensions/runai_model_streamer.md,217
docs/{source => }/models/extensions/fastsafetensor.md,217
docs/{source => }/getting_started/v1_user_guide.md,217
docs/{source => }/getting_started/troubleshooting.md,217
docs/{source => }/getting_started/quickstart.md,217
docs/{source => }/getting_started/installation/python_env_setup.inc.md,217
docs/{source => }/getting_started/installation/gpu/xpu.inc.md,217
docs/{source => }/getting_started/installation/gpu/rocm.inc.md,217
docs/{source => }/getting_started/installation/gpu/cuda.inc.md,217
docs/{source => }/getting_started/installation/device.template.md,217
docs/{source => }/getting_started/installation/cpu/s390x.inc.md,217
docs/{source => }/getting_started/installation/cpu/build.inc.md,217
docs/{source => }/getting_started/installation/cpu/apple.inc.md,217
docs/{source => }/getting_started/installation/cpu.md,217
docs/{source => }/getting_started/installation/ai_accelerator/tpu.inc.md,217
docs/{source => }/getting_started/installation/ai_accelerator/neuron.inc.md,217
docs/{source => }/getting_started/installation/ai_accelerator/hpu-gaudi.inc.md,217
docs/{source => }/getting_started/faq.md,217
docs/{source => }/features/tool_calling.md,217
docs/{source => }/features/structured_outputs.md,217
docs/{source => }/features/spec_decode.md,217
docs/{source => }/features/reasoning_outputs.md,217
docs/{source => }/features/quantization/torchao.md,217
docs/{source => }/features/quantization/quark.md,217
docs/{source => }/features/quantization/quantized_kvcache.md,217
docs/{source => }/features/quantization/modelopt.md,217
docs/{source => }/features/quantization/int8.md,217
docs/{source => }/features/quantization/int4.md,217
docs/{source => }/features/quantization/gptqmodel.md,217
docs/{source => }/features/quantization/gguf.md,217
docs/{source => }/features/quantization/fp8.md,217
docs/{source => }/features/quantization/bnb.md,217
docs/{source => }/features/quantization/bitblas.md,217
docs/{source => }/features/quantization/auto_awq.md,217
docs/{source => }/features/prompt_embeds.md,217
docs/{source => }/features/multimodal_inputs.md,217
docs/{source => }/features/lora.md,217
docs/{source => }/features/disagg_prefill.md,217
docs/{source => }/features/automatic_prefix_caching.md,217
docs/{source => }/design/v1/torch_compile.md,217
docs/{source => }/design/v1/prefix_caching.md,217
docs/{source => }/design/v1/metrics.md,217
docs/{source => }/design/plugin_system.md,217
docs/{source => }/design/multiprocessing.md,217
docs/{source => }/design/mm_processing.md,217
docs/{source => }/design/kernel/paged_attention.md,217
docs/{source => }/design/huggingface_integration.md,217
docs/{source => }/design/automatic_prefix_caching.md,217
docs/{source => }/design/arch_overview.md,217
docs/{source => }/deployment/security.md,217
docs/{source => }/deployment/nginx.md,217
docs/{source => }/deployment/k8s.md,217
docs/{source => }/deployment/integrations/production-stack.md,217
docs/{source => }/deployment/integrations/llmaz.md,217
docs/{source => }/deployment/integrations/llamastack.md,217
docs/{source => }/deployment/integrations/kubeai.md,217
docs/{source => }/deployment/integrations/kserve.md,217
docs/{source => }/deployment/frameworks/triton.md,217
docs/{source => }/deployment/frameworks/streamlit.md,217
docs/{source => }/deployment/frameworks/skypilot.md,217
docs/{source => }/deployment/frameworks/retrieval_augmented_generation.md,217
docs/{source => }/deployment/frameworks/open-webui.md,217
docs/{source => }/deployment/frameworks/modal.md,217
docs/{source => }/deployment/frameworks/lws.md,217
docs/{source => }/deployment/frameworks/lobe-chat.md,217
docs/{source => }/deployment/frameworks/litellm.md,217
docs/{source => }/deployment/frameworks/dstack.md,217
docs/{source => }/deployment/frameworks/dify.md,217
docs/{source => }/deployment/frameworks/chatbox.md,217
docs/{source => }/deployment/frameworks/cerebrium.md,217
docs/{source => }/deployment/frameworks/bentoml.md,217
docs/{source => }/deployment/frameworks/anything-llm.md,217
docs/{source => }/contributing/vulnerability_management.md,217
docs/{source => }/contributing/overview.md,217
docs/{source => }/contributing/model/tests.md,217
docs/{source => }/contributing/model/registration.md,217
docs/{source => }/contributing/model/basic.md,217
docs/{source => }/contributing/dockerfile/dockerfile.md,217
docs/{source => }/contributing/deprecation_policy.md,217
docs/{source => }/community/sponsors.md,217
docs/{source => }/community/meetups.md,217
docs/{source => }/assets/logos/vllm-logo-text-light.png,217
docs/{source => }/assets/logos/vllm-logo-text-dark.png,217
docs/{source => }/assets/logos/vllm-logo-only-light.png,217
docs/{source => }/assets/logos/vllm-logo-only-light.ico,217
docs/{source => }/assets/kernel/value.png,217
docs/{source => }/assets/kernel/v_vec.png,217
docs/{source => }/assets/kernel/query.png,217
docs/{source => }/assets/kernel/q_vecs.png,217
docs/{source => }/assets/kernel/logits_vec.png,217
docs/{source => }/assets/kernel/key.png,217
docs/{source => }/assets/kernel/k_vecs.png,217
docs/{source => }/assets/features/disagg_prefill/overview.jpg,217
docs/{source => }/assets/features/disagg_prefill/abstraction.jpg,217
docs/{source => }/assets/design/v1/prefix_caching/overview.png,217
docs/{source => }/assets/design/v1/prefix_caching/free.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-7.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-6.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-5.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-4.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-3.png,217
docs/{source => }/assets/design/v1/prefix_caching/example-time-1.png,217
docs/{source => }/assets/design/v1/metrics/intervals-3.png,217
docs/{source => }/assets/design/v1/metrics/intervals-2.png,217
docs/{source => }/assets/design/v1/metrics/intervals-1.png,217
docs/{source => }/assets/design/hierarchy.png,217
docs/{source => }/assets/design/arch_overview/llm_engine.excalidraw.png,217
docs/{source => }/assets/design/arch_overview/entrypoints.excalidraw.png,217
docs/{source => }/assets/deployment/streamlit-chat.png,217
docs/{source => }/assets/deployment/open_webui.png,217
docs/{source => }/assets/deployment/dify-settings.png,217
docs/{source => }/assets/deployment/dify-create-chatbot.png,217
docs/{source => }/assets/deployment/dify-chat.png,217
docs/{source => }/assets/deployment/chatbox-settings.png,217
docs/{source => }/assets/deployment/chatbox-chat.png,217
docs/{source => }/assets/deployment/architecture_helm_deployment.png,217
docs/{source => }/assets/deployment/anything-llm-upload-doc.png,217
docs/{source => }/assets/deployment/anything-llm-provider.png,217
docs/{source => }/assets/deployment/anything-llm-chat-without-doc.png,217
docs/{source => }/assets/deployment/anything-llm-chat-with-doc.png,217
docs/source/usage/structured_outputs.md,217
docs/source/usage/spec_decode.md,217
docs/source/getting_started/installation/gpu.md,217
docs/serving/serve_args.md,217
docs/serving/integrations/llamaindex.md,217
docs/serving/env_vars.md,217
docs/serving/engine_args.md,217
docs/mkdocs/overrides/main.html,217
docs/deployment/integrations/llamastack.md,217
docs/api/vllm/.meta.yml,217
docs/models/extensions/tensorizer.md,216
csrc/quantization/marlin/sparse/marlin_24_cuda_kernel.cu,216
vllm/model_executor/models/phi_1_5.py,215
docs/source/quantization/fp8_e4m3_kvcache.rst,215
csrc/attention/dtype_bfloat16.cuh,215
vllm/entrypoints/pooling/score/protocol.py,214
csrc/attention/attention_utils.cuh,214
docs/source/getting_started/tpu-installation.md,213
docs/source/getting_started/gaudi-installation.md,213
tests/v1/determinism/utils.py,212
vllm/entrypoints/serve/elastic_ep/api_router.py,211
tests/weight_loading/models.txt,211
tests/entrypoints/openai/test_completion_error.py,211
tests/v1/structured_output/test_backend_guidance.py,210
docs/source/getting_started/installation/cpu-x86.md,210
docs/source/dev/offline_inference/offline_index.md,210
csrc/quantization/fp8/common.cu,209
vllm/config/renderer.py,208
tests/tokenizers_/test_registry.py,208
docs/source/getting_started/cpu-installation.md,208
docs/source/dev/offline_inference/offline_index.rst,208
vllm/model_executor/layers/ops/sample.py,207
vllm/distributed/kv_transfer/kv_connector/v1/example_connector.py,207
vllm/entrypoints/serve/tokenize/api_router.py,206
vllm/entrypoints/serve/disagg/api_router.py,206
tests/reasoning/test_deepseekv3_reasoning_parser.py,206
docs/getting_started/installation/gpu/rocm.inc.md,206
docs/design/fused_moe_modular_kernel.md,206
csrc/cuda_utils.h,206
csrc/attention/dtype_float16.cuh,206
docs/source/serving/integrations.md,205
docs/source/getting_started/tpu-installation.rst,205
vllm/model_executor/models/eagle2_5_vl.py,204
docs/source/getting_started/xpu-installation.rst,204
vllm/reasoning/identity_reasoning_parser.py,203
vllm/distributed/kv_transfer/kv_connector/v1/moriio/moriio_connector.py,203
vllm/tokenizers/mistral.py,202
tests/multimodal/test_mapper.py,202
docs/source/getting_started/debugging.md,201
docs/source/features/spec_decode.md,201
vllm/model_executor/models/siglip2.py,199
vllm/executor/ray_tpu_executor.py,199
tests/kernels/attention/test_triton_prefill_attention.py,199
examples/fp8/extract_scales.py,199
docs/source/getting_started/openvino-installation.rst,199
docs/contributing/README.md,199
CONTRIBUTING.md,199
vllm/reasoning/ernie45_reasoning_parser.py,198
docs/source/serving/distributed_serving.rst,198
vllm/model_executor/parallel_utils/parallel_state.py,197
vllm/attention/backends/differential_flash_attn.py,197
tests/entrypoints/openai/test_gptoss_structural_tags_integration.py,197
docs/source/usage/multimodal_inputs.md,197
docs/source/getting_started/gaudi-installation.rst,197
csrc/quantization/gptq_marlin/gptq_marlin_repack.cu,197
docs/source/usage/usage_stats.md,196
docs/source/usage/lora.md,196
docs/source/usage/compatibility_matrix.md,196
docs/source/serving/deploying_with_docker.md,196
docs/source/performance/benchmarks.md,196
docs/source/models/enabling_multimodal_inputs.md,196
docs/source/getting_started/xpu-installation.md,196
docs/source/getting_started/amd-installation.md,196
vllm/entrypoints/serve/disagg/protocol.py,195
tests/test_attention_backend_registry.py,195
tests/kernels/moe/test_modular_oai_triton_moe.py,195
docs/source/getting_started/installation/gpu/rocm.inc.md,195
vllm/{attention/utils => v1/attention/backends}/fa_utils.py,194
vllm/{attention/layers => v1/attention/ops}/__init__.py,194
vllm/{attention/layers => model_executor/layers/attention}/static_sink_attention.py,194
vllm/{attention/layers => model_executor/layers/attention}/mm_encoder_attention.py,194
vllm/{attention/layers => model_executor/layers/attention}/encoder_only_attention.py,194
vllm/{attention/layers => model_executor/layers/attention}/cross_attention.py,194
vllm/{attention/layers => model_executor/layers/attention}/chunked_local_attention.py,194
vllm/{attention/backends/abstract.py => v1/attention/backend.py},194
vllm/{attention/backends => model_executor/layers/attention}/__init__.py,194
vllm/{ => v1}/attention/selector.py,194
vllm/{ => v1}/attention/ops/vit_attn_wrappers.py,194
vllm/{ => v1}/attention/ops/triton_unified_attention.py,194
vllm/{ => v1}/attention/ops/triton_reshape_and_cache_flash.py,194
vllm/{ => v1}/attention/ops/triton_prefill_attention.py,194
vllm/{ => v1}/attention/ops/triton_merge_attn_states.py,194
vllm/{ => v1}/attention/ops/triton_decode_attention.py,194
vllm/{ => v1}/attention/ops/rocm_aiter_mla_sparse.py,194
vllm/{ => v1}/attention/ops/prefix_prefill.py,194
vllm/{ => v1}/attention/ops/pallas_kv_cache_update.py,194
vllm/{ => v1}/attention/ops/paged_attn.py,194
vllm/{ => v1}/attention/ops/merge_attn_states.py,194
vllm/{ => v1}/attention/ops/flashmla.py,194
vllm/{ => v1}/attention/ops/common.py,194
vllm/{ => v1}/attention/ops/chunked_prefill_paged_decode.py,194
vllm/{ => v1}/attention/backends/registry.py,194
vllm/entrypoints/responses_utils.py,194
vllm/attention/ops/__init__.py,194
csrc/quantization/gptq/q_gemm.cu,194
docs/source/api/multimodal/index.md,193
csrc/moe/marlin_moe_wna16/marlin_template.h,193
.buildkite/scripts/hardware_ci/run-amd-test.sh,193
vllm/v1/worker/gpu/model_runner.py,192
docs/source/usage/compatibility_matrix.rst,192
docs/source/models/generative_models.rst,192
docs/contributing/ci/update_pytorch_version.md,192
examples/offline_inference/pooling/README.md,191
docs/design/metrics.md,191
tests/entrypoints/openai/tool_parsers/test_gigachat3_tool_parser.py,190
docs/cli/README.md,190
Dockerfile.openvino,190
tests/transformers_utils/test_config.py,189
docs/source/serving/deploying_with_dstack.rst,189
docs/source/getting_started/debugging.rst,189
docs/source/design/multimodal/adding_multimodal_plugin.md,189
csrc/attention/dtype_float32.cuh,189
vllm/model_executor/layers/fused_moe/fused_moe_modular_method.py,188
vllm/entrypoints/openai/utils.py,188
tests/tokenizers_/test_basic.py,188
docs/source/design/plugin_system.md,188
docs/design/huggingface_integration.md,188
csrc/quantization/squeezellm/quant_cuda_kernel.cu,188
docs/source/serving/deploying_with_docker.rst,187
docs/source/quantization/fp8.rst,187
vllm/entrypoints/pooling/pooling/api_router.py,185
vllm/entrypoints/pooling/embed/api_router.py,185
docs/source/design/input_processing/model_inputs_index.md,184
docs/source/design/input_processing/input_processing_pipeline.md,184
vllm/distributed/kv_transfer/README.md,183
tests/compile/test_aot_compile.py,183
docs/source/quantization/bnb.rst,183
docs/source/models/extensions/tensorizer.md,183
docs/source/getting_started/installation/gpu/xpu.inc.md,183
docs/configuration/serve_args.md,183
vllm/model_executor/parallel_utils/custom_all_reduce.py,182
vllm/entrypoints/serve/lora/api_router.py,182
tests/distributed/test_chunked_prefill_distributed.py,182
docs/features/prompt_embeds.md,182
tests/models/test_fp8.py,181
docs/source/serving/integrations.rst,181
vllm/utils/argparse_utils.py,180
vllm/entrypoints/serve/disagg/serving.py,180
docs/source/serving/run_on_sky.rst,180
docs/deployment/frameworks/lobe-chat.md,180
tests/entrypoints/pooling/embed/test_online.py,179
docs/usage/usage_stats.md,179
docs/source/usage/multimodal_inputs.rst,179
docs/source/design/plugin_system.rst,179
docs/source/serving/runai_model_streamer.rst,178
docs/source/serving/runai_model_streamer.md,178
docs/source/serving/deploying_with_dstack.md,178
docs/source/serving/deploying_with_cerebrium.md,178
docs/source/getting_started/neuron-installation.md,178
docs/source/getting_started/examples/examples_index.template.md,178
docs/source/getting_started/arm-installation.md,178
docs/community/meetups.md,178
tests/kernels/test_machete_gemm.py,177
docs/features/quantization/modelopt.md,177
vllm/entrypoints/pooling/score/api_router.py,176
vllm/entrypoints/pooling/classify/api_router.py,176
csrc/custom_all_reduce.cuh,176
vllm/compilation/matcher_utils.py,175
docs/source/quantization/fp8_e5m2_kvcache.rst,175
docs/source/getting_started/neuron-installation.rst,175
csrc/attention/attention_generic.cuh,175
docs/source/getting_started/arm-installation.rst,174
docs/source/dev/engine/engine_index.rst,174
.buildkite/scripts/hardware_ci/run-xpu-test.sh,174
requirements/cpu.txt,173
docs/source/usage/spec_decode.rst,173
docs/source/getting_started/installation/ai_accelerator/hpu-gaudi.inc.md,173
docs/source/contributing/model/registration.md,173
docs/design/automatic_prefix_caching.md,173
docs/source/community/meetups.md,172
vllm/model_executor/models/glm4_moe_lite_mtp.py,171
vllm/model_executor/models/glm4_moe_lite.py,171
docs/source/serving/metrics.rst,171
docs/source/getting_started/examples/examples_index.template.rst,171
docs/source/community/meetups.rst,171
docs/deployment/frameworks/anyscale.md,171
docs/source/design/huggingface_integration.rst,170
.buildkite/nightly-benchmarks/nightly-annotation.md,170
vllm/model_executor/models/exaone_moe.py,169
vllm/entrypoints/openai/engine/serving.py,169
docs/source/usage/disagg_prefill.rst,169
docs/source/quantization/int8.rst,169
docs/source/performance/benchmarks.rst,169
csrc/cuda_utils_kernels.cu,169
docs/source/serving/tensorizer.rst,168
docs/source/serving/serving_with_langchain.rst,168
docs/source/serving/deploying_with_nginx.rst,168
docs/source/automatic_prefix_caching/apc.rst,168
docs/contributing/dockerfile/dockerfile.md,168
vllm/model_executor/layers/attention/attention.py,167
docs/source/serving/serving_with_llamastack.rst,167
docs/source/serving/serving_with_llamaindex.rst,167
docs/source/serving/deploying_with_triton.rst,167
docs/source/serving/deploying_with_lws.rst,167
docs/source/serving/deploying_with_kubeai.rst,167
docs/source/serving/deploying_with_kserve.rst,167
docs/source/serving/deploying_with_k8s.rst,167
docs/source/serving/deploying_with_cerebrium.rst,167
docs/source/serving/deploying_with_bentoml.rst,167
docs/source/quantization/gguf.rst,167
docs/source/quantization/auto_awq.rst,167
docs/source/api/offline_inference/index.md,167
docs/source/api/engine/index.md,167
docs/deployment/integrations/kserve.md,167
docs/community/contact_us.md,167
csrc/custom_all_reduce.cu,167
benchmarks/kernels/benchmark_mixtral_moe.py,167
vllm/model_executor/models/jais2.py,166
vllm/entrypoints/openai/tool_parsers/minimax_m2_tool_parser.py,166
examples/offline_inference/prithvi_geospatial_mae_io_processor.py,166
docs/source/usage/{performance.rst => performance.md},166
docs/source/usage/{faq.rst => faq.md},166
docs/source/usage/{engine_args.rst => engine_args.md},166
docs/source/usage/structured_outputs.rst,166
docs/source/usage/lora.rst,166
docs/source/usage/env_vars.rst,166
docs/source/usage/env_vars.md,166
docs/source/usage/disagg_prefill.md,166
docs/source/serving/{deploying_with_helm.rst => deploying_with_helm.md},166
docs/source/serving/tensorizer.md,166
docs/source/serving/serving_with_llamastack.md,166
docs/source/serving/serving_with_llamaindex.md,166
docs/source/serving/serving_with_langchain.md,166
docs/source/serving/run_on_sky.md,166
docs/source/serving/deploying_with_triton.md,166
docs/source/serving/deploying_with_nginx.md,166
docs/source/serving/deploying_with_lws.md,166
docs/source/serving/deploying_with_kubeai.md,166
docs/source/serving/deploying_with_kserve.md,166
docs/source/serving/deploying_with_k8s.md,166
docs/source/serving/deploying_with_bentoml.md,166
docs/source/quantization/{supported_hardware.rst => supported_hardware.md},166
docs/source/quantization/int8.md,166
docs/source/quantization/gguf.md,166
docs/source/quantization/fp8_e5m2_kvcache.md,166
docs/source/quantization/fp8_e4m3_kvcache.md,166
docs/source/quantization/fp8.md,166
docs/source/quantization/bnb.md,166
docs/source/quantization/auto_awq.md,166
docs/source/models/{supported_models.rst => supported_models.md},166
docs/source/getting_started/openvino-installation.md,166
docs/source/features/quantization/fp8_e4m3_kvcache.md,166
docs/source/dev/{sampling_params.rst => sampling_params.md},166
docs/source/dev/{pooling_params.rst => pooling_params.md},166
docs/source/dev/offline_inference/{llm_inputs.rst => llm_inputs.md},166
docs/source/dev/offline_inference/{llm.rst => llm.md},166
docs/source/dev/engine/{llm_engine.rst => llm_engine.md},166
docs/source/dev/engine/{async_llm_engine.rst => async_llm_engine.md},166
docs/source/dev/engine/engine_index.md,166
docs/source/design/{arch_overview.rst => arch_overview.md},166
docs/source/design/multimodal/{multimodal_index.rst => multimodal_index.md},166
docs/source/design/multimodal/adding_multimodal_plugin.rst,166
docs/source/design/kernel/paged_attention.rst,166
docs/source/design/input_processing/model_inputs_index.rst,166
docs/source/design/input_processing/input_processing_pipeline.rst,166
docs/source/design/huggingface_integration.md,166
docs/source/contributing/{overview.rst => overview.md},166
docs/source/contributing/profiling/profiling_index.rst,166
docs/source/contributing/dockerfile/dockerfile.rst,166
docs/source/automatic_prefix_caching/apc.md,166
csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cu,166
csrc/moe/marlin_moe_wna16/kernel.h,166
docs/usage/faq.md,165
docs/deployment/integrations/llmaz.md,165
docs/deployment/integrations/kubeai.md,165
docs/deployment/frameworks/triton.md,165
docs/deployment/frameworks/modal.md,165
docs/deployment/frameworks/bentoml.md,165
cacheflow/__init__.py,165
examples/offline_inference/pooling/multi_vector_retrieval.py,164
cacheflow/model_executor/__init__.py,164
vllm/entrypoints/openai/tool_parsers/ernie45_tool_parser.py,163
examples/phi3v_example.py,163
examples/openai_client.py,163
examples/online_serving/pooling/README.md,163
docs/source/getting_started/installation/xpu.md,163
docs/serving/expert_parallel_deployment.md,163
docs/configuration/model_resolution.md,163
.buildkite/nightly-benchmarks/README.md,163
docs/source/getting_started/installation/ai_accelerator/tpu.inc.md,162
csrc/moe/marlin_moe_wna16/ops.cu,162
csrc/layernorm_quant_kernels.cu,162
Dockerfile.xpu,162
.github/workflows/clang-format.yml,162
docs/source/getting_started/installation/ai_accelerator/neuron.inc.md,161
docs/design/torch_compile.md,161
vllm/model_executor/layers/ops/rand.py,160
tests/lora/test_punica_variation.py,160
tests/kernels/test_rand.py,160
requirements-rocm.txt,160
examples/offline_inference/pooling/ner.py,160
csrc/cpu/pos_encoding.cpp,160
vllm/transformers_utils/image_processor.py,159
requirements/cuda.txt,159
docs/source/dev/offline_inference/llm_inputs.rst,159
vllm/reasoning/holo2_reasoning_parser.py,158
vllm/model_executor/layers/fused_moe/router/router_factory.py,158
docs/configuration/tpu.md,158
csrc/quantization/machete/machete_mainloop.cuh,158
csrc/mamba/mamba_ssm/selective_scan_fwd.cu,158
examples/api_client.py,157
csrc/quantization/fp8/nvidia/quant_utils.cuh,157
vllm/entrypoints/openai/parser/harmony_utils.py,156
csrc/quantization/aqlm/gemm_kernels.cu,155
vllm/tool_parsers/abstract_tool_parser.py,154
vllm/tokenizers/protocol.py,154
tests/entrypoints/pooling/pooling/test_online.py,154
vllm/model_executor/layers/quantization/deepgemm.py,153
csrc/moe/marlin_moe_ops.cu,153
Dockerfile.tpu,153
vllm/model_executor/models/lightonocr.py,152
tests/models/test_models.py,152
requirements/build.txt,152
examples/openai_vision_api_client.py,152
examples/offline_inference/qwen3_reranker.py,152
examples/offline_inference.py,152
csrc/punica/bgmv/bgmv_config.h,152
cacheflow/worker/controller.py,152
cacheflow/sequence.py,152
tests/lora/test_punica_sizes.py,151
csrc/quantization/marlin/sparse/common/mma.h,151
tests/kernels/test_rocm_attention_selector.py,150
requirements-cpu.txt,150
docs/getting_started/installation/google_tpu.md,150
tests/entrypoints/openai/test_protocol.py,149
.buildkite/nightly-benchmarks/nightly-descriptions.md,149
vllm/transformers_utils/gguf_utils.py,148
tests/lora/test_punica.py,148
csrc/rocm/skinny_gemms.cu,148
tests/entrypoints/openai/responses/test_function_call_parsing.py,147
vllm/model_executor/layers/fused_moe/router/custom_routing_router.py,146
tests/kernels/moe/test_cpu_fused_moe.py,146
requirements-test.in,146
examples/offline_inference/openai_batch/README.md,146
examples/gradio_webserver.py,146
.github/workflows/scripts/build.sh,146
vllm/v1/executor/uniproc_executor.py,145
docs/design/multiprocessing.md,145
csrc/quantization/awq/gemm_kernels.cu,145
.buildkite/nightly-benchmarks/scripts/run-nightly-benchmarks.sh,145
tests/kernels/core/test_fused_qk_norm_rope.py,144
tests/compile/distributed/test_async_tp.py,144
vllm/model_executor/models/transformers/utils.py,143
examples/online_serving/chart-helm/README.md,143
examples/gradio_openai_chatbot_webserver.py,143
vllm/model_executor/layers/fused_moe/fused_moe_method_base.py,142
vllm/entrypoints/openai/chat_completion/api_router.py,142
tests/distributed/test_basic_distributed_correctness_enc_dec.py,142
csrc/quantization/gptq_marlin/marlin_template.h,141
Dockerfile.neuron,141
csrc/quantization/compressed_tensors/int8_quant_kernels.cu,140
csrc/cpu/pybind.cpp,140
csrc/cpu/layernorm.cpp,140
vllm/lora/layers/fused_moe.py,139
vllm/entrypoints/anthropic/serving_messages.py,139
docs/source/getting_started/installation/gpu/cuda.inc.md,139
csrc/rocm/ops.h,139
csrc/quantization/cutlass_w8a8/scaled_mm_dq_c3x.cu,139
.buildkite/lm-eval-harness/run-lm-eval-gsm-vllm-baseline.sh,139
tests/entrypoints/openai/correctness/test_mteb_score.py,138
simple_server.py,138
csrc/quantization/gptq_marlin/dequant.h,138
tests/lora/test_fused_moe_lora_kernel.py,137
docs/source/api/multimodal/inputs.md,137
csrc/quantization/marlin/qqq/marlin_qqq_gemm_kernel.cu,137
MANIFEST.in,137
csrc/quantization/gptq_marlin/gptq_marlin.cuh,136
.buildkite/test-template.j2,136
vllm/model_executor/layers/quantization/utils/mxfp6_utils.py,135
tests/v1/kv_connector/nixl_integration/run_accuracy_test.sh,135
csrc/quantization/cutlass_w8a8/scaled_mm_dq_c2x.cu,135
vllm/model_executor/layers/fused_moe/triton_cutlass_moe.py,134
vllm/model_executor/layers/fused_moe/oracle/fp8.py,134
vllm/model_executor/layers/fused_moe/fallback.py,134
tests/tokenization/__init__.py,134
csrc/sparse/cutlass/sparse_scaled_mm_c3x.cu,134
csrc/cutlass_extensions/epilogue/scaled_mm_epilogues_c3x.hpp,134
Dockerfile.ppc64le,134
.buildkite/run-cpu-test-ppc64le.sh,133
vllm/entrypoints/openai/chat_completion/protocol.py,132
tests/entrypoints/openai/utils.py,132
tests/entrypoints/openai/test_serving_chat_stream_harmony.py,132
requirements/rocm.txt,132
csrc/core/scalar_type.hpp,132
csrc/attention/attention_kernels.cuh,132
vllm/tool_parsers/functiongemma_tool_parser.py,131
vllm/model_executor/models/llama_embedding.py,131
tests/tool_parsers/test_functiongemma_tool_parser.py,131
requirements-lint.txt,131
examples/online_serving/prithvi_geospatial_mae.py,131
.pylintrc,131
vllm/tool_parsers/openai_tool_parser.py,130
examples/offline_inference/basic/reward.py,130
docs/source/getting_started/installation/index.md,130
docs/features/README.md,130
vllm/v1/tokenizer/detokenizer.py,129
vllm/tool_parsers/minimax_m2_tool_parser.py,129
docs/source/design/multiprocessing.md,129
vllm/tool_parsers/mistral_tool_parser.py,128
vllm/tool_parsers/kimi_k2_tool_parser.py,128
vllm/tool_parsers/glm4_moe_tool_parser.py,128
vllm/entrypoints/serve/tokenize/protocol.py,128
tests/tool_parsers/test_mistral_tool_parser.py,128
tests/tool_parsers/test_kimi_k2_tool_parser.py,128
docs/source/getting_started/installation/cpu/apple.inc.md,128
csrc/moe_align_block_size_kernels.cu,128
cacheflow/model_executor/models/__init__.py,128
cacheflow/core/scheduler.py,128
vllm/tool_parsers/xlam_tool_parser.py,127
vllm/tool_parsers/utils.py,127
vllm/tool_parsers/step3_tool_parser.py,127
vllm/tool_parsers/seed_oss_tool_parser.py,127
vllm/tool_parsers/qwen3xml_tool_parser.py,127
vllm/tool_parsers/qwen3coder_tool_parser.py,127
vllm/tool_parsers/pythonic_tool_parser.py,127
vllm/tool_parsers/phi4mini_tool_parser.py,127
vllm/tool_parsers/olmo3_tool_parser.py,127
vllm/tool_parsers/minimax_tool_parser.py,127
vllm/tool_parsers/llama_tool_parser.py,127
vllm/tool_parsers/llama4_pythonic_tool_parser.py,127
vllm/tool_parsers/jamba_tool_parser.py,127
vllm/tool_parsers/internlm2_tool_parser.py,127
vllm/tool_parsers/hunyuan_a13b_tool_parser.py,127
vllm/tool_parsers/hermes_tool_parser.py,127
vllm/tool_parsers/granite_tool_parser.py,127
vllm/tool_parsers/granite_20b_fc_tool_parser.py,127
vllm/tool_parsers/gigachat3_tool_parser.py,127
vllm/tool_parsers/ernie45_tool_parser.py,127
vllm/tool_parsers/deepseekv3_tool_parser.py,127
vllm/tool_parsers/deepseekv32_tool_parser.py,127
vllm/tool_parsers/deepseekv31_tool_parser.py,127
vllm/entrypoints/openai/{serving_engine.py => engine/serving.py},127
vllm/entrypoints/openai/{serving_chat_stream_harmony.py => chat_completion/stream_harmony.py},127
vllm/entrypoints/openai/{serving_chat.py => chat_completion/serving.py},127
vllm/entrypoints/openai/{ => engine}/protocol.py,127
vllm/entrypoints/openai/engine/__init__.py,127
vllm/entrypoints/openai/chat_completion/__init__.py,127
tests/tool_parsers/test_xlam_tool_parser.py,127
tests/tool_parsers/test_seed_oss_tool_parser.py,127
tests/tool_parsers/test_qwen3coder_tool_parser.py,127
tests/tool_parsers/test_openai_tool_parser.py,127
tests/tool_parsers/test_minimax_tool_parser.py,127
tests/tool_parsers/test_jamba_tool_parser.py,127
tests/tool_parsers/test_glm4_moe_tool_parser.py,127
tests/tool_parsers/test_ernie45_moe_tool_parser.py,127
tests/entrypoints/openai/responses/test_errors.py,127
csrc/quantization/cutlass_w8a8/scaled_mm_dq_entry.cu,127
csrc/cpu/cpu_types.hpp,127
vllm/v1/attention/backend.py,126
vllm/utils/math_utils.py,126
tests/weight_loading/run_model_weight_loading_test.sh,126
tests/compile/distributed/test_fusion_all_reduce.py,126
csrc/moe/moe_permute_unpermute_op.cu,126
vllm/model_executor/layers/fused_moe/router/grouped_topk_router.py,125
tests/kernels/moe/test_routing.py,125
csrc/moe/moe_ops.cpp,125
vllm/model_executor/layers/fused_moe/configs/README,124
vllm/entrypoints/openai/rpc/server.py,124
examples/offline_inference/pooling/embed_matryoshka_fy.py,124
examples/offline_inference/pooling/embed_jina_embeddings_v3.py,124
docs/source/features/quantization/int8.md,124
docs/source/features/quantization/gguf.md,124
csrc/quantization/machete/machete_prepack_launcher.cuh,124
csrc/punica/bgmv/bgmv_impl.cuh,124
.github/PULL_REQUEST_TEMPLATE.md,124
vllm/utils/import_utils.py,123
tests/entrypoints/openai/tool_parsers/conftest.py,123
docs/source/features/quantization/fp8.md,123
csrc/quantization/gptq_marlin/kernel.h,123
vllm/model_executor/layers/fused_moe/flashinfer_cutedsl_moe.py,122
vllm/attention/layers/mm_encoder_attention.py,122
examples/tensorize_vllm_model.py,122
csrc/moe/moe_align_sum_kernels.cu,122
.buildkite/nightly-benchmarks/scripts/run-performance-benchmarks.sh,122
vllm/model_executor/layers/quantized_linear/awq.py,121
vllm/compilation/qk_norm_rope_fusion.py,120
tests/models/test_minicpmv.py,120
requirements-cuda.txt,120
docs/features/nixl_connector_usage.md,120
csrc/quantization/machete/machete_pytorch.cu,120
csrc/mamba/causal_conv1d/causal_conv1d.cu,120
vllm/v1/worker/gpu/cudagraph_utils.py,119
mypy.ini,119
examples/llava_next_example.py,119
vllm/{transformers_utils => }/tokenizers/mistral.py,118
tests/{tokenization/test_mistral_tokenizer.py => tokenizers_/test_mistral.py},118
tests/{tokenization => tokenizers_}/test_detokenize.py,118
tests/{tokenization => tokenizers_}/test_cached_tokenizer.py,118
tests/transformers_utils/{test_get_processor_kwargs_from_processor.py => test_processor.py},118
tests/transformers_utils/test_repo_utils.py,118
tests/tokenizers_/__init__.py,118
tests/models/encoder_decoder/language/__init__.py,118
tests/models/encoder_decoder/__init__.py,118
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-CT-Block-deepgemm-deepep-ll.yaml,118
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-AutoFp8-deepgemm-deepep-ll.yaml,118
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Llama-4-Scout-Fp8-ModelOpt-triton.yaml,118
docs/contributing/ci/failures.md,118
csrc/cuda_compat.h,118
cacheflow/sampling_params.py,118
cacheflow/models/opt.py,118
vllm/transformers_utils/configs/kimi_linear.py,117
vllm/_aiter_ops.py,117
benchmarks/benchmark_async_llm_server.py,117
.buildkite/lm-eval-harness/configs/Minitron-4B-Base-FP8.yaml,117
tools/check_pickle_imports.py,116
tests/models/decoder_only/language/test_hybrid.py,115
examples/{ => other}/tensorize_vllm_model.py,115
examples/{ => other}/logging_configuration.md,115
examples/{ => other}/fp8/quantizer/quantize.py,115
examples/{ => other}/fp8/quantizer/README.md,115
examples/{ => other}/fp8/extract_scales.py,115
examples/{ => other}/fp8/README.md,115
examples/{ => online_serving}/sagemaker-entrypoint.sh,115
examples/{ => online_serving}/run_cluster.sh,115
examples/{ => online_serving}/prometheus_grafana/prometheus.yaml,115
examples/{ => online_serving}/prometheus_grafana/grafana.json,115
examples/{ => online_serving}/prometheus_grafana/docker-compose.yaml,115
examples/{ => online_serving}/prometheus_grafana/README.md,115
examples/{ => online_serving}/opentelemetry/dummy_client.py,115
examples/{ => online_serving}/opentelemetry/Otel.md,115
examples/{ => online_serving}/openai_pooling_client.py,115
examples/{ => online_serving}/openai_embedding_client.py,115
examples/{ => online_serving}/openai_cross_encoder_score.py,115
examples/{ => online_serving}/openai_completion_client.py,115
examples/{ => online_serving}/openai_chat_embedding_client_for_multimodal.py,115
examples/{ => online_serving}/openai_chat_completion_structured_outputs.py,115
examples/{ => online_serving}/openai_chat_completion_client_with_tools.py,115
examples/{ => online_serving}/openai_chat_completion_client_for_multimodal.py,115
examples/{ => online_serving}/openai_chat_completion_client.py,115
examples/{ => online_serving}/gradio_webserver.py,115
examples/{ => online_serving}/gradio_openai_chatbot_webserver.py,115
examples/{ => online_serving}/disaggregated_prefill.sh,115
examples/{ => online_serving}/chart-helm/values.yaml,115
examples/{ => online_serving}/chart-helm/values.schema.json,115
examples/{ => online_serving}/chart-helm/templates/service.yaml,115
examples/{ => online_serving}/chart-helm/templates/secrets.yaml,115
examples/{ => online_serving}/chart-helm/templates/pvc.yaml,115
examples/{ => online_serving}/chart-helm/templates/poddisruptionbudget.yaml,115
examples/{ => online_serving}/chart-helm/templates/job.yaml,115
examples/{ => online_serving}/chart-helm/templates/hpa.yaml,115
examples/{ => online_serving}/chart-helm/templates/deployment.yaml,115
examples/{ => online_serving}/chart-helm/templates/custom-objects.yaml,115
examples/{ => online_serving}/chart-helm/templates/configmap.yaml,115
examples/{ => online_serving}/chart-helm/templates/_helpers.tpl,115
examples/{ => online_serving}/chart-helm/lintconf.yaml,115
examples/{ => online_serving}/chart-helm/ct.yaml,115
examples/{ => online_serving}/chart-helm/Chart.yaml,115
examples/{ => online_serving}/chart-helm/.helmignore,115
examples/{ => online_serving}/api_client.py,115
examples/{ => offline_inference}/save_sharded_state.py,115
examples/{ => offline_inference}/offline_profile.py,115
examples/{ => offline_inference}/offline_inference_with_profiler.py,115
examples/{ => offline_inference}/offline_inference_with_prefix.py,115
examples/{ => offline_inference}/offline_inference_with_default_generation_config.py,115
examples/{ => offline_inference}/offline_inference_whisper.py,115
examples/{ => offline_inference}/offline_inference_vision_language_multi_image.py,115
examples/{ => offline_inference}/offline_inference_vision_language_embedding.py,115
examples/{ => offline_inference}/offline_inference_vision_language.py,115
examples/{ => offline_inference}/offline_inference_tpu.py,115
examples/{ => offline_inference}/offline_inference_structured_outputs.py,115
examples/{ => offline_inference}/offline_inference_scoring.py,115
examples/{ => offline_inference}/offline_inference_pixtral.py,115
examples/{ => offline_inference}/offline_inference_neuron_int8_quantization.py,115
examples/{ => offline_inference}/offline_inference_neuron.py,115
examples/{ => offline_inference}/offline_inference_mlpspeculator.py,115
examples/{ => offline_inference}/offline_inference_encoder_decoder.py,115
examples/{ => offline_inference}/offline_inference_embedding.py,115
examples/{ => offline_inference}/offline_inference_distributed.py,115
examples/{ => offline_inference}/offline_inference_cli.py,115
examples/{ => offline_inference}/offline_inference_classification.py,115
examples/{ => offline_inference}/offline_inference_chat.py,115
examples/{ => offline_inference}/offline_inference_audio_language.py,115
examples/{ => offline_inference}/offline_inference_arctic.py,115
examples/{ => offline_inference}/offline_inference.py,115
examples/{ => offline_inference}/offline_chat_with_tools.py,115
examples/{ => offline_inference}/multilora_inference.py,115
examples/{ => offline_inference}/lora_with_quantization_inference.py,115
examples/{ => offline_inference}/llm_engine_example.py,115
examples/{ => offline_inference}/gguf_inference.py,115
examples/{ => offline_inference}/florence2_inference.py,115
examples/{ => offline_inference}/cpu_offload.py,115
examples/{ => offline_inference}/aqlm_example.py,115
examples/{ => offline_inference/offline_inference_openai}/openai_example_batch.jsonl,115
examples/{ => offline_inference/offline_inference_openai}/offline_inference_openai.md,115
docs/source/models/extensions/runai_model_streamer.md,115
docs/source/deployment/frameworks/dstack.md,115
docs/source/deployment/frameworks/cerebrium.md,115
csrc/quantization/gptq_marlin/awq_marlin_repack.cu,115
csrc/cutlass_extensions/common.hpp,115
cmake/external_projects/flashmla.cmake,115
vllm/tasks.py,114
vllm/model_executor/layers/fused_moe/oracle/nvfp4.py,114
tests/entrypoints/llm/test_classify.py,114
.buildkite/nightly-benchmarks/scripts/nightly-annotate.sh,114
tests/models/test_gptq_marlin.py,113
csrc/quantization/machete/machete_mm_kernel.cuh,113
vllm/entrypoints/openai/responses/serving.py,112
tests/entrypoints/pooling/classify/test_online.py,112
csrc/rocm/torch_bindings.cpp,112
tests/models/test_mistral.py,111
tests/models/language/pooling/test_intfloat.py,111
csrc/attention/paged_attention_v2.cu,111
csrc/attention/paged_attention_v1.cu,111
vllm/transformers_utils/configs/flex_olmo.py,110
vllm/model_executor/layers/pooler/tokwise/poolers.py,110
vllm/entrypoints/openai/rpc/client.py,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-ModelOpt-vllm-cutlass.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-CT-vllm-cutlass.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Block-marlin.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Block-fi-cutlass.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-AutoFp8-triton.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-AutoFp8-marlin.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-AutoFp8-fi-trtllm.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-AutoFp8-fi-cutlass.yaml,110
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-Fp8-ModelOpt-triton.yaml,110
vllm/transformers_utils/configs/afmoe.py,109
vllm/model_executor/layers/quantized_linear/__init__.py,109
vllm/executor/ray_hpu_executor.py,109
vllm/attention/ops/vit_attn_wrappers.py,109
tests/kernels/moe/test_triton_moe_no_act_mul.py,109
tests/kernels/attention/test_cpu_attn.py,109
tests/entrypoints/openai/correctness/test_mteb_embed.py,109
examples/offline_inference_audio_language.py,109
csrc/punica/punica_ops.h,109
vllm/transformers_utils/tokenizers/baichuan.py,108
docs/source/api/multimodal/registry.md,108
docs/source/api/multimodal/profiling.md,108
docs/source/api/multimodal/processing.md,108
docs/source/api/multimodal/parse.md,108
docs/source/api/model/interfaces_base.md,108
docs/source/api/model/interfaces.md,108
docs/source/api/model/adapters.md,108
csrc/cpu/dnnl_helper.cpp,108
vllm/model_executor/layers/quantization/utils/marlin_perms.py,107
vllm/model_executor/layers/quantization/utils/marlin_24_perms.py,107
tests/entrypoints/pooling/score/test_utils.py,107
examples/online_serving/openai_cross_encoder_score_for_multimodal.py,107
examples/offline_inference_embedding.py,107
docs/source/getting_started/installation/cpu/index.md,107
csrc/punica/bgmv/generator.py,107
csrc/moe/marlin_kernels/marlin_moe_kernel.h,107
csrc/custom_all_reduce_test.cu,107
.buildkite/lm-eval-harness/configs/models-small.txt,107
vllm/prompt_adapter/__init__.py,106
vllm/entrypoints/pooling/__init__.py,106
tests/models/test_paligemma.py,106
tests/compile/distributed/test_fusions_e2e.py,106
docs/design/prefix_caching.md,106
csrc/punica/bgmv/vec_dtypes.cuh,106
cacheflow/server/llm_server.py,105
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_GeForce_RTX_4090,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=640,device_name=NVIDIA_A800-SXM4-80GB.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=320,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=2560,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=64,N=1280,device_name=NVIDIA_A800-SXM4-80GB.json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=64,device_name=NVIDIA_A800-SXM4-80GB.json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H20,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_L20Y,dtype=fp8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A800-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8.json",104
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a8,block_shape=[128,128].json",104
"vllm/model_executor/layers/fused_moe/configs/E=160,N=192,device_name=NVIDIA_A800-SXM4-80GB.json",104
tests/worker/spec_decode/utils.py,104
examples/offline_inference_vision_language_embedding.py,104
csrc/quantization/gptq/qdq_4.cuh,104
csrc/quantization/gptq/matrix_view.cuh,104
csrc/quantization/fused_kernels/quant_conversions.cuh,104
csrc/quantization/fp8/amd/quant_utils.cuh,104
vllm/block.py,103
csrc/quantization/machete/machete_mm_launcher.cuh,103
vllm/model_executor/layers/pooler/seqwise/poolers.py,102
docs/getting_started/installation/gpu/cuda.inc.md,102
vllm/model_executor/layers/attention/backends/flash_attn.py,101
vllm/core/embedding_model_block_manager.py,101
cacheflow/models/model_utils.py,101
vllm/lora/ops/triton_ops/{lora_shrink.py => lora_shrink_op.py},100
vllm/lora/ops/triton_ops/{lora_expand.py => lora_expand_op.py},100
tests/lora/test_chatglm3.py,100
examples/offline_inference_vision_language_multi_image.py,100
docs/source/dev/input_processing/model_inputs_index.rst,100
docs/source/deployment/nginx.md,100
docs/source/api/offline_inference/llm_inputs.md,100
docs/source/api/offline_inference/llm.md,100
docs/source/api/inference_params.md,100
docs/source/api/engine/llm_engine.md,100
docs/source/api/engine/async_llm_engine.md,100
docs/getting_started/installation/gpu/xpu.inc.md,100
docs/configuration/env_vars.md,100
csrc/punica/torch_bindings.cpp,100
csrc/punica/punica_ops.cu,100
vllm/entrypoints/openai/chat_completion/serving.py,99
tests/fp8_kv/llama2-7b-fp8-kv/kv_cache_scales.json,99
tests/fp8_kv/llama2-70b-fp8-kv/kv_cache_scales.json,99
tests/entrypoints/pooling/score/test_online_score.py,99
docs/source/getting_started/installation/gpu/index.md,99
docs/source/getting_started/installation/ai_accelerator/index.md,99
csrc/quantization/gguf/gguf_kernel.cu,99
tests/models/test_big_models.py,98
tests/models/language/pooling_mteb_test/test_nemotron.py,98
vllm/model_executor/layers/attention/ops/paged_attn.py,97
tests/lora/test_lora.py,97
tests/kernels/quantization/test_cutlass_w4a8_moe.py,97
docs/source/getting_started/installation/hpu-gaudi.md,97
csrc/quantization/gptq/qdq_util.cuh,97
csrc/quantization/gptq/compat.cuh,97
csrc/punica/LICENSE,97
cacheflow/utils.py,97
tests/models/test_chameleon.py,96
csrc/cpu/quant.cpp,96
cacheflow/worker/cache_engine.py,96
vllm/model_executor/models/transformers/causal.py,95
tests/{engine/test_detokenization.py => detokenizer/test_disable_detokenization.py},95
tests/{engine/output_processor => detokenizer}/test_stop_checker.py,95
tests/{engine/output_processor => detokenizer}/__init__.py,95
tests/{engine => detokenizer}/test_stop_reason.py,95
tests/models/decoder_only/vision_language/test_qwen.py,95
tests/engine/{output_processor/test_multi_step.py => test_multi_step_output_processor.py},95
csrc/quantization/cutlass_w8a8/scaled_mm_c2x.cuh,95
csrc/quantization/activation_kernels.cu,95
benchmarks/kernels/benchmark_cutlass_moe_nvfp4.py,95
Dockerfile.hpu,95
requirements-build.txt,94
cacheflow/models/memory_analyzer.py,94
tests/spec_decode/e2e/__init__.py,93
docs/features/quantization/auto_round.md,93
csrc/moe/marlin_moe_ops.h,93
vllm/model_executor/layers/fused_moe/oracle/unquantized.py,92
vllm/executor/hpu_executor.py,92
tests/models/test_aqlm.py,92
tests/models/language/pooling/test_qwen3_reranker.py,92
docs/source/getting_started/installation/ai_accelerator/openvino.inc.md,92
docs/serving/distributed_troubleshooting.md,92
cacheflow/models/attention.py,92
.buildkite/test_areas/misc.yaml,92
.buildkite/scripts/hardware_ci/run-tpu-v1-test.sh,92
vllm/lora/ops/sgmv_expand_slice.py,91
vllm/lora/ops/sgmv_expand.py,91
vllm/benchmarks/mm_processor.py,91
tests/utils_/test_func_utils.py,91
tests/models/decoder_only/vision_language/test_broadcast.py,91
cacheflow/model_executor/utils.py,91
vllm/v1/executor/ray_executor.py,90
tools/vllm-rocm/pin_rocm_dependencies.py,90
tests/utils_/test_async_utils.py,90
tests/models/decoder_only/vision_language/mm_processor_kwargs/test_phi3v.py,90
csrc/quantization/gptq_allspark/allspark_utils.cuh,90
csrc/quantization/fused_kernels/fused_layernorm_dynamic_per_token_quant.cu,90
csrc/quantization/awq/dequantize.cuh,90
{cacheflow => vllm}/worker/worker.py,89
{cacheflow => vllm}/worker/cache_engine.py,89
{cacheflow => vllm}/worker/__init__.py,89
{cacheflow => vllm}/utils.py,89
{cacheflow => vllm}/sequence.py,89
{cacheflow => vllm}/sampling_params.py,89
{cacheflow => vllm}/outputs.py,89
{cacheflow => vllm}/model_executor/weight_utils.py,89
{cacheflow => vllm}/model_executor/utils.py,89
{cacheflow => vllm}/model_executor/parallel_utils/tensor_parallel/utils.py,89
{cacheflow => vllm}/model_executor/parallel_utils/tensor_parallel/random.py,89
{cacheflow => vllm}/model_executor/parallel_utils/tensor_parallel/mappings.py,89
{cacheflow => vllm}/model_executor/parallel_utils/tensor_parallel/layers.py,89
{cacheflow => vllm}/model_executor/parallel_utils/tensor_parallel/__init__.py,89
{cacheflow => vllm}/model_executor/parallel_utils/parallel_state.py,89
{cacheflow => vllm}/model_executor/parallel_utils/__init__.py,89
{cacheflow => vllm}/model_executor/parallel_utils/README.md,89
{cacheflow => vllm}/model_executor/models/opt.py,89
{cacheflow => vllm}/model_executor/models/llama.py,89
{cacheflow => vllm}/model_executor/models/gpt_neox.py,89
{cacheflow => vllm}/model_executor/models/gpt2.py,89
{cacheflow => vllm}/model_executor/model_loader.py,89
{cacheflow => vllm}/model_executor/layers/sampler.py,89
{cacheflow => vllm}/model_executor/layers/layernorm.py,89
{cacheflow => vllm}/model_executor/layers/attention.py,89
{cacheflow => vllm}/model_executor/layers/activation.py,89
{cacheflow => vllm}/model_executor/layers/__init__.py,89
{cacheflow => vllm}/model_executor/input_metadata.py,89
{cacheflow => vllm}/logger.py,89
{cacheflow => vllm}/entrypoints/openai/protocol.py,89
{cacheflow => vllm}/entrypoints/openai/api_server.py,89
{cacheflow => vllm}/entrypoints/openai/__init__.py,89
{cacheflow => vllm}/entrypoints/llm.py,89
{cacheflow => vllm}/entrypoints/api_server.py,89
{cacheflow => vllm}/entrypoints/__init__.py,89
{cacheflow => vllm}/engine/tokenizer_utils.py,89
{cacheflow => vllm}/engine/ray_utils.py,89
{cacheflow => vllm}/engine/llm_engine.py,89
{cacheflow => vllm}/engine/async_llm_engine.py,89
{cacheflow => vllm}/engine/arg_utils.py,89
{cacheflow => vllm}/engine/__init__.py,89
{cacheflow => vllm}/core/scheduler.py,89
{cacheflow => vllm}/core/policy.py,89
{cacheflow => vllm}/core/block_manager.py,89
{cacheflow => vllm}/core/__init__.py,89
{cacheflow => vllm}/config.py,89
{cacheflow => vllm}/block.py,89
vllm/model_executor/parallel_utils/layers.py,89
tests/models/multimodal/test_tensor_schema.py,89
tests/engine/test_detokenize.py,89
docs/source/getting_started/installation/python_env_setup.inc.md,89
csrc/punica/punica_ops.cc,89
csrc/cpu/cpu_attn_impl.hpp,89
csrc/cpu/activation.cpp,89
.markdownlint.yaml,89
.buildkite/lm-eval-harness/run-lm-eval-gsm-hf-baseline.sh,89
vllm/prefix.py,88
tests/models/test_bart.py,88
tests/models/encoder_decoder/vision_language/__init__.py,87
tests/models/decoder_only/vision_language/test_llava_onevision.py,87
tests/lora/test_olmoe_tp.py,87
tests/kernels/quantization/test_nvfp4_qutlass.py,87
tests/kernels/quantization/test_mxfp4_qutlass.py,87
docs/source/getting_started/installation/gpu-rocm.md,87
csrc/quantization/cutlass_w8a8/moe/moe_data.cu,87
cacheflow/model_executor/layers/sampler.py,87
.buildkite/nightly-benchmarks/tests/nightly-tests.json,87
vllm/v1/worker/gpu/input_batch.py,86
vllm/lora/ops/sgmv_shrink.py,86
tests/tool_use/test_mistral_tool_parser.py,86
vllm/v1/spec_decode/suffix_decoding.py,85
csrc/quantization/gptq_marlin/.gitignore,85
csrc/moe/marlin_moe_wna16/.gitignore,85
cacheflow/models/llama.py,85
cacheflow/master/server.py,85
tests/entrypoints/pooling/score/test_online_rerank.py,84
examples/online_serving/disaggregated_encoder/README.md,84
docs/usage/reproducibility.md,84
csrc/punica/bgmv/bgmv_fp32_fp16_fp16.cu,84
csrc/punica/bgmv/bgmv_fp32_bf16_bf16.cu,84
csrc/punica/bgmv/bgmv_fp16_fp32_fp16.cu,84
csrc/punica/bgmv/bgmv_fp16_fp16_fp16.cu,84
csrc/punica/bgmv/bgmv_bf16_fp32_bf16.cu,84
csrc/punica/bgmv/bgmv_bf16_bf16_bf16.cu,84
cacheflow/models/__init__.py,84
vllm/transformers_utils/configs/nemotron_vl.py,83
vllm/model_executor/models/neuron/llama.py,83
tests/entrypoints/pooling/embed/test_online_long_text.py,83
requirements/rocm-build.txt,83
csrc/quantization/cutlass_w8a8/Epilogues.md,83
tests/v1/e2e/test_ngram_spec_decode.py,82
tests/models/language/pooling/test_bge_reranker_v2_gemma.py,82
tests/entrypoints/pooling/embed/test_online_vision.py,82
docs/design/p2p_nccl_connector.md,82
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Block-triton.yaml,81
docs/source/models/lora.rst,81
.buildkite/nightly-benchmarks/performance-benchmarks-descriptions.md,81
vllm/model_executor/layers/attention/__init__.py,80
tests/quantization/test_autogptq_marlin_configs.py,80
tests/models/test_blip2.py,80
tests/entrypoints/llm/test_score.py,80
tests/entrypoints/llm/test_reward.py,80
requirements/xpu.txt,80
docs/{ => contributing}/ci/update_pytorch_version.md,80
docs/usage/security.md,80
docs/contributing/{ci-failures.md => ci/failures.md},80
csrc/quantization/marlin/sparse/common/mem.h,80
csrc/quantization/marlin/sparse/common/base.h,80
csrc/quantization/cutlass_w8a8/scaled_mm_c2x.cu,80
csrc/core/math.hpp,80
.buildkite/run-amd-test.sh,80
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-QQQ.yaml,80
vllm/v1/worker/gpu/spec_decode/eagle.py,79
vllm/multimodal/processing/context.py,79
tests/v1/kv_connector/nixl_integration/run_tpu_edge_case_test.sh,79
tests/v1/kv_connector/nixl_integration/run_tpu_disagg_accuracy_test.sh,79
tests/models/test_embedding.py,79
tests/models/language/pooling_mteb_test/mteb_score_utils.py,79
tests/models/encoder_decoder/audio_language/__init__.py,79
tests/models/embedding/vision_language/__init__.py,79
tests/kernels/moe/test_silu_mul_per_token_group_quant_fp8_colmajor.py,79
tests/evals/gsm8k/configs/moe-refactor/config-b200.txt,79
docs/configuration/README.md,79
csrc/sparse/cutlass/sparse_scaled_mm_entry.cu,79
csrc/attention/dtype_fp8.cuh,79
vllm/triton_utils/libentry.py,78
vllm/entrypoints/openai/rpc/__init__.py,78
examples/simple_server.py,78
csrc/quantization/gptq_allspark/allspark_qgemm_w8a16.cu,78
csrc/quantization/fp8/common.cuh,78
csrc/mamba/mamba_ssm/selective_scan.h,78
vllm/transformers_utils/configs/starcoder2.py,77
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_unquantized.py,77
vllm/model_executor/layers/fused_moe/router/fused_topk_bias_router.py,77
vllm/entrypoints/openai/engine/protocol.py,77
tests/v1/kv_connector/nixl_integration/run_edge_case_test.sh,77
tests/kernels/test_fla_layernorm_guard.py,77
tests/evals/gsm8k/configs/moe-refactor/config-h100.txt,77
tests/models/language/pooling/test_mxbai_rerank.py,76
docs/serving/parallelism_scaling.md,76
docs/mkdocs/stylesheets/extra.css,76
docs/getting_started/installation/cpu/apple.inc.md,76
docs/features/disagg_encoder.md,76
docs/design/v1/p2p_nccl_connector.md,76
csrc/cutlass_extensions/torch_utils.hpp,76
vllm/multimodal/{profiling.py => processing/dummy_inputs.py},75
vllm/multimodal/{processing.py => processing/processor.py},75
vllm/multimodal/processing/__init__.py,75
vllm/lora/ops/bgmv_expand_slice.py,75
vllm/lora/ops/bgmv_expand.py,75
tests/models/test_gptq_marlin_24.py,75
docs/serving/data_parallel_deployment.md,75
csrc/quantization/machete/machete_prepack_kernel.cuh,75
csrc/quantization/gptq_marlin/marlin.cuh,75
cacheflow/models/sample.py,75
vllm/model_executor/quantization_utils/awq.py,74
vllm/model_executor/parallel_utils/tensor_parallel/layers.py,74
vllm/model_executor/models/transformers/pooling.py,74
vllm/model_executor/layers/pooler/tokwise/methods.py,74
vllm/model_executor/layers/pooler/seqwise/methods.py,74
typos.toml,74
tests/kernels/moe/modular_kernel_tools/utils.py,74
docs/contributing/deprecation_policy.md,74
csrc/cpu/utils.cpp,74
csrc/cpu/shm.cpp,74
cacheflow/model_executor/layers/attention.py,74
benchmarks/disagg_benchmarks/disagg_performance_benchmark.sh,74
benchmarks/disagg_benchmarks/disagg_overhead_benchmark.sh,74
vllm/v1/executor/ray_utils.py,73
vllm/spec_decode/__init__.py,73
vllm/compilation/caching.py,73
tools/doc-lint.sh,73
tests/v1/test_request.py,73
tests/multimodal/test_base.py,73
docs/getting_started/installation/aws_neuron.md,73
cacheflow/outputs.py,73
.buildkite/download-images.sh,73
vllm/v1/worker/gpu/states.py,72
vllm/model_executor/quantization_utils/base.py,72
tests/spec_decode/__init__.py,72
docs/source/contributing/model/tests.md,72
csrc/quantization/fp4/nvfp4_quant_entry.cu,72
cacheflow/models/input_metadata.py,72
tests/models/decoder_only/vision_language/test_paligemma.py,71
docker/Dockerfile.nightly_torch,71
csrc/quantization/fp8/amd/hip_float8_impl.h,71
csrc/punica/bgmv/bgmv_all.cu,71
.buildkite/nightly-benchmarks/scripts/wait-for-image.sh,71
tests/spec_decode/e2e/test_correctness.py,70
tests/models/decoder_only/vision_language/mm_processor_kwargs/test_llava_next.py,70
requirements-tpu.txt,70
csrc/quantization/gptq/qdq_8.cuh,70
csrc/quantization/gptq/qdq_3.cuh,70
csrc/quantization/gptq/qdq_2.cuh,70
vllm/v1/sample/logits_processor.py,69
vllm/v1/executor/gpu_executor.py,69
vllm/model_executor/layers/attention/cross_attention.py,69
vllm/distributed/device_communicators/pynccl_utils.py,69
tests/v1/sample/test_logits_processors.py,69
tests/v1/e2e/test_async_scheduling.py,69
docs/source/getting_started/installation/cpu/build.inc.md,69
docs/source/features/tool_calling.md,69
vllm/tool_parsers/__init__.py,68
vllm/model_executor/quantization_utils/__init__.py,68
vllm/model_executor/models/neuron/mistral.py,68
docs/source/features/automatic_prefix_caching.md,68
docs/getting_started/installation/cpu/s390x.inc.md,68
csrc/quantization/fp8/amd/hip_float8.h,68
csrc/quantization/fp4/nvfp4_experts_quant.cu,68
csrc/attention/attention_dtypes.h,68
cacheflow/model_executor/model_loader.py,68
cacheflow/master/scheduler.py,68
tests/models/test_internvl.py,67
tests/lora/test_tokenizer.py,67
csrc/sparse/cutlass/sparse_scaled_mm_c3x.cuh,67
cmake/external_projects/vllm_flash_attn.cmake,67
vllm/model_executor/{tensorizer_loader.py => model_loader/tensorizer.py},66
vllm/model_executor/{neuron_model_loader.py => model_loader/neuron.py},66
vllm/model_executor/{ => model_loader}/weight_utils.py,66
vllm/lora/ops/triton_ops/fused_moe_lora_op.py,66
tests/{tensorizer => tensorizer_loader}/test_tensorizer.py,66
tests/{tensorizer => tensorizer_loader}/tensorize_vllm_model_for_testing.py,66
tests/{tensorizer => tensorizer_loader}/__init__.py,66
tests/models/decoder_only/vision_language/mm_processor_kwargs/test_qwen2_vl.py,66
requirements-xpu.txt,66
docs/source/features/quantization/quantized_kvcache.md,66
docs/getting_started/installation/cpu/build.inc.md,66
csrc/quantization/gptq_marlin/gptq_marlin_dtypes.cuh,66
csrc/prepare_inputs/advance_step.cu,66
cacheflow/server/arg_utils.py,66
benchmarks/auto_tune/README.md,66
vllm/plugins/lora_resolvers/README.md,65
vllm/model_executor/models/donut.py,65
vllm/model_executor/layers/fused_moe/router/base_router.py,65
csrc/mamba/causal_conv1d/causal_conv1d.h,65
csrc/cpu/dnnl_helper.h,65
cacheflow/models/utils.py,65
.buildkite/nightly-benchmarks/scripts/launch-server.sh,65
tools/ep_kernels/README.md,64
tests/models/{encoder_decoder/vision_language => multimodal/generation}/test_mllama.py,64
tests/models/{encoder_decoder/vision_language => multimodal/generation}/test_florence2.py,64
tests/models/{encoder_decoder/language => language/generation}/test_bart.py,64
tests/models/{encoder_decoder/audio_language => multimodal/generation}/test_whisper.py,64
tests/models/{embedding/vision_language => multimodal/pooling}/test_phi3v.py,64
tests/models/{embedding/vision_language => multimodal/pooling}/test_llava_next.py,64
tests/models/{embedding/vision_language => multimodal/pooling}/test_dse_qwen2_vl.py,64
tests/models/{embedding/language => quantization}/__init__.py,64
tests/models/{embedding/language => language/pooling}/test_truncation_control.py,64
tests/models/{embedding/language => language/pooling}/test_snowflake_arctic_embed.py,64
tests/models/{embedding/language => language/pooling}/test_scoring.py,64
tests/models/{embedding/language => language/pooling}/test_jina.py,64
tests/models/{embedding/language => language/pooling}/test_gritlm.py,64
tests/models/{embedding/language => language/pooling}/test_embedding.py,64
tests/models/{embedding/language => language/pooling}/test_cls_models.py,64
tests/models/{embedding => multimodal/pooling}/__init__.py,64
tests/models/{decoder_only/vision_language/test_models.py => multimodal/generation/test_common.py},64
tests/models/{decoder_only/vision_language => quantization}/test_awq.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/types.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/runners.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/model_utils.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/custom_inputs.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/core.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/case_filtering.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/builders.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/vlm_utils/__init__.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/test_qwen2_vl.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/test_pixtral.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/test_phi4mm.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/test_intern_vit.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/test_interleaved.py,64
tests/models/{decoder_only/vision_language => multimodal/generation}/__init__.py,64
tests/models/{decoder_only/language => quantization}/test_nvfp4.py,64
tests/models/{decoder_only/language => quantization}/test_modelopt.py,64
tests/models/{decoder_only/language => quantization}/test_gptq_marlin_24.py,64
tests/models/{decoder_only/language => quantization}/test_gptq_marlin.py,64
tests/models/{decoder_only/language => quantization}/test_gguf.py,64
tests/models/{decoder_only/language => quantization}/test_fp8.py,64
tests/models/{decoder_only/language => quantization}/test_aqlm.py,64
tests/models/{decoder_only/language => language/pooling}/__init__.py,64
tests/models/{decoder_only/language => language/generation}/test_phimoe.py,64
tests/models/{decoder_only/language => language/generation}/test_models.py,64
tests/models/{decoder_only/language => language/generation}/test_mistral.py,64
tests/models/{decoder_only/language => language/generation}/test_hybrid.py,64
tests/models/{decoder_only/language => language/generation}/test_granite.py,64
tests/models/{decoder_only/audio_language => multimodal/generation}/test_ultravox.py,64
tests/models/{decoder_only/audio_language => multimodal/generation}/test_granite_speech.py,64
tests/models/{decoder_only/audio_language => language/generation}/__init__.py,64
tests/models/{decoder_only => language}/__init__.py,64
tests/models/{ => quantization}/test_gptq_bitblas.py,64
tests/models/{ => quantization}/test_bitblas.py,64
examples/online_serving/openai_embedding_long_text/service.sh,64
examples/online_serving/openai_chat_completion_client_with_tools_xlam_streaming.py,64
examples/online_serving/openai_chat_completion_client_with_tools_xlam.py,64
docs/usage/README.md,64
docs/source/models/engine_args.rst,64
docs/getting_started/installation/{gpu/xpu.inc.md => gpu.xpu.inc.md},64
docs/getting_started/installation/{gpu/rocm.inc.md => gpu.rocm.inc.md},64
docs/getting_started/installation/{gpu/cuda.inc.md => gpu.cuda.inc.md},64
docs/getting_started/installation/{cpu/x86.inc.md => cpu.x86.inc.md},64
docs/getting_started/installation/{cpu/s390x.inc.md => cpu.s390x.inc.md},64
docs/getting_started/installation/{cpu/arm.inc.md => cpu.arm.inc.md},64
docs/getting_started/installation/{cpu/apple.inc.md => cpu.apple.inc.md},64
benchmarks/auto_tune/auto_tune.sh,64
vllm/lora/ops/bgmv_shrink.py,63
vllm/compilation/levels.py,63
tests/tpu/lora/__init__.py,63
tests/entrypoints/pooling/embed/test_online_dimensions.py,63
tests/core/block/test_block_manager_v2.py,63
tests/compile/test_dynamic_shapes_compilation.py,63
examples/offline_inference_with_prefix.py,63
examples/fp8/README.md,63
docs/source/deployment/k8s.md,63
docs/deployment/frameworks/hf_inference_endpoints.md,63
csrc/quantization/cutlass_w4a8/w4a8_mm_entry.cu,63
csrc/punica/punica_pybind.cpp,63
csrc/cutlass_extensions/vllm_collective_builder.cuh,63
.clang-format,63
.buildkite/test_areas/tool_use.yaml,63
vllm/model_executor/parallel_utils/cupy_utils.py,62
tests/tokenization/test_image_processor.py,62
tests/models/language/pooling_mteb_test/mteb_embed_utils.py,62
tests/models/decoder_only/vision_language/processing/test_llava_next.py,62
tests/kernels/attention.py,62
examples/offline_inference_mlpspeculator.py,62
examples/offline_inference/disaggregated-prefill-v1/README.md,62
docs/source/dev/input_processing/input_processing_pipeline.rst,62
csrc/quantization/gguf/mmvq.cuh,62
csrc/attention.cpp,62
cacheflow/parallel_utils/__init__.py,62
.buildkite/nightly-benchmarks/nightly-pipeline.yaml,62
vllm/model_executor/layers/pooler/tokwise/heads.py,61
vllm/model_executor/layers/pooler/seqwise/heads.py,61
vllm/compilation/config.py,61
examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_proxy_p2p_nccl_xpyd.py,61
csrc/quantization/fp4/nvfp4_quant_kernels.cu,61
csrc/pos_encoding.cpp,61
csrc/attention_kernels.cu,61
cacheflow/model_executor/models/opt.py,61
cacheflow/model_executor/models/gpt_neox.py,61
cacheflow/model_executor/models/gpt2.py,61
cacheflow/entrypoints/llm.py,61
vllm/{entrypoints/openai => }/tool_parsers/xlam_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/utils.py,60
vllm/{entrypoints/openai => }/tool_parsers/step3_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/seed_oss_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/qwen3xml_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/qwen3coder_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/pythonic_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/phi4mini_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/openai_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/olmo3_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/mistral_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/minimax_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/minimax_m2_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/longcat_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/llama_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/llama4_pythonic_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/kimi_k2_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/jamba_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/internlm2_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/hunyuan_a13b_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/hermes_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/granite_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/granite_20b_fc_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/glm4_moe_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/gigachat3_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/ernie45_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/deepseekv3_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/deepseekv32_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/deepseekv31_tool_parser.py,60
vllm/{entrypoints/openai => }/tool_parsers/abstract_tool_parser.py,60
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_statictensor.py,60
vllm/entrypoints/pooling/score/utils.py,60
tests/weight_loading/models-large.txt,60
tests/models/language/pooling/test_cross_encoder.py,60
tests/models/decoder_only/vision_language/test_internvl.py,60
tests/models/decoder_only/vision_language/processing/test_llava_onevision.py,60
tests/encoder_decoder/__init__.py,60
docs/source/getting_started/installation/cpu.md,60
docs/source/getting_started/faq.md,60
docs/source/community/sponsors.md,60
csrc/quantization/gptq_marlin/marlin_dtypes.cuh,60
csrc/cub_helpers.h,60
.github/workflows/shellcheck.yml,60
.buildkite/run-tpu-v1-test.sh,60
vllm/model_executor/layers/quantization/kernels/machete.py,59
vllm/attention/ops/blocksparse_attention/__init__.py,59
tests/models/test_fuyu.py,59
tests/entrypoints/pooling/embed/test_offline.py,59
requirements/neuron.txt,59
requirements-openvino.txt,59
examples/other/fp8/quantizer/quantize.py,59
examples/other/fp8/quantizer/README.md,59
examples/other/fp8/extract_scales.py,59
examples/other/fp8/README.md,59
docs/source/features/quantization/bnb.md,59
docs/getting_started/installation/python_env_setup.inc.md,59
csrc/quantization/machete/machete_prepacked_layout.cuh,59
csrc/quantization/fp8/fp8_marlin.cu,59
csrc/cutlass_extensions/epilogue/scaled_mm_epilogues_c2x.hpp,59
cacheflow/core/block_manager.py,59
cacheflow/config.py,59
.buildkite/lm-eval-harness/configs/models-large.txt,59
vllm/utils/system_utils.py,58
vllm/model_executor/layers/conv.py,58
tests/models/decoder_only/vision_language/test_llava_next_video.py,58
requirements/tpu.txt,58
requirements/cpu-build.txt,58
docs/source/getting_started/installation/cpu-apple.md,58
docs/getting_started/installation/gpu.cuda.inc.md,58
csrc/quantization/gguf/dequantize.cuh,58
csrc/quantization/fused_kernels/layernorm_utils.cuh,58
cacheflow/core/server.py,58
benchmarks/kernels/deepgemm/README.md,58
vllm/distributed/ec_transfer/ec_connector/factory.py,57
vllm/attention/backends/mla/__init__.py,57
vllm/adapter_commons/__init__.py,57
csrc/quantization.cpp,57
cacheflow/server/ray_utils.py,57
cacheflow/model_executor/models/llama.py,57
Dockerfile.arm,57
.github/ISSUE_TEMPLATE/600-new-model.yml,57
.buildkite/test_areas/entrypoints.yaml,57
vllm/v1/executor/__init__.py,56
vllm/model_executor/parallel_utils/tensor_parallel/__init__.py,56
vllm/model_executor/layers/fused_moe/router/fused_topk_router.py,56
vllm/lora/ops/utils.py,56
vllm/entrypoints/openai/models/serving.py,56
tests/v1/ec_connector/integration/run_epd_correctness_test.sh,56
tests/lora/{test_transfomers_model.py => test_transformers_model.py},56
tests/evals/gsm8k/configs/moe-refactor-dp-ep/config-b200.txt,56
tests/engine/test_stop_checker.py,56
server.py,56
examples/others/logging_configuration.md,56
examples/online_serving/disaggregated_encoder/disagg_1e1pd_example.sh,56
examples/online_serving/disaggregated_encoder/disagg_1e1p1d_example.sh,56
examples/offline_inference_neuron.py,56
examples/offline_inference_encoder_decoder.py,56
examples/offline_inference/dolphin.py,56
docs/design/v1/metrics.md,56
docker/Dockerfile.rocm_base,56
docker/Dockerfile.rocm,56
csrc/quantization/cutlass_w8a8/moe/grouped_mm_c3x.cuh,56
benchmark/benchmark_latency.py,56
.buildkite/nightly-benchmarks/tests/genai-perf-tests.json,56
vllm/v1/pool/__init__.py,55
tests/utils_/test_torch_utils.py,55
tests/entrypoints/sagemaker/conftest.py,55
docs/source/design/multimodal/multimodal_index.rst,55
csrc/sparse/cutlass/sparse_compressor_entry.cu,55
csrc/sparse/cutlass/sparse_compressor_c3x.cu,55
csrc/quantization/fp4/activation_nvfp4_quant_fusion_kernels.cu,55
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_kernels.hpp,55
csrc/punica/type_convert.h,55
csrc/cpu/scratchpad_manager.h,55
csrc/cpu/scratchpad_manager.cpp,55
Dockerfile.s390x,55
.github/scripts/cleanup_pr_body.sh,55
.buildkite/run-benchmarks.sh,55
vllm/v1/engine/async_stream.py,54
vllm/entrypoints/pooling/base/protocol.py,54
vllm/entrypoints/openai/completion/serving.py,54
tests/models/{ => encoder_decoder/language}/test_bart.py,54
tests/models/{ => embedding/language}/test_embedding.py,54
tests/models/{ => decoder_only/vision_language}/test_qwen.py,54
tests/models/{ => decoder_only/vision_language}/test_pixtral.py,54
tests/models/{ => decoder_only/vision_language}/test_phi3v.py,54
tests/models/{ => decoder_only/vision_language}/test_paligemma.py,54
tests/models/{ => decoder_only/vision_language}/test_minicpmv.py,54
tests/models/{ => decoder_only/vision_language}/test_llava_next_video.py,54
tests/models/{ => decoder_only/vision_language}/test_llava_next.py,54
tests/models/{ => decoder_only/vision_language}/test_llava_image_embeds.py,54
tests/models/{ => decoder_only/vision_language}/test_llava.py,54
tests/models/{ => decoder_only/vision_language}/test_internvl.py,54
tests/models/{ => decoder_only/vision_language}/test_intern_vit.py,54
tests/models/{ => decoder_only/vision_language}/test_fuyu.py,54
tests/models/{ => decoder_only/vision_language}/test_chameleon.py,54
tests/models/{ => decoder_only/vision_language}/test_blip2.py,54
tests/models/{ => decoder_only/language}/test_phimoe.py,54
tests/models/{ => decoder_only/language}/test_models.py,54
tests/models/{ => decoder_only/language}/test_modelopt.py,54
tests/models/{ => decoder_only/language}/test_mistral.py,54
tests/models/{ => decoder_only/language}/test_marlin.py,54
tests/models/{ => decoder_only/language}/test_jamba.py,54
tests/models/{ => decoder_only/language}/test_granite.py,54
tests/models/{ => decoder_only/language}/test_gptq_marlin_24.py,54
tests/models/{ => decoder_only/language}/test_gptq_marlin.py,54
tests/models/{ => decoder_only/language}/test_gguf.py,54
tests/models/{ => decoder_only/language}/test_fp8.py,54
tests/models/{ => decoder_only/language}/test_danube3_4b.py,54
tests/models/{ => decoder_only/language}/test_big_models.py,54
tests/models/{ => decoder_only/language}/test_aqlm.py,54
tests/models/{ => decoder_only/audio_language}/test_ultravox.py,54
tests/models/multimodal/pooling/test_siglip.py,54
tests/models/embedding/language/__init__.py,54
tests/models/embedding/__init__.py,54
tests/models/decoder_only/vision_language/test_fuyu.py,54
tests/models/decoder_only/vision_language/__init__.py,54
tests/models/decoder_only/language/__init__.py,54
tests/models/decoder_only/audio_language/__init__.py,54
tests/models/decoder_only/__init__.py,54
tests/kernels/{test_cutlass.py => quantization/test_cutlass_scaled_mm.py},54
tests/kernels/{ => quantization}/test_triton_scaled_mm.py,54
tests/kernels/{ => quantization}/test_nvfp4_scaled_mm.py,54
tests/kernels/{ => quantization}/test_nvfp4_quant.py,54
tests/kernels/{ => quantization}/test_marlin_gemm.py,54
tests/kernels/{ => quantization}/test_machete_mm.py,54
tests/kernels/{ => quantization}/test_int8_quant.py,54
tests/kernels/{ => quantization}/test_int8_kernel.py,54
tests/kernels/{ => quantization}/test_gptq.py,54
tests/kernels/{ => quantization}/test_gguf.py,54
tests/kernels/{ => quantization}/test_ggml.py,54
tests/kernels/{ => quantization}/test_fp8_quant.py,54
tests/kernels/{ => quantization}/test_cutlass_2of4_sparse.py,54
tests/kernels/{ => quantization}/test_block_int8.py,54
tests/kernels/{ => quantization}/test_block_fp8.py,54
tests/kernels/{ => quantization}/test_awq_triton.py,54
tests/kernels/{ => quantization}/test_awq_marlin.py,54
tests/kernels/{ => quantization}/test_awq.py,54
tests/kernels/{ => quantization}/test_aqlm.py,54
tests/kernels/{ => quantization}/test_allspark_gemm.py,54
tests/kernels/{ => moe}/test_triton_moe_ptpc_fp8.py,54
tests/kernels/{ => moe}/test_moe.py,54
tests/kernels/{ => moe}/test_cutlass_moe.py,54
tests/kernels/{ => mamba}/test_mamba_ssm_ssd.py,54
tests/kernels/{ => mamba}/test_mamba_ssm.py,54
tests/kernels/{ => mamba}/test_mamba_mixer2.py,54
tests/kernels/{ => mamba}/test_causal_conv1d.py,54
tests/kernels/{ => core}/test_uva.py,54
tests/kernels/{ => core}/test_rotary_embedding.py,54
tests/kernels/{ => core}/test_pos_encoding.py,54
tests/kernels/{ => core}/test_permute_cols.py,54
tests/kernels/{ => core}/test_layernorm.py,54
tests/kernels/{ => core}/test_fused_quant_layernorm.py,54
tests/kernels/{ => core}/test_activation.py,54
tests/kernels/{ => attention}/test_triton_decode_attention.py,54
tests/kernels/{ => attention}/test_rocm_attention_selector.py,54
tests/kernels/{ => attention}/test_prefix_prefill.py,54
tests/kernels/{ => attention}/test_mla_decode_cpu.py,54
tests/kernels/{ => attention}/test_mha_attn.py,54
tests/kernels/{ => attention}/test_merge_attn_states.py,54
tests/kernels/{ => attention}/test_lightning_attn.py,54
tests/kernels/{ => attention}/test_flashmla.py,54
tests/kernels/{ => attention}/test_flashinfer.py,54
tests/kernels/{ => attention}/test_flash_attn.py,54
tests/kernels/{ => attention}/test_encoder_decoder_attn.py,54
tests/kernels/{ => attention}/test_cascade_flash_attn.py,54
tests/kernels/{ => attention}/test_cache.py,54
tests/kernels/{ => attention}/test_blocksparse_attention.py,54
tests/kernels/{ => attention}/test_attention_selector.py,54
tests/kernels/{ => attention}/test_attention.py,54
tests/kernels/{ => attention}/conftest.py,54
tests/entrypoints/openai/test_orca_metrics.py,54
tests/config/test_config_with_model.yaml,54
examples/others/lmcache/README.md,54
docs/source/dev/profiling/profiling_index.rst,54
docs/contributing/vulnerability_management.md,54
csrc/registration.h,54
csrc/cutlass_extensions/vllm_numeric_conversion.cuh,54
csrc/cutlass_extensions/cute_utils.cuh,54
RELEASE.md,54
.buildkite/nightly-benchmarks/benchmark-pipeline.yaml,54
"vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325_OAM,dtype=fp8_w8a8,block_shape=[128,128].json",53
"vllm/model_executor/layers/fused_moe/configs/E=256,N=1024,device_name=AMD_Instinct_MI325X,block_shape=[128,128].json",53
vllm/_core_ext.py,53
tests/tpu/__init__.py,53
docs/source/serving/usage_stats.md,53
docs/design/v1/torch_compile.md,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_entry.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c3x_sm90.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c3x_sm120.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c3x_sm100.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x_sm89_int8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x_sm89_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x_sm80_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x_sm75_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/scaled_mm_c2x.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/moe_data.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/grouped_mm_c3x_sm90.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/grouped_mm_c3x_sm100.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/grouped_mm_c3x.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/get_group_starts.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/moe/blockwise_scaled_group_mm_sm100.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm90_int8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm90_int8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm90_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm90_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm120_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm120_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm100_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_sm100_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_kernels.hpp,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_helper.hpp,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm90_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm90_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm120_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm120_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm100_fp8_dispatch.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_blockwise_sm100_fp8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm_azp_sm90_int8.cu,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/scaled_mm.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/c3x/cutlass_gemm_caller.cuh,53
csrc/quantization/{cutlass_w8a8 => w8a8/cutlass}/Epilogues.md,53
csrc/quantization/{compressed_tensors/int8_quant_kernels.cu => w8a8/int8/scaled_quant.cu},53
csrc/quantization/{ => w8a8}/per_token_group_quant_8bit.h,53
csrc/quantization/{ => w8a8}/fp8/per_token_group_quant.cu,53
csrc/quantization/{ => w8a8}/fp8/nvidia/quant_utils.cuh,53
csrc/quantization/{ => w8a8}/fp8/common.cuh,53
csrc/quantization/{ => w8a8}/fp8/common.cu,53
csrc/quantization/{ => w8a8}/fp8/amd/quant_utils.cuh,53
csrc/quantization/w8a8/int8/per_token_group_quant.cu,53
csrc/quantization/gguf/ggml-common.h,53
.buildkite/scripts/upload-wheels.sh,53
vllm/v1/attention/backends/mamba_selectors.py,52
tests/models/decoder_only/vision_language/test_minicpmv.py,52
tests/core/block/e2e/__init__.py,52
examples/online_serving/opentelemetry/README.md,52
docs/source/performance/optimization.md,52
docs/ci/update_pytorch_version.md,52
docker/Dockerfile.xpu,52
csrc/quantization/gguf/mmq.cuh,52
csrc/cpu/cpu_types_arm.hpp,52
cacheflow/frontend/fastapi_frontend.py,52
.github/workflows/actionlint.yml,52
vllm/{model_executor/parallel_utils => distributed}/utils.py,51
vllm/{model_executor/parallel_utils => distributed}/parallel_state.py,51
vllm/{model_executor/parallel_utils => distributed}/communication_op.py,51
vllm/{model_executor/parallel_utils => distributed/device_communicators}/pynccl_utils.py,51
vllm/{model_executor/parallel_utils => distributed/device_communicators}/pynccl.py,51
vllm/{model_executor/parallel_utils => distributed/device_communicators}/custom_all_reduce.py,51
vllm/{model_executor/parallel_utils => distributed/device_communicators}/__init__.py,51
vllm/v1/worker/ec_connector_model_runner_mixin.py,51
vllm/utils/{functools.py => func_utils.py},51
vllm/utils/{collections.py => collection_utils.py},51
vllm/utils/{asyncio.py => async_utils.py},51
vllm/model_executor/parallel_utils/README.md,51
vllm/lora/__init__.py,51
vllm/entrypoints/serve/__init__.py,51
vllm/entrypoints/anthropic/__init__.py,51
tools/sphinx-lint.sh,51
tests/v1/tpu/__init__.py,51
tests/utils_/{test_collections.py => test_collection_utils.py},51
tests/utils_/test_mem_utils.py,51
tests/utils_/test_hashing.py,51
tests/reasoning/test_ernie45_reasoning_parser.py,51
tests/models/language/generation/test_mbart.py,51
tests/lora/__init__.py,51
tests/entrypoints/openai/test_vision_embeds.py,51
docs/features/quantization/inc.md,51
docker/Dockerfile.neuron,51
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-Channelwise-compressed-tensors.yaml,51
vllm/model_executor/quantization_utils/squeezellm.py,50
vllm/model_executor/layers/quantized_linear/squeezellm.py,50
tests/model_executor/test_eagle_quantization.py,50
tests/lora/test_moe_lora_align_sum.py,50
tests/async_engine/__init__.py,50
plot/plot_stats.py,50
plot/plot_normalized_latency.py,50
examples/openai_cross_encoder_score.py,50
examples/online_serving/prometheus_grafana/README.md,50
docs/source/getting_started/installation/gpu-cuda.md,50
docs/source/design/automatic_prefix_caching.md,50
docs/models/extensions/fastsafetensor.md,50
csrc/moe/moe_lora_align_sum_kernels.cu,50
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-FP8.yaml,50
vllm/transformers_utils/chat_templates/template_minicpmv45.jinja,49
vllm/model_executor/layers/quantization/kernels/__init__.py,49
vllm/model_executor/layers/attention/static_sink_attention.py,49
vllm/model_executor/layers/attention/encoder_only_attention.py,49
vllm/model_executor/layers/attention/chunked_local_attention.py,49
vllm/entrypoints/openai/translations/api_router.py,49
tests/v1/determinism/test_batch_invariance.py,49
tests/kv_transfer/test_send_recv.sh,49
tests/kv_transfer/test_lookup_buffer.sh,49
tests/entrypoints/openai/test_uds.py,49
requirements-xpu.txt => requirements/xpu.txt,49
requirements-tpu.txt => requirements/tpu.txt,49
requirements-test.txt => requirements/test.txt,49
requirements-test.in => requirements/test.in,49
requirements-rocm.txt => requirements/rocm.txt,49
requirements-rocm-build.txt => requirements/rocm-build.txt,49
requirements-openvino.txt => requirements/openvino.txt,49
requirements-neuron.txt => requirements/neuron.txt,49
requirements-neuron.txt,49
requirements-lint.txt => requirements/lint.txt,49
requirements-hpu.txt => requirements/hpu.txt,49
requirements-dev.txt => requirements/dev.txt,49
requirements-cuda.txt => requirements/cuda.txt,49
requirements-cpu.txt => requirements/cpu.txt,49
requirements-common.txt => requirements/common.txt,49
requirements-build.txt => requirements/build.txt,49
examples/offline_inference/kv_load_failure_recovery/prefill_example.py,49
examples/offline_inference/kv_load_failure_recovery/decode_example.py,49
examples/offline_inference/kv_load_failure_recovery/README.md,49
examples/fp8/quantizer/quantize.py,49
docs/source/design/mm_processing.md,49
docs/requirements-docs.txt => requirements/docs.txt,49
csrc/quantization/cutlass_w8a8/moe/grouped_mm_c3x.cu,49
csrc/core/torch_bindings.cpp,49
.buildkite/test_areas/distributed.yaml,49
vllm/model_executor/parallel_utils/utils.py,48
vllm/inputs.py,48
tests/models/multimodal/pooling/conftest.py,48
tests/entrypoints/pooling/classify/test_online_vision.py,48
tests/core/block/__init__.py,48
requirements/rocm-test.txt,48
examples/openai_api_client_for_multimodal.py,48
docs/source/serving/integrations/llamaindex.md,48
docs/source/serving/integrations/langchain.md,48
docs/source/getting_started/installation/tpu.md,48
docs/source/getting_started/installation/openvino.md,48
docs/source/getting_started/installation/neuron.md,48
docs/source/dev/multimodal/adding_multimodal_model.rst,48
docs/source/deployment/integrations/llamastack.md,48
csrc/cutlass_extensions/gemm/collective/sm90_mma_tma_gmma_ss_warpspecialized_fp8_blockwise_scaling.hpp,48
csrc/cpu/dnnl_helper.hpp,48
.github/workflows/{sphinx-lint.yml => doc-lint.yml},48
.buildkite/scripts/hardware_ci/run-neuron-test.sh,48
vllm/utils/network_utils.py,47
vllm/renderers/terratorch.py,47
vllm/renderers/registry.py,47
vllm/renderers/protocol.py,47
vllm/renderers/mistral.py,47
vllm/renderers/hf.py,47
vllm/renderers/grok2.py,47
vllm/renderers/deepseek_v32.py,47
vllm/renderers/__init__.py,47
vllm/executor/multiproc_xpu_executor.py,47
vllm/entrypoints/serve/profile/api_router.py,47
vllm/entrypoints/openai/responses/context.py,47
vllm/entrypoints/openai/completion/protocol.py,47
vllm/entrypoints/anthropic/api_server.py,47
tests/v1/tpu/worker/__init__.py,47
tests/v1/determinism/test_rms_norm_batch_invariant.py,47
tests/renderers/test_mistral.py,47
tests/renderers/test_hf.py,47
tests/renderers/__init__.py,47
tests/multimodal/{test_base.py => test_inputs.py},47
tests/entrypoints/test_server_oot_registration.py,47
docs/source/models/spec_decode.rst,47
vllm/{model_executor/layers => }/attention/ops/prefix_prefill.py,46
vllm/{model_executor/layers => }/attention/ops/__init__.py,46
vllm/{model_executor/layers => }/attention/backends/xformers.py,46
vllm/{model_executor/layers => }/attention/backends/__init__.py,46
vllm/v1/worker/cp_utils.py,46
vllm/lora/ops/__init__.py,46
vllm/entrypoints/openai/completion/api_router.py,46
tests/compile/test_full_graph_smoke.py,46
tests/compile/test_full_graph_multi_gpu.py,46
examples/fp8/quantizer/README.md,46
docs/cli/serve.md,46
docs/cli/run-batch.md,46
docs/cli/complete.md,46
docs/cli/chat.md,46
docs/cli/bench/throughput.md,46
docs/cli/bench/serve.md,46
docs/cli/bench/latency.md,46
csrc/quantization/vectorization.cuh,46
csrc/quantization/machete/Readme.md,46
cacheflow/model_executor/parallel_utils/__init__.py,46
.github/workflows/pylint.yml,46
vllm/transformers_utils/configs/qwen.py,45
vllm/entrypoints/openai/translations/speech_to_text.py,45
tests/worker/test_worker.py,45
tests/v1/determinism/test_online_batch_invariance.py,45
tests/models/decoder_only/language/test_qwen.py,45
tests/kernels/test_semi_structured.py,45
tests/kernels/pos_encoding.py,45
examples/online_serving/chart-helm/values.yaml,45
examples/offline_inference/{offline_profile.py => profiling.py},45
examples/offline_inference/{offline_inference_with_profiler.py => simple_profiling.py},45
examples/offline_inference/{offline_inference_with_prefix.py => prefix_caching.py},45
examples/offline_inference/{offline_inference_with_default_generation_config.py => basic_with_model_default_sampling.py},45
examples/offline_inference/{offline_inference_whisper.py => whisper.py},45
examples/offline_inference/{offline_inference_vision_language_multi_image.py => vision_language_multi_image.py},45
examples/offline_inference/{offline_inference_vision_language_embedding.py => vision_language_embedding.py},45
examples/offline_inference/{offline_inference_vision_language.py => vision_language.py},45
examples/offline_inference/{offline_inference_tpu.py => tpu.py},45
examples/offline_inference/{offline_inference_structured_outputs.py => structured_outputs.py},45
examples/offline_inference/{offline_inference_scoring.py => scoring.py},45
examples/offline_inference/{offline_inference_pixtral.py => pixtral.py},45
examples/offline_inference/{offline_inference_openai/offline_inference_openai.md => openai/openai_batch.md},45
examples/offline_inference/{offline_inference_openai => openai}/openai_example_batch.jsonl,45
examples/offline_inference/{offline_inference_neuron_int8_quantization.py => neuron_int8_quantization.py},45
examples/offline_inference/{offline_inference_neuron.py => neuron.py},45
examples/offline_inference/{offline_inference_mlpspeculator.py => mlpspeculator.py},45
examples/offline_inference/{offline_inference_encoder_decoder.py => encoder_decoder.py},45
examples/offline_inference/{offline_inference_embedding.py => embedding.py},45
examples/offline_inference/{offline_inference_distributed.py => distributed.py},45
examples/offline_inference/{offline_inference_cli.py => cli.py},45
examples/offline_inference/{offline_inference_classification.py => classification.py},45
examples/offline_inference/{offline_inference_chat.py => chat.py},45
examples/offline_inference/{offline_inference_audio_language.py => audio_language.py},45
examples/offline_inference/{offline_inference_arctic.py => arctic.py},45
examples/offline_inference/{offline_inference.py => basic.py},45
examples/offline_inference/{offline_chat_with_tools.py => chat_with_tools.py},45
docs/cli/bench/sweep/serve_sla.md,45
docs/cli/bench/sweep/serve.md,45
docs/cli/bench/sweep/plot.md,45
csrc/quantization/gptq_marlin/marlin_int4_fp8_preprocess.cu,45
csrc/quantization/gguf/vecdotq.cuh,45
cacheflow/http_frontend/fastapi_frontend.py,45
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-FBGEMM-nonuniform.yaml,45
vllm/transformers_utils/configs/baichuan.py,44
vllm/model_executor/layers/fused_moe/{routing_simulator.py => router/routing_simulator_router.py},44
vllm/model_executor/layers/fused_moe/{ => router}/fused_moe_router.py,44
vllm/model_executor/layers/fused_moe/router/__init__.py,44
vllm/entrypoints/serve/sleep/api_router.py,44
vllm/distributed/kv_transfer/kv_pipe/__init__.py,44
vllm/distributed/kv_transfer/kv_lookup_buffer/__init__.py,44
vllm/core/{block_manager_v2.py => block_manager.py},44
vllm/commit_id.py,44
tests/{ => kernels/moe}/test_routing_simulator.py,44
tests/v1/ec_connector/integration/test_epd_correctness.py,44
tests/v1/e2e/test_async_spec_decode.py,44
tests/standalone_tests/pytorch_nightly_dependency.sh,44
tests/models/test_qwen.py,44
tests/models/test_llava_image_embeds.py,44
tests/core/block/{test_block_manager_v2.py => test_block_manager.py},44
examples/online_serving/elastic_ep/serve_deepseek_v2.sh,44
docs/source/{usage/performance.md => performance/optimization.md},44
docs/source/{usage => serving}/usage_stats.md,44
docs/source/{usage => serving}/env_vars.md,44
docs/source/{usage => serving}/engine_args.md,44
docs/source/{usage => features}/tool_calling.md,44
docs/source/{usage => features}/structured_outputs.md,44
docs/source/{usage => features}/spec_decode.md,44
docs/source/{usage => features}/multimodal_inputs.md,44
docs/source/{usage => features}/lora.md,44
docs/source/{usage => features}/disagg_prefill.md,44
docs/source/{usage => features}/compatibility_matrix.md,44
docs/source/{models/enabling_multimodal_inputs.md => contributing/model/multimodal.md},44
docs/source/{automatic_prefix_caching/details.md => design/automatic_prefix_caching.md},44
docs/source/{automatic_prefix_caching/apc.md => features/automatic_prefix_caching.md},44
docs/source/{ => features}/quantization/supported_hardware.md,44
docs/source/{ => features}/quantization/int8.md,44
docs/source/{ => features}/quantization/gguf.md,44
docs/source/{ => features}/quantization/fp8_e5m2_kvcache.md,44
docs/source/{ => features}/quantization/fp8_e4m3_kvcache.md,44
docs/source/{ => features}/quantization/fp8.md,44
docs/source/{ => features}/quantization/bnb.md,44
docs/source/{ => features}/quantization/auto_awq.md,44
docs/source/assets/{usage => features}/disagg_prefill/overview.jpg,44
docs/source/assets/{usage => features}/disagg_prefill/abstraction.jpg,44
csrc/cpu/cpu_attn.cpp,44
.github/workflows/{pylint.yml => ruff.yml},44
.buildkite/scripts/tpu/run_bm.sh,44
.buildkite/scripts/generate-nightly-index.py,44
.buildkite/nightly-benchmarks/tests/serving-tests-cpu.json,44
vllm/transformers_utils/configs/aquila.py,43
vllm/model_executor/layers/attention/mm_encoder_attention.py,43
tests/models/decoder_only/vision_language/test_glm4.py,43
tests/kernels/quantization/test_awq_marlin.py,43
tests/entrypoints/test_llm_generate.py,43
tests/entrypoints/llm/test_embedding.py,43
tests/compile/fullgraph/test_basic_correctness.py,43
examples/pooling/pooling/vision_language_pooling.py,43
examples/offline_inference/basic/README.md,43
csrc/quantization/fp8_e5m2_kvcache/quant_utils.cuh,43
csrc/quantization/cutlass_w8a8/c3x/scaled_mm.cuh,43
csrc/cpu/utils.hpp,43
csrc/cpu/micro_gemm/cpu_micro_gemm_vec.hpp,43
csrc/cpu/micro_gemm/cpu_micro_gemm_impl.hpp,43
csrc/cpu/micro_gemm/cpu_micro_gemm_amx.hpp,43
csrc/cpu/cpu_wna16.cpp,43
csrc/activation.cpp,43
benchmarks/launch_tgi_server.sh,43
vllm/worker/spec_decode/multi_step_worker.py,42
vllm/v1/worker/gpu/sample/sampler.py,42
vllm/v1/worker/gpu/block_table.py,42
vllm/model_executor/parallel_utils/pynccl.py,42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/fused_moe/configs/E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json",42
"vllm/model_executor/layers/fused_moe/configs/E=16,N=1024,device_name=AMD_Instinct_MI300X.json",42
vllm/executor/{ray_gpu_executor.py => ray_distributed_executor.py},42
vllm/executor/{multiproc_gpu_executor.py => mp_distributed_executor.py},42
vllm/executor/__init__.py,42
vllm/entrypoints/openai/{serving_models.py => models/serving.py},42
vllm/entrypoints/openai/{serving_completion.py => completion/serving.py},42
vllm/entrypoints/openai/translations/serving.py,42
vllm/entrypoints/openai/tool_parsers/olmo3_tool_parser.py,42
vllm/entrypoints/openai/models/protocol.py,42
vllm/entrypoints/openai/models/api_router.py,42
vllm/entrypoints/openai/models/__init__.py,42
vllm/entrypoints/openai/completion/__init__.py,42
vllm/entrypoints/anthropic/{serving_messages.py => serving.py},42
vllm/entrypoints/anthropic/api_router.py,42
tools/shellcheck.sh,42
tests/{runai_model_streamer => runai_model_streamer_test}/test_weight_utils.py,42
tests/{runai_model_streamer => runai_model_streamer_test}/test_runai_model_streamer_loader.py,42
tests/{runai_model_streamer => runai_model_streamer_test}/__init__.py,42
tests/kv_transfer/{module_test.py => test_module.py},42
tests/kv_transfer/{disagg_test.py => test_disagg.py},42
tests/entrypoints/test_llm_encode.py,42
tests/entrypoints/pooling/score/test_correctness_mteb.py,42
tests/entrypoints/pooling/embed/test_correctness_mteb.py,42
tests/entrypoints/openai/test_lora_lineage.py,42
tests/entrypoints/openai/rpc/test_zmq_client.py,42
examples/online_serving/disaggregated_serving_p2p_nccl_xpyd/disagg_example_p2p_nccl_xpyd.sh,42
docs/source/{offline_inference => dev}/sampling_params.rst,42
docs/source/{ => dev}/offline_inference/llm.rst,42
.github/workflows/pre-commit.yml,42
vllm/v1/worker/mamba_utils.py,41
vllm/transformers_utils/configs/yi.py,41
vllm/model_executor/parallel_utils/{tensor_parallel => }/utils.py,41
vllm/model_executor/parallel_utils/tensor_parallel/random.py,41
vllm/model_executor/parallel_utils/tensor_parallel/mappings.py,41
vllm/model_executor/parallel_utils/__init__.py,41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2304,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2304,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=1152,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=1152,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=1024,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=1024,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=512,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4608,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4608,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4096,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4096,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=3072,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=3072,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=3072,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=256,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=2304,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=2304,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=2048,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=2048,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=1536,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=1536,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/quantization/utils/configs/{N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => N=1536,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
vllm/model_executor/layers/pooler/special.py,41
vllm/model_executor/layers/pooler/common.py,41
"vllm/model_executor/layers/fused_moe/configs/{E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json => E=256,N=256,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json}",41
"vllm/model_executor/layers/fused_moe/configs/{E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128, 128].json => E=256,N=128,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json}",41
tests/v1/test_external_lb_dp.py,41
tests/v1/kv_connector/nixl_integration/tp_config_sweep_accuracy_test.sh,41
tests/v1/e2e/test_mamba_prefix_cache.py,41
tests/v1/e2e/test_async_sched_and_preempt.py,41
tests/entrypoints/pooling/score/test_offline.py,41
tests/core/block/test_block_space_manager.py,41
csrc/quantization/cutlass_w8a8/common.hpp,41
vllm/worker/cpu_embedding_model_runner.py,40
vllm/utils/mem_utils.py,40
vllm/tokenizers/hf.py,40
vllm/model_executor/layers/fused_moe/all2all_utils.py,40
vllm/lora/model_manager.py,40
tests/utils_/test_import_utils.py,40
tests/models/language/pooling/test_multi_vector_retrieval.py,40
tests/models/decoder_only/vision_language/test_chameleon.py,40
tests/lora/test_gptoss.py,40
examples/pooling/score/online_using_template.py,40
examples/pooling/score/offline_using_template.py,40
examples/openai_embedding_client.py,40
examples/online_serving/pooling/multi_vector_retrieval_client.py,40
docs/source/serving/compatibility_matrix.rst,40
docs/source/quantization/{fp8_e5m2_kv_cache.rst => fp8_e5m2_kvcache.rst},40
csrc/quantization/fp8/amd_detail/quant_utils.cuh,40
csrc/quantization/fp8/amd_detail/hip_float8_impl.h,40
csrc/quantization/fp8/amd_detail/hip_float8.h,40
csrc/layernorm.cpp,40
csrc/cpu/sgl-kernels/vec.h,40
csrc/cpu/sgl-kernels/gemm_int8.cpp,40
csrc/cpu/sgl-kernels/gemm.h,40
csrc/cpu/sgl-kernels/common.h,40
csrc/attention/{dtype_fp8_e5m2.cuh => dtype_fp8.cuh},40
cacheflow/master/block_manager.py,40
cacheflow/entrypoints/simple_fastapi_frontend.py,40
cacheflow/entrypoints/openai/openai_frontend.py,40
.buildkite/lm-eval-harness/run-tests.sh,40
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-FP8-compressed-tensors.yaml,40
vllm/model_executor/guided_decoding/reasoner/reasoner.py,39
vllm/model_executor/guided_decoding/reasoner/deepseek_reasoner.py,39
tests/utils_/test_argparse_utils.py,39
tests/pplx_utils.py,39
tests/multimodal/test_processor.py,39
tests/models/test_ultravox.py,39
tests/models/test_jamba.py,39
tests/entrypoints/openai/test_mp_api_server.py,39
requirements/hpu.txt,39
requirements-mamba.txt,39
examples/production_monitoring/Otel.md,39
docs/source/{serving/serving_with_llamastack.md => deployment/integrations/llamastack.md},39
docs/source/{serving/run_on_sky.md => deployment/frameworks/skypilot.md},39
docs/source/{serving/deploying_with_triton.md => deployment/frameworks/triton.md},39
docs/source/{serving/deploying_with_nginx.md => deployment/nginx.md},39
docs/source/{serving/deploying_with_lws.md => deployment/frameworks/lws.md},39
docs/source/{serving/deploying_with_kubeai.md => deployment/integrations/kubeai.md},39
docs/source/{serving/deploying_with_kserve.md => deployment/integrations/kserve.md},39
docs/source/{serving/deploying_with_k8s.md => deployment/k8s.md},39
docs/source/{serving/deploying_with_helm.md => deployment/frameworks/helm.md},39
docs/source/{serving/deploying_with_dstack.md => deployment/frameworks/dstack.md},39
docs/source/{serving/deploying_with_docker.md => deployment/docker.md},39
docs/source/{serving/deploying_with_cerebrium.md => deployment/frameworks/cerebrium.md},39
docs/source/{serving/deploying_with_bentoml.md => deployment/frameworks/bentoml.md},39
docs/source/{serving => models/extensions}/tensorizer.md,39
docs/source/{serving => models/extensions}/runai_model_streamer.md,39
docs/source/{serving => assets/deployment}/architecture_helm_deployment.png,39
docs/source/{features => serving}/multimodal_inputs.md,39
docs/source/serving/{serving_with_llamaindex.md => integrations/llamaindex.md},39
docs/source/serving/{serving_with_langchain.md => integrations/langchain.md},39
docs/getting_started/installation/gpu.rocm.inc.md,39
csrc/quantization/marlin/dense/common/mem.h,39
csrc/quantization/marlin/dense/common/base.h,39
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_blockwise_sm90_fp8_dispatch.cuh,39
cacheflow/{models/utils.py => model_executor/weight_utils.py},39
cacheflow/{models/sample.py => model_executor/layers/sampler.py},39
cacheflow/{models/model_utils.py => model_executor/model_loader.py},39
cacheflow/{models => model_executor}/memory_analyzer.py,39
cacheflow/{models => model_executor}/input_metadata.py,39
cacheflow/{models => model_executor/layers}/layernorm.py,39
cacheflow/{models => model_executor/layers}/attention.py,39
cacheflow/{models => model_executor/layers}/activation.py,39
cacheflow/{master => frontend}/simple_frontend.py,39
cacheflow/{master => core}/server.py,39
cacheflow/{master => core}/scheduler.py,39
cacheflow/{master => core}/policy.py,39
cacheflow/{master => core}/block_manager.py,39
cacheflow/{http_frontend => frontend}/fastapi_frontend.py,39
cacheflow/{ => model_executor}/parallel_utils/utils.py,39
cacheflow/{ => model_executor}/parallel_utils/tensor_parallel/utils.py,39
cacheflow/{ => model_executor}/parallel_utils/tensor_parallel/random.py,39
cacheflow/{ => model_executor}/parallel_utils/tensor_parallel/mappings.py,39
cacheflow/{ => model_executor}/parallel_utils/tensor_parallel/layers.py,39
cacheflow/{ => model_executor}/parallel_utils/tensor_parallel/__init__.py,39
cacheflow/{ => model_executor}/parallel_utils/parallel_state.py,39
cacheflow/{ => model_executor}/parallel_utils/README.md,39
cacheflow/{ => model_executor}/models/opt.py,39
cacheflow/{ => model_executor}/models/llama.py,39
cacheflow/{ => model_executor}/models/gpt_neox.py,39
cacheflow/{ => model_executor}/models/gpt2.py,39
cacheflow/http_frontend/test_cli_client.py => test_cli_client.py,39
cacheflow/http_frontend/gradio_webserver.py => gradio_webserver.py,39
cacheflow/entrypoints/fastapi_server.py,39
benchmarks/kernels/bench_block_fp8_gemm.py,39
.buildkite/run-multi-node-test.sh,39
vllm/v1/worker/gpu/sampler.py,38
vllm/entrypoints/{openai/serving_score.py => pooling/score/serving.py},38
vllm/entrypoints/{openai/serving_pooling.py => pooling/pooling/serving.py},38
vllm/entrypoints/{openai/serving_embedding.py => pooling/embed/serving.py},38
vllm/entrypoints/{openai/serving_classification.py => pooling/classify/serving.py},38
vllm/entrypoints/pooling/score/__init__.py,38
vllm/entrypoints/pooling/pooling/__init__.py,38
vllm/entrypoints/pooling/embed/__init__.py,38
vllm/entrypoints/pooling/classify/__init__.py,38
tests/{mistral_tool_use => tool_use/mistral}/utils.py,38
tests/{mistral_tool_use => tool_use/mistral}/test_mistral_tool_calls.py,38
tests/{mistral_tool_use => tool_use/mistral}/conftest.py,38
tests/{mistral_tool_use => tool_use/mistral}/__init__.py,38
tests/prefix_caching/__init__.py,38
tests/models/decoder_only/vision_language/test_llava_next.py,38
examples/pooling/score/qwen3_reranker_online.py,38
csrc/quantization/fp4/nvfp4_utils.cuh,38
csrc/quantization/fp4/nvfp4_blockwise_moe_kernel.cu,38
cacheflow/block.py,38
.yapfignore,38
.github/workflows/codespell.yml,38
.buildkite/nightly-benchmarks/tests/serving-tests-cpu-snc3.json,38
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-INT8-compressed-tensors.yaml,38
vllm/v1/attention/backends/mla/aiter_triton_mla.py,37
vllm/model_executor/models/lfm2_siglip2.py,37
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8_dynamictoken.py,37
vllm/model_executor/layers/fused_moe/oracle/__init__.py,37
tests/models/decoder_only/vision_language/{ => mm_processor_kwargs}/test_qwen2_vl.py,37
tests/models/decoder_only/vision_language/vlm_utils/__init__.py,37
tests/models/decoder_only/vision_language/test_llava_image_embeds.py,37
tests/models/decoder_only/vision_language/test_llava.py,37
tests/models/decoder_only/vision_language/test_blip2.py,37
tests/models/decoder_only/vision_language/mm_processor_kwargs/__init__.py,37
tests/kernels/quantization/test_scaled_mm_kernel_selection.py,37
tests/evals/gsm8k/configs/moe-refactor/{Qwen3-30B-A3B-Fp8-CT-Block-vllm-cutlass.yaml => Qwen3-30B-A3B-Fp8-CT-Block-triton.yaml},37
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-Fp8-CT-vllm-cutlass.yaml,37
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-NvFp4-CT-fi-cutlass.yaml,37
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-CT-Block-deepgemm.yaml,37
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-CT-Block-deepgemm-deepep-ht.yaml,37
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-AutoFp8-deepgemm.yaml,37
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-Fp8-AutoFp8-deepgemm-deepep-ht.yaml,37
docs/source/quantization/supported_hardware.rst,37
docs/source/design/v1/prefix_caching.md,37
docs/cli/.nav.yml,37
csrc/quantization/w8a8/cutlass/scaled_mm_entry.cu,37
cacheflow/server/async_llm_server.py,37
benchmarks/kernels/benchmark_silu_mul_fp8_quant.py,37
.buildkite/test_areas/attention.yaml,37
vllm/model_executor/models/transformers/legacy.py,36
vllm/model_executor/layers/triton_kernel/prefix_prefill.py,36
"vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",36
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",36
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3.json",36
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",36
vllm/core/evictor_v2.py,36
vllm/benchmarks/sweep/serve_sla.py,36
tests/utils_/test_network_utils.py,36
tests/kernels/cache.py,36
tests/entrypoints/openai/test_serving_tokens.py,36
tests/config/test_config.yaml,36
examples/pooling/score/convert_model_to_seq_cls.py,36
examples/aqlm_example.py,36
docs/source/design/v1/metrics.md,36
docs/source/design/class_hierarchy.rst,36
csrc/type_convert.cuh,36
csrc/moe/marlin_kernels/marlin_moe_kernel_ku8b128.h,36
csrc/moe/marlin_kernels/marlin_moe_kernel_ku8b128.cu,36
csrc/moe/marlin_kernels/marlin_moe_kernel_ku4b8.h,36
csrc/moe/marlin_kernels/marlin_moe_kernel_ku4b8.cu,36
csrc/cutlass_extensions/gemm/dispatch_policy.hpp,36
csrc/cutlass_extensions/gemm/collective/fp8_accumulation.hpp,36
csrc/cutlass_extensions/gemm/collective/collective_builder.hpp,36
csrc/cpu/cpu_attn_amx.hpp,36
cacheflow/frontend/simple_frontend.py,36
.github/workflows/scripts/cuda-install.sh,36
vllm/model_executor/models/mistral_large_3_eagle.py,35
vllm/engine/output_processor/__init__.py,35
tools/actionlint.sh,35
tests/{entrypoints/openai/rpc => mq_llm_engine}/__init__.py,35
tests/{async_engine => entrypoints/openai}/test_chat_template.py,35
tests/v1/ec_connector/integration/README.md,35
tests/async_engine/test_openapi_server.py,35
requirements-hpu.txt,35
examples/{online_serving/pooling/prithvi_geospatial_mae.py => pooling/plugin/prithvi_geospatial_mae_client.py},35
examples/{online_serving/pooling => pooling/token_embed}/multi_vector_retrieval_client.py,35
examples/{online_serving/pooling => pooling/token_classify}/ner_client.py,35
examples/{online_serving/pooling => pooling/score}/openai_cross_encoder_score_for_multimodal.py,35
examples/{online_serving/pooling => pooling/score}/openai_cross_encoder_score.py,35
examples/{online_serving/pooling => pooling/score}/jinaai_rerank_client.py,35
examples/{online_serving/pooling => pooling/score}/cohere_rerank_client.py,35
examples/{online_serving/pooling => pooling/embed}/openai_embedding_matryoshka_fy.py,35
examples/{online_serving/pooling => pooling/embed}/openai_embedding_client.py,35
examples/{online_serving/pooling => pooling/embed}/openai_chat_embedding_client_for_multimodal.py,35
examples/{online_serving/pooling => pooling/embed}/embedding_requests_bytes_client.py,35
examples/{online_serving/pooling => pooling/embed}/embedding_requests_base64_client.py,35
examples/{online_serving/pooling => pooling/classify}/openai_classification_client.py,35
examples/{online_serving => pooling}/pooling/openai_pooling_client.py,35
examples/{online_serving => pooling/embed}/openai_embedding_long_text/service.sh,35
examples/{online_serving => pooling/embed}/openai_embedding_long_text/client.py,35
examples/{online_serving => pooling/embed}/openai_embedding_long_text/README.md,35
examples/{offline_inference/pooling/prithvi_geospatial_mae.py => pooling/plugin/prithvi_geospatial_mae_offline.py},35
examples/{offline_inference/pooling => pooling/token_embed}/multi_vector_retrieval.py,35
examples/{offline_inference/pooling => pooling/token_classify}/ner.py,35
examples/{offline_inference/pooling => pooling/score}/qwen3_reranker.py,35
examples/{offline_inference/pooling => pooling/score}/convert_model_to_seq_cls.py,35
examples/{offline_inference/pooling => pooling/plugin}/prithvi_geospatial_mae_io_processor.py,35
examples/{offline_inference/pooling => pooling/embed}/embed_matryoshka_fy.py,35
examples/{offline_inference/pooling => pooling/embed}/embed_jina_embeddings_v3.py,35
examples/{offline_inference => pooling/pooling}/vision_language_pooling.py,35
examples/openai_audio_api_client.py,35
docs/source/quantization/supported_hardware.md,35
csrc/quantization/cutlass_w8a8/moe/get_group_starts.cuh,35
csrc/quantization/cutlass_w8a8/c3x/cutlass_gemm_caller.cuh,35
csrc/punica/bgmv/bgmv_fp32_fp32_fp16.cu,35
csrc/punica/bgmv/bgmv_fp32_fp32_bf16.cu,35
csrc/punica/bgmv/bgmv_fp32_fp16_bf16.cu,35
csrc/punica/bgmv/bgmv_fp32_bf16_fp16.cu,35
csrc/punica/bgmv/bgmv_fp16_fp32_bf16.cu,35
csrc/punica/bgmv/bgmv_fp16_fp16_bf16.cu,35
csrc/punica/bgmv/bgmv_fp16_bf16_fp16.cu,35
csrc/punica/bgmv/bgmv_fp16_bf16_bf16.cu,35
csrc/punica/bgmv/bgmv_bf16_fp32_fp16.cu,35
csrc/punica/bgmv/bgmv_bf16_fp16_fp16.cu,35
csrc/punica/bgmv/bgmv_bf16_fp16_bf16.cu,35
csrc/punica/bgmv/bgmv_bf16_bf16_fp16.cu,35
csrc/moe/permute_unpermute_kernels/moe_permute_unpermute_kernel.cu,35
.buildkite/lm-eval-harness/configs/Qwen2-1.5B-Instruct-W8A16-compressed-tensors.yaml,35
vllm/model_executor/parallel_utils/pynccl_utils.py,34
vllm/model_executor/layers/{triton_kernel => attention/ops}/prefix_prefill.py,34
vllm/model_executor/layers/{triton_kernel => attention/backends}/__init__.py,34
vllm/model_executor/layers/{attention.py => attention/backends/xformers.py},34
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w8a8.py,34
vllm/model_executor/layers/attention/ops/__init__.py,34
vllm/distributed/ec_transfer/ec_connector/base.py,34
vllm/compilation/compile_context.py,34
tests/plugins/prithvi_io_processor_plugin/setup.py,34
tests/plugins/prithvi_io_processor_plugin/prithvi_io_processor/__init__.py,34
csrc/cpu/cpu_types_vsx.hpp,34
csrc/cpu/cpu_attn_macros.h,34
benchmark/benchmark_text_completion.py,34
.github/workflows/png-lint.yml,34
.buildkite/test_areas/pytorch.yaml,34
.buildkite/test_areas/models_basic.yaml,34
.buildkite/test_areas/lora.yaml,34
.buildkite/test_areas/lm_eval.yaml,34
.buildkite/test_areas/e2e_integration.yaml,34
.buildkite/scripts/run-benchmarks.sh,34
.buildkite/scripts/hardware_ci/run-tpu-v1-test-part2.sh,34
.buildkite/nightly-benchmarks/scripts/run-vllm-nightly.sh,34
.buildkite/nightly-benchmarks/scripts/run-trt-nightly.sh,34
.buildkite/nightly-benchmarks/scripts/run-tgi-nightly.sh,34
.buildkite/nightly-benchmarks/scripts/run-lmdeploy-nightly.sh,34
.buildkite/nightly-benchmarks/scripts/plot-nightly-results.py,34
.buildkite/nightly-benchmarks/scripts/launch-trt-server.sh,34
.buildkite/nightly-benchmarks/run-nightly-suite.sh,34
.buildkite/lm-eval-harness/configs/Qwen2-1.5B-Instruct-FP8W8.yaml,34
vllm/utils/serial_utils.py,33
vllm/utils/func.py,33
vllm/model_executor/layers/pooler/tokwise/__init__.py,33
vllm/model_executor/layers/pooler/seqwise/__init__.py,33
vllm/model_executor/layers/pooler/activations.py,33
vllm/model_executor/layers/pooler/abstract.py,33
vllm/model_executor/layers/pooler/__init__.py,33
vllm/distributed/ec_transfer/ec_connector/example_connector.py,33
vllm/benchmarks/sweep/serve.py,33
tests/v1/kv_connector/unit/__init__.py,33
tests/v1/engine/test_detokenizer.py,33
tests/v1/cudagraph/__init__.py,33
tests/transformers_utils/test_utils.py,33
tests/samplers/__init__.py,33
tests/quantization/__init__.py,33
tests/models/__init__.py,33
tests/model_executor/__init__.py,33
tests/metrics/__init__.py,33
tests/lora/test_qwen3moe_tp.py,33
tests/lora/test_deepseekv2_tp.py,33
tests/kernels/__init__.py,33
tests/entrypoints/__init__.py,33
tests/engine/output_processor/__init__.py,33
tests/engine/__init__.py,33
tests/distributed/test_eplb_spec_decode.py,33
tests/distributed/__init__.py,33
tests/compile/piecewise/piecewise_compilation_config.json,33
tests/basic_correctness/__init__.py,33
playground/streaming_fastapi_worker.py,33
playground/http_client.py,33
examples/offline_inference/qwen2_5_omni/README.md,33
csrc/mamba/causal_conv1d/static_switch.h,33
csrc/cpu/dnnl_kernels.cpp,33
csrc/cpu/cpu_attn_vec16.hpp,33
csrc/cpu/cpu_attn_vec.hpp,33
Dockerfile.xpu => docker/Dockerfile.xpu,33
Dockerfile.tpu => docker/Dockerfile.tpu,33
Dockerfile.s390x => docker/Dockerfile.s390x,33
Dockerfile.rocm_base => docker/Dockerfile.rocm_base,33
Dockerfile.rocm => docker/Dockerfile.rocm,33
Dockerfile.ppc64le => docker/Dockerfile.ppc64le,33
Dockerfile.neuron => docker/Dockerfile.neuron,33
Dockerfile.hpu => docker/Dockerfile.hpu,33
Dockerfile.cpu => docker/Dockerfile.cpu,33
Dockerfile.arm => docker/Dockerfile.arm,33
Dockerfile => docker/Dockerfile,33
.github/workflows/scripts/pytorch-install.sh,33
.github/ISSUE_TEMPLATE/400-bug report.yml,33
.buildkite/nightly-benchmarks/scripts/compare-json-results.py,33
.buildkite/lm-eval-harness/configs/Qwen2-1.5B-Instruct-INT8-compressed-tensors.yaml,33
vllm/v1/worker/gpu/sample/metadata.py,32
vllm/v1/worker/gpu/async_utils.py,32
vllm/model_executor/layers/quantization/kernels/MPLinearKernel.py,32
vllm/entrypoints/openai/responses/api_router.py,32
vllm/distributed/kv_transfer/kv_connector/__init__.py,32
vllm/distributed/kv_transfer/disagg_prefill_workflow.jpg,32
tests/v1/core/test_priority_scheduler_random.py,32
tests/kernels/test_cutlass_moe.py,32
tests/entrypoints/test_responses_utils.py,32
examples/other/logging_configuration.md,32
examples/offline_inference_openai.md,32
examples/disaggregated_prefill.sh,32
docker/Dockerfile.s390x,32
csrc/quantization/machete/machete_collective_builder.cuh,32
csrc/cpu/sgl-kernels/moe.cpp,32
csrc/attention_utils.h,32
.buildkite/nightly-benchmarks/tests/serving-tests-cpu-snc2.json,32
.buildkite/lm-eval-harness/configs/Mixtral-8x7B-Instruct-v0.1.yaml,32
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct.yaml,32
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-nonuniform-compressed-tensors.yaml,32
.buildkite/lm-eval-harness/configs/Meta-Llama-3-70B-Instruct.yaml,32
vllm/utils/hashing.py,31
vllm/model_executor/models/transformers/__init__.py,31
vllm/model_executor/layers/quantization/quark/__init__.py,31
vllm/executor/utils.py,31
vllm/benchmarks/sweep/plot.py,31
tests/lora/test_minicpmv.py,31
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-ModelOpt-fi-cutlass-dp-ep.yaml,31
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-CT-fi-cutlass-dp-ep.yaml,31
docs/features/sleep_mode.md,31
cacheflow/parallel_utils/tensor_parallel/layers.py,31
.github/ISSUE_TEMPLATE/100-documentation.yml,31
.buildkite/nightly-benchmarks/tests/serving-tests.json,31
.buildkite/lm-eval-harness/configs/Qwen2-57B-A14-Instruct.yaml,31
.buildkite/lm-eval-harness/configs/Mixtral-8x7B-Instruct-v0.1-FP8.yaml,31
.buildkite/lm-eval-harness/configs/Mixtral-8x22B-Instruct-v0.1-FP8-Dynamic.yaml,31
.buildkite/lm-eval-harness/configs/DeepSeek-V2-Lite-Chat.yaml,31
vllm/{executor/ray_distributed_executor.py => v1/executor/ray_executor.py},30
vllm/{ => v1}/executor/uniproc_executor.py,30
vllm/{ => v1}/executor/ray_utils.py,30
vllm/v1/worker/workspace.py,30
vllm/v1/structured_output/grammar.py,30
vllm/model_executor/models/gemma2_embedding.py,30
vllm/model_executor/layers/rotary_embedding/xdrope.py,30
vllm/distributed/ec_transfer/ec_transfer_state.py,30
vllm/distributed/ec_transfer/ec_connector/shared_storage_connector.py,30
vllm/distributed/ec_transfer/ec_connector/__init__.py,30
vllm/distributed/ec_transfer/__init__.py,30
vllm/config/ec_transfer.py,30
tests/v1/ec_connector/unit/test_ec_shared_storage_connector.py,30
tests/v1/ec_connector/integration/hato.jpg,30
tests/models/test_gguf.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/test_qwen2_vl.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/test_qwen.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/test_phi3v.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/test_internvl.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/test_idefics3.py,30
tests/models/decoder_only/vision_language/{mm_processor_kwargs => processing}/__init__.py,30
examples/simple_fastapi_client.py,30
examples/online_serving/disaggregated_encoder/disagg_epd_proxy.py,30
docs/source/getting_started/installation/cpu-arm.md,30
docs/assets/features/disagg_encoder/disagg_encoder_flow.png,30
csrc/quantization/w8a8/cutlass/moe/moe_data.cu,30
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_blockwise_sm100_fp8_dispatch.cuh,30
csrc/moe/marlin_kernels/marlin_moe_kernel_ku4.h,30
csrc/moe/marlin_kernels/marlin_moe_kernel_ku4.cu,30
csrc/cuda_utils.cpp,30
csrc/cuda_primitives.h,30
.github/ISSUE_TEMPLATE/300-usage.yml,30
.github/ISSUE_TEMPLATE/200-installation.yml,30
.buildkite/test_areas/weight_loading.yaml,30
.buildkite/test_areas/samplers.yaml,30
.buildkite/test_areas/quantization.yaml,30
.buildkite/test_areas/plugins.yaml,30
.buildkite/test_areas/models_multimodal.yaml,30
.buildkite/test_areas/models_language.yaml,30
.buildkite/test_areas/models_distributed.yaml,30
.buildkite/test_areas/model_executor.yaml,30
.buildkite/test_areas/expert_parallelism.yaml,30
.buildkite/test_areas/engine.yaml,30
.buildkite/test_areas/cuda.yaml,30
.buildkite/test_areas/compile.yaml,30
.buildkite/test_areas/benchmarks.yaml,30
.buildkite/test_areas/basic_correctness.yaml,30
.buildkite/nightly-benchmarks/kickoff-pipeline.sh,30
.buildkite/image_build/image_build_hpu.sh,30
.buildkite/image_build/image_build_cpu_arm64.sh,30
.buildkite/image_build/image_build_cpu.sh,30
.buildkite/image_build/image_build.yaml,30
.buildkite/image_build/image_build.sh,30
.buildkite/ci_config.yaml,30
vllm/v1/worker/gpu/structured_outputs.py,29
vllm/transformers_utils/model_arch_config_convertor.py,29
vllm/model_executor/layers/quantization/kernels/scaled_mm/rocm.py,29
vllm/model_executor/layers/quantization/kernels/scaled_mm/pytorch.py,29
vllm/model_executor/layers/quantization/kernels/scaled_mm/flashinfer.py,29
vllm/model_executor/layers/quantization/cpu_wna16.py,29
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X.json",29
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X.json",29
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X.json",29
vllm/model_executor/guided_decoding/reasoner/__init__.py,29
vllm/core/{block_manager.py => block_manager_v1.py},29
vllm/core/block/__init__.py,29
tests/v1/kv_connector/unit/test_example_connector.py,29
tests/v1/entrypoints/__init__.py,29
tests/tokenizers_/test_mistral.py,29
tests/quantization/test_cpu_wna16.py,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-ModelOpt-marlin.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-ModelOpt-fi-trtllm.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-ModelOpt-fi-cutlass.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-CT-marlin.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-CT-fi-trtllm.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-NvFp4-CT-fi-cutlass.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Channel-vllm-cutlass.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Channel-marlin.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Block-vllm-cutlass.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-CT-Block-deepgemm.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-Fp8-AutoFp8-deepgemm.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Mixtral-8x7B-Fp8-AutoFp8-triton.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Mixtral-8x7B-Fp8-AutoFp8-fi-cutlass.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-Fp8-ModelOpt-marlin.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-Fp8-ModelOpt-fi-trtllm.yaml,29
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-Fp8-ModelOpt-fi-cutlass.yaml,29
tests/entrypoints/test_openai_vision.py,29
examples/template_florence2.jinja,29
examples/online_serving/disaggregated_serving/moriio_toy_proxy_server.py,29
examples/offline_inference/profiling_tpu/README.md,29
docs/source/quantization/fp8_e5m2_kv_cache.rst,29
docs/getting_started/installation/cpu.arm.inc.md,29
docs/features/custom_arguments.md,29
docs/design/paged_attention.md,29
csrc/moe/permute_unpermute_kernels/dispatch.h,29
csrc/cutlass_extensions/common.cpp,29
cacheflow/parallel_utils/parallel_state.py,29
.buildkite/lm-eval-harness/configs/models-small-rocm.txt,29
{vllm/v1/tokenizer => tests/v1}/__init__.py,28
vllm/v1/__init__.py,28
vllm/utils/collections.py,28
vllm/transformers_utils/configs/exaone4.py,28
vllm/entrypoints/serve/instrumentator/metrics.py,28
vllm/core/{embedding_model_block_manager.py => placeholder_block_space_manager.py},28
vllm/core/__init__.py,28
tools/ep_kernels/install_python_libraries.sh,28
tools/ep_kernels/elastic_ep/install_eep_libraries.sh,28
tests/v1/structured_output/test_gptoss_structural_tags.py,28
tests/v1/engine/__init__.py,28
tests/utils_/test_collections.py,28
tests/multimodal/__init__.py,28
tests/models/language/pooling/test_st_projector.py,28
tests/models/decoder_only/vision_language/test_phi4mm.py,28
tests/kernels/moe/deepep_utils.py,28
tests/kernels/activation.py,28
tests/entrypoints/openai/test_sparse_tensor_validation.py,28
rocm_patch/flashpy_xformers-0.0.22.post7.rocm.patch,28
rocm_patch/commonpy_xformers-0.0.22.post7.rocm.patch,28
patch_xformers-0.0.22.post7.rocm.sh,28
examples/run_cluster.sh,28
examples/production_monitoring/README.md,28
examples/offline_inference/{ => basic}/basic.py,28
examples/gguf_inference.py,28
csrc/{ => core}/registration.h,28
csrc/quantization/fp4/nvfp4_scaled_mm_kernels.cu,28
.github/ISSUE_TEMPLATE/400-bug-report.yml,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/throughput-tests.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/throughput-tests-cpu.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/serving-tests.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/serving-tests-cpu.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/serving-tests-cpu-snc3.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/serving-tests-cpu-snc2.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/nightly-tests.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/latency-tests.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/latency-tests-cpu.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/tests/genai-perf-tests.json,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/scripts/run-performance-benchmarks.sh,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/scripts/launch-server.sh,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/scripts/convert-results-json-to-markdown.py,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/scripts/compare-json-results.py,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/performance-benchmarks-descriptions.md,28
.buildkite/{nightly-benchmarks => performance-benchmarks}/README.md,28
.buildkite/lm-eval-harness/configs/Meta-Llama-3-8B-Instruct-INT8-compressed-tensors-asym.yaml,28
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X.json",27
tests/worker/__init__.py,27
tests/v1/worker/test_gpu_profiler.py,27
tests/v1/kv_connector/unit/test_output_aggregator.py,27
tests/evals/gsm8k/configs/Qwen1.5-MoE-W4A16-CT.yaml,27
tests/entrypoints/openai/test_enable_force_include_usage.py,27
examples/template_qwen_vl.jinja,27
examples/template_paligemma.jinja,27
examples/save_sharded_state.py,27
examples/logging_configuration.md,27
docker/Dockerfile.hpu,27
csrc/{quantization/cutlass_w8a8 => cutlass_extensions/epilogue}/broadcast_load_epilogue_c3x.hpp,27
csrc/{quantization/cutlass_w8a8 => cutlass_extensions/epilogue}/broadcast_load_epilogue_c2x.hpp,27
csrc/quantization/machete/machete_interleaving_utils.cuh,27
csrc/moe/permute_unpermute_kernels/moe_permute_unpermute_kernel.h,27
csrc/cutlass_extensions/vllm_type_utils.cuh,27
csrc/cutlass_extensions/vllm_custom_types.cuh,27
csrc/cache.cpp,27
cacheflow/master/simple_frontend.py,27
benchmarks/run_structured_output_benchmark.sh,27
.shellcheckrc,27
.dockerignore,27
vllm/v1/worker/gpu/sample/penalties.py,26
vllm/v1/worker/__init__.py,26
vllm/v1/tokenizer/__init__.py,26
vllm/v1/sample/__init__.py,26
vllm/v1/core/__init__.py,26
vllm/v1/attention/backends/__init__.py,26
vllm/v1/attention/__init__.py,26
vllm/model_executor/layers/quantization/kernels/marlin.py,26
vllm/lora/ops/xla_ops/pallas.py,26
vllm/entrypoints/{openai/serving_tokens.py => serve/disagg/serving.py},26
vllm/entrypoints/{openai/serving_tokenization.py => serve/tokenize/serving.py},26
vllm/entrypoints/{dynamic_lora.py => serve/lora/api_router.py},26
vllm/entrypoints/serve/tokenize/__init__.py,26
vllm/entrypoints/serve/sleep/__init__.py,26
vllm/entrypoints/serve/rlhf/api_router.py,26
vllm/entrypoints/serve/rlhf/__init__.py,26
vllm/entrypoints/serve/profile/__init__.py,26
vllm/entrypoints/serve/lora/__init__.py,26
vllm/entrypoints/serve/instrumentator/health.py,26
vllm/entrypoints/serve/instrumentator/__init__.py,26
vllm/entrypoints/serve/elastic_ep/middleware.py,26
vllm/entrypoints/serve/elastic_ep/__init__.py,26
vllm/entrypoints/serve/disagg/__init__.py,26
vllm/distributed/kv_transfer/kv_connector/v1/{shared_storage_connector.py => example_connector.py},26
vllm/distributed/ec_transfer/ec_connector/{shared_storage_connector.py => example_connector.py},26
tests/v1/kv_connector/unit/{test_shared_storage_connector.py => test_example_connector.py},26
tests/v1/ec_connector/unit/{test_ec_shared_storage_connector.py => test_ec_example_connector.py},26
tests/tpu/lora/test_pallas_kernels.py,26
tests/lora/data/__init__.py,26
tests/entrypoints/llm/test_mm_cache_stats.py,26
examples/{other => others}/tensorize_vllm_model.py,26
examples/{other => others}/logging_configuration.md,26
examples/{ => others}/lmcache/kv_cache_sharing_lmcache_v1.py,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v1/disagg_vllm_launcher.sh,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v1/disagg_proxy_server.py,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v1/disagg_example_nixl.sh,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v1/configs/lmcache-prefiller-config.yaml,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v1/configs/lmcache-decoder-config.yaml,26
examples/{ => others}/lmcache/disagg_prefill_lmcache_v0.py,26
examples/{ => others}/lmcache/cpu_offload_lmcache.py,26
examples/{ => others}/lmcache/README.md,26
examples/online_serving/{ => pooling}/prithvi_geospatial_mae.py,26
examples/online_serving/{ => pooling}/openai_cross_encoder_score_for_multimodal.py,26
examples/online_serving/{ => pooling}/openai_cross_encoder_score.py,26
examples/online_serving/structured_outputs/pyproject.toml,26
examples/offline_inference/{ => pooling}/prithvi_geospatial_mae_io_processor.py,26
examples/offline_inference/{ => pooling}/prithvi_geospatial_mae.py,26
examples/offline_inference/kv_load_failure_recovery/{rogue_shared_storage_connector.py => load_recovery_example_connector.py},26
docs/{usage => configuration}/env_vars.md,26
docs/{serving/seed_parameter_behavior.md => usage/reproducibility.md},26
docs/{serving => usage}/usage_stats.md,26
docs/{serving => usage}/metrics.md,26
docs/{serving => usage}/env_vars.md,26
docs/{serving => configuration}/serve_args.md,26
docs/{serving => configuration}/engine_args.md,26
docs/{performance => contributing}/benchmarks.md,26
docs/{performance => configuration}/optimization.md,26
docs/{getting_started/v1_user_guide.md => usage/v1_guide.md},26
docs/{getting_started => usage}/troubleshooting.md,26
docs/{getting_started => usage}/faq.md,26
docs/{deployment => usage}/security.md,26
docs/training/rlhf.md,26
docs/contributing/{overview.md => README.md},26
docker/Dockerfile.ppc64le,26
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm90_fp8.cu,26
csrc/prepare_inputs/advance_step.cuh,26
csrc/permute_cols.cu,26
csrc/core/batch_invariant.hpp,26
benchmarks/structured_schemas/structured_schema_1.json,26
benchmarks/kernels/requirements.txt,26
.github/workflows/matchers/ruff.json,26
.buildkite/lm-eval-harness/configs/Qwen1.5-MoE-W4A16-compressed-tensors.yaml,26
vllm/{inputs.py => inputs/data.py},25
vllm/v1/worker/gpu/sample/gumbel.py,25
vllm/utils/platform_utils.py,25
vllm/tokenizers/deepseekv32.py,25
vllm/entrypoints/pooling/embed/conftest.py,25
tests/v1/test_hybrid_lb_dp.py,25
tests/v1/structured_output/__init__.py,25
tests/v1/entrypoints/llm/__init__.py,25
tests/tool_use/__init__.py,25
tests/test_lazy_torch_compile.py,25
tests/multimodal/{test_processor.py => test_mapper.py},25
tests/entrypoints/pooling/embed/conftest.py,25
tests/entrypoints/pooling/basic/test_truncation.py,25
tests/entrypoints/pooling/basic/test_encode.py,25
examples/tool_chat_template_mistral_parallel.jinja,25
examples/tool_chat_template_mistral.jinja,25
examples/tool_chat_template_hermes.jinja,25
examples/pooling/score/vision_score_api_online.py,25
examples/pooling/score/vision_rerank_api_online.py,25
examples/openai_chat_completion_client_with_tools.py,25
examples/online_serving/dashboards/perses/README.md,25
examples/online_serving/dashboards/grafana/README.md,25
examples/offline_inference/disaggregated_prefill_lmcache.py,25
csrc/quantization/marlin/dense/LICENSE,25
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_helper.hpp,25
csrc/moe/permute_unpermute_kernels/moe_permute_unpermute_kernel.inl,25
csrc/attention/dtype_fp8_e5m2.cuh,25
cacheflow/parallel_utils/tensor_parallel/__init__.py,25
cacheflow/models/gpt_neox.py,25
benchmarks/{benchmark_serving_guided.py => benchmark_serving_structured_output.py},25
.github/workflows/dummy.yml,25
.github/workflows/doc-lint.yml,25
.buildkite/lm-eval-harness/run-lm-eval-mmlupro-vllm-baseline.sh,25
.buildkite/lm-eval-harness/run-lm-eval-chartqa-vllm-vlm-baseline.sh,25
.buildkite/lm-eval-harness/configs/SparseLlama3.1_2of4_fp8_compressed.yaml,25
.buildkite/lm-eval-harness/configs/Meta-Llama-3-70B-Instruct-FBGEMM-nonuniform.yaml,25
vllm/worker/{embedding_model_runner.py => pooling_model_runner.py},24
vllm/worker/{cpu_embedding_model_runner.py => cpu_pooling_model_runner.py},24
vllm/v1/attention/backends/fa_utils.py,24
vllm/utils/async_utils.py,24
vllm/multimodal/{ => media}/base.py,24
vllm/multimodal/media/video.py,24
vllm/multimodal/media/image.py,24
vllm/multimodal/media/audio.py,24
vllm/multimodal/media/__init__.py,24
vllm/lora/ops/{ => triton_ops}/utils.py,24
vllm/lora/ops/{ => triton_ops}/sgmv_shrink.py,24
vllm/lora/ops/{ => triton_ops}/sgmv_expand.py,24
vllm/lora/ops/{ => triton_ops}/bgmv_shrink.py,24
vllm/lora/ops/{ => triton_ops}/bgmv_expand_slice.py,24
vllm/lora/ops/{ => triton_ops}/bgmv_expand.py,24
vllm/lora/ops/triton_ops/v1/__init__.py,24
tests/v1/e2e/{test_async_sched_and_preempt.py => test_async_scheduling.py},24
tests/utils_/test_system_utils.py,24
tests/tokenizers_/test_detokenize.py,24
tests/multimodal/media/test_video.py,24
tests/multimodal/media/test_image.py,24
tests/multimodal/media/test_base.py,24
tests/multimodal/media/test_audio.py,24
tests/multimodal/media/__init__.py,24
tests/models/language/pooling/test_extract_hidden_states.py,24
tests/lora/{test_punica_variation.py => test_punica_ops_variation.py},24
tests/lora/{test_punica_sizes.py => test_punica_ops_sizes.py},24
tests/kernels/quantization/test_silu_nvfp4_quant_fusion.py,24
tests/evals/gsm8k/configs/Qwen3-0.6B-FP8.yaml,24
tests/evals/gsm8k/configs/Qwen2.5-VL-3B-Instruct-FP8-dynamic.yaml,24
tests/evals/gsm8k/configs/Llama-3.2-1B-Instruct-INT8-CT.yaml,24
tests/evals/gsm8k/configs/Llama-3-8B-Instruct-nonuniform-CT.yaml,24
tests/evals/gsm8k/README.md,24
tests/entrypoints/openai/{test_skip_tokenizer.py => test_vision_embeds.py},24
examples/offline_inference/logits_processor.py,24
docs/source/{serving => usage}/usage_stats.md,24
docs/source/{serving => usage}/faq.rst,24
docs/source/{serving => usage}/env_vars.rst,24
docs/source/{serving => usage}/compatibility_matrix.rst,24
docs/source/{models/vlm.rst => usage/multimodal_inputs.rst},24
docs/source/{models => usage}/structured_outputs.rst,24
docs/source/{models => usage}/spec_decode.rst,24
docs/source/{models => usage}/performance.rst,24
docs/source/{models => usage}/lora.rst,24
docs/source/{models => usage}/engine_args.rst,24
docs/getting_started/installation/ai_accelerator/neuron.inc.md,24
docs/design/debug_vllm_compile.md,24
csrc/{cache.cpp => cache.h},24
csrc/quantization/cutlass_w8a8/{scaled_mm_c3x_sm90_int8_dispatch.cuh => c3x/scaled_mm_sm90_int8_dispatch.cuh},24
csrc/quantization/cutlass_w8a8/{scaled_mm_c3x_sm90_fp8_dispatch.cuh => c3x/scaled_mm_sm90_fp8_dispatch.cuh},24
csrc/quantization/cutlass_w8a8/{scaled_mm_c3x.cuh => c3x/scaled_mm.cuh},24
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm90_int8.cu,24
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_blockwise_sm90_fp8.cu,24
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_azp_sm90_int8.cu,24
csrc/cumem_allocator.cpp,24
.buildkite/nightly-benchmarks/run-benchmarks-suite.sh,24
.buildkite/lm-eval-harness/configs/Meta-Llama-3.2-1B-Instruct-INT8-compressed-tensors.yaml,24
vllm/utils/{func.py => functools.py},23
vllm/utils/{async_utils.py => asyncio.py},23
vllm/utils/collection_utils.py,23
vllm/transformers_utils/{tokenizer_group => }/tokenizer_group.py,23
vllm/model_executor/models/step_vl.py,23
"vllm/model_executor/layers/quantization/utils/configs/N=8192,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=128,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1152,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=1024,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=256,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=2304,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=2048,K=512,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=1536,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8,block_shape=[128,128].json",23
vllm/entrypoints/openai/chat_utils.py,23
vllm/distributed/kv_transfer/{kv_transfer_agent.py => kv_connector_agent.py},23
vllm/config/profiler.py,23
vllm/benchmarks/sweep/cli.py,23
tools/ep_kernels/elastic_ep/eep_nvshmem.patch,23
tests/v1/kv_connector/unit/test_decode_bench_connector.py,23
tests/v1/generation/test_rms_norm_batch_invariant.py,23
tests/v1/entrypoints/openai/serving_responses/test_image.py,23
tests/models/decoder_only/language/test_granitemoe.py,23
tests/models/decoder_only/language/test_big_models.py,23
tests/lora/test_gptoss_tp.py,23
tests/core/__init__.py,23
examples/pooling/token_embed/{multi_vector_retrieval_client.py => multi_vector_retrieval_online.py},23
examples/pooling/token_embed/{multi_vector_retrieval.py => multi_vector_retrieval_offline.py},23
examples/pooling/token_embed/{jina_embeddings_v4.py => jina_embeddings_v4_offline.py},23
examples/pooling/token_classify/{ner_client.py => ner_online.py},23
examples/pooling/token_classify/{ner.py => ner_offline.py},23
examples/pooling/pooling/{openai_pooling_client.py => pooling_online.py},23
examples/pooling/plugin/{prithvi_geospatial_mae_client.py => prithvi_geospatial_mae_online.py},23
examples/pooling/embed/{openai_embedding_matryoshka_fy.py => openai_embedding_matryoshka_fy_client.py},23
examples/pooling/embed/{embedding_requests_bytes_client.py => embedding_requests_bytes_online.py},23
examples/pooling/embed/{embedding_requests_base64_client.py => embedding_requests_base64_online.py},23
examples/pooling/embed/{embed_matryoshka_fy.py => embed_matryoshka_fy_offline.py},23
examples/pooling/embed/{embed_jina_embeddings_v3.py => embed_jina_embeddings_v3_offline.py},23
examples/paligemma_example.py,23
examples/online_serving/elastic_ep/scale.py,23
examples/online_serving/elastic_ep/bench.sh,23
examples/offline_inference/kv_load_failure_recovery/run.sh,23
examples/offline_inference/disaggregated-prefill-v1/run.sh,23
docs/source/{dev/offline_inference/offline_index.md => api/offline_inference/index.md},23
docs/source/{dev/engine/engine_index.md => api/engine/index.md},23
docs/source/{dev => api}/offline_inference/llm_inputs.md,23
docs/source/{dev => api}/offline_inference/llm.md,23
docs/source/{dev => api}/engine/llm_engine.md,23
docs/source/{dev => api}/engine/async_llm_engine.md,23
docs/source/{design/multimodal/multimodal_index.md => api/multimodal/index.md},23
docs/source/dev/sampling_params.md,23
docs/source/dev/pooling_params.md,23
docs/source/assets/{dev => contributing}/dockerfile-stages-dependency.png,23
docs/source/api/params.md,23
docs/governance/collaboration.md,23
docs/design/optimization_levels.md,23
csrc/sampler.cu,23
csrc/quantization/{gptq_marlin/gptq_marlin.cu => marlin/marlin.cu},23
csrc/quantization/{gptq_marlin => marlin}/marlin_template.h,23
csrc/quantization/{gptq_marlin => marlin}/marlin_mma.h,23
csrc/quantization/{gptq_marlin => marlin}/marlin_int4_fp8_preprocess.cu,23
csrc/quantization/{gptq_marlin => marlin}/marlin_dtypes.cuh,23
csrc/quantization/{gptq_marlin => marlin}/marlin.cuh,23
csrc/quantization/{gptq_marlin => marlin}/kernel.h,23
csrc/quantization/{gptq_marlin => marlin}/gptq_marlin_repack.cu,23
csrc/quantization/{gptq_marlin => marlin}/generate_kernels.py,23
csrc/quantization/{gptq_marlin => marlin}/dequant.h,23
csrc/quantization/{gptq_marlin => marlin}/awq_marlin_repack.cu,23
csrc/quantization/{gptq_marlin => marlin}/.gitignore,23
csrc/quantization/gptq_allspark/allspark_repack.cu,23
csrc/attention/mla/cutlass_mla_kernels.cu,23
cacheflow/{frontend/utils.py => server/tokenizer_utils.py},23
cacheflow/parallel_utils/utils.py,23
cacheflow/parallel_utils/tensor_parallel/utils.py,23
cacheflow/parallel_utils/tensor_parallel/random.py,23
cacheflow/parallel_utils/tensor_parallel/mappings.py,23
cacheflow/parallel_utils/README.md,23
.github/workflows/add_label_automerge.yml,23
.buildkite/nightly-benchmarks/tests/throughput-tests-cpu.json,23
.buildkite/nightly-benchmarks/tests/latency-tests-cpu.json,23
vllm/v1/core/specialized_manager.py,22
vllm/model_executor/models/{prithvi_geospatial_mae.py => terratorch.py},22
vllm/model_executor/models/vlm_base.py,22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB.json",22
"vllm/model_executor/layers/fused_moe/configs/E=1,N=14336,device_name=NVIDIA_A100-SXM4-80GB,dtype=int8_w8a16.json",22
tests/utils_/test_serial_utils.py,22
tests/models/decoder_only/vision_language/processing/test_qwen2_vl.py,22
tests/models/decoder_only/vision_language/processing/test_phi3v.py,22
tests/kernels/moe/__init__.py,22
tests/entrypoints/pooling/{openai/test_vision_embedding.py => embed/test_online_vision.py},22
tests/entrypoints/pooling/{openai/test_vision_classification.py => classify/test_online_vision.py},22
tests/entrypoints/pooling/{openai/test_score.py => score/test_online_score.py},22
tests/entrypoints/pooling/{openai/test_rerank.py => score/test_online_rerank.py},22
tests/entrypoints/pooling/{openai/test_pooling.py => pooling/test_online.py},22
tests/entrypoints/pooling/{openai/test_embedding_long_text.py => embed/test_online_long_text.py},22
tests/entrypoints/pooling/{openai/test_embedding_dimensions.py => embed/test_online_dimensions.py},22
tests/entrypoints/pooling/{openai/test_embedding.py => embed/test_online.py},22
tests/entrypoints/pooling/{openai/test_classification.py => classify/test_online.py},22
tests/entrypoints/pooling/{openai => embed}/__init__.py,22
tests/entrypoints/pooling/{openai => basic}/test_truncation.py,22
tests/entrypoints/pooling/{llm/test_score.py => score/test_offline.py},22
tests/entrypoints/pooling/{llm/test_reward.py => reward/test_offline.py},22
tests/entrypoints/pooling/{llm/test_embedding.py => embed/test_offline.py},22
tests/entrypoints/pooling/{llm/test_classify.py => classify/test_offline.py},22
tests/entrypoints/pooling/{llm => classify}/__init__.py,22
tests/entrypoints/pooling/{llm => basic}/test_encode.py,22
tests/entrypoints/pooling/{correctness/test_mteb_score.py => score/test_correctness_mteb.py},22
tests/entrypoints/pooling/{correctness/test_mteb_embed.py => embed/test_correctness_mteb.py},22
tests/entrypoints/pooling/{correctness => basic}/__init__.py,22
tests/entrypoints/pooling/score/__init__.py,22
tests/entrypoints/pooling/reward/__init__.py,22
tests/entrypoints/pooling/pooling/__init__.py,22
examples/pooling/score/using_template_online.py,22
examples/pooling/score/using_template_offline.py,22
examples/pooling/score/template/qwen3_reranker.jinja,22
examples/pooling/score/template/mxbai_rerank_v2.jinja,22
examples/pooling/score/template/bge-reranker-v2-gemma.jinja,22
examples/pooling/score/qwen3_reranker_offline.py,22
examples/pooling/score/offline_reranker.py,22
examples/online_serving/sagemaker-entrypoint.sh,22
examples/offline_inference/openai/openai_batch.md,22
docs/source/dev/engine/llm_engine.rst,22
csrc/cpu/{cpu_attn_macros.h => cpu_arch_macros.h},22
csrc/cpu/sgl-kernels/moe_int8.cpp,22
csrc/cpu/sgl-kernels/moe_fp8.cpp,22
csrc/cpu/sgl-kernels/gemm_fp8.cpp,22
csrc/cpu/sgl-kernels/gemm.cpp,22
csrc/cpu/cpu_fused_moe.cpp,22
.github/ISSUE_TEMPLATE/700-performance discussion.yml,22
vllm/v1/worker/gpu/spec_decode/eagle_cudagraph.py,21
vllm/v1/worker/gpu/sample/min_p.py,21
vllm/v1/sample/{logits_processor.py => logits_processor/builtin.py},21
vllm/transformers_utils/configs/qwen2vl.py,21
vllm/transformers_utils/configs/aria.py,21
vllm/profiler/{gpu_profiler.py => wrapper.py},21
vllm/model_executor/tensorizer_loader.py,21
vllm/model_executor/layers/quantization/qutlass_utils.py,21
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X.json",21
vllm/entrypoints/{score_utils.py => pooling/score/utils.py},21
vllm/entrypoints/pooling/base/__init__.py,21
tests/v1/{sample/test_logits_processors.py => logits_processors/test_correctness.py},21
tests/v1/logits_processors/__init__.py,21
tests/models/language/pooling/test_splade_sparse_pooler.py,21
tests/models/language/pooling/test_qwen3_reranker_seq_cls.py,21
tests/entrypoints/openai/test_response_api_parsable_context.py,21
examples/pooling/score/vision_reranker_offline.py,21
examples/pooling/classify/openai_classification_client.py,21
examples/pooling/classify/classification_online.py,21
examples/openai_chat_embedding_client_for_multimodal.py,21
docs/source/{usage => getting_started}/faq.md,21
docs/source/getting_started/{xpu-installation.md => installation/xpu.md},21
docs/source/getting_started/{tpu-installation.md => installation/tpu.md},21
docs/source/getting_started/{openvino-installation.md => installation/openvino.md},21
docs/source/getting_started/{neuron-installation.md => installation/neuron.md},21
docs/source/getting_started/{installation.md => installation/gpu-cuda.md},21
docs/source/getting_started/{gaudi-installation.md => installation/hpu-gaudi.md},21
docs/source/getting_started/{debugging.md => troubleshooting.md},21
docs/source/getting_started/{cpu-installation.md => installation/cpu-x86.md},21
docs/source/getting_started/{arm-installation.md => installation/cpu-arm.md},21
docs/source/getting_started/{amd-installation.md => installation/gpu-rocm.md},21
docs/getting_started/installation/ai_accelerator/hpu-gaudi.inc.md,21
csrc/reduction_utils.h,21
csrc/quantization/fp4/nvfp4_scaled_mm_entry.cu,21
csrc/quantization/cutlass_w4a8/w4a8_utils.cuh,21
csrc/quantization/cutlass_w4a8/w4a8_utils.cu,21
csrc/quantization/cutlass_w4a8/w4a8_grouped_mm_entry.cu,21
csrc/quantization/cutlass_w4a8/get_group_starts.cuh,21
csrc/fused_qknorm_rope_kernel.cu,21
csrc/cutlass_extensions/epilogue/broadcast_load_epilogue_array_c3x.hpp,21
csrc/core/registration.h,21
csrc/attention/mla/sm100_cutlass_mla_kernel.cu,21
benchmarks/kernels/bench_nvfp4_quant.py,21
.buildkite/scripts/scheduled_integration_test/qwen3_next_mtp_async_eplb.sh,21
vllm/v1/worker/gpu/dp_utils.py,20
vllm/v1/spec_decode/draft_model.py,20
vllm/v1/executor/{gpu_executor.py => uniproc_executor.py},20
vllm/triton_utils/sample.py,20
vllm/transformers_utils/processors/ovis2.py,20
vllm/model_executor/models/ovis2.py,20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=36864,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=1536,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",20
"vllm/model_executor/layers/quantization/utils/configs/N=12288,K=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8,block_shape=[128,128].json",20
vllm/model_executor/layers/fused_moe.py,20
vllm/entrypoints/openai/{serving_responses.py => responses/serving.py},20
vllm/entrypoints/openai/responses/protocol.py,20
vllm/entrypoints/openai/responses/__init__.py,20
tests/{worker => }/spec_decode/utils.py,20
tests/{worker => }/spec_decode/test_multi_step_worker.py,20
tests/{worker => }/spec_decode/__init__.py,20
tests/v1/attention/test_mamba_selectors.py,20
tests/models/test_llava_next_video.py,20
tests/models/language/pooling/test_override_pooler_config.py,20
tests/models/embedding/language/test_truncation_control.py,20
tests/models/decoder_only/vision_language/{test_internvl.py => test_awq.py},20
tests/model_executor/model_loader/runai_streamer_loader/conftest.py,20
tests/kernels/layernorm.py,20
tests/entrypoints/{openai => pooling}/correctness/test_mteb_score.py,20
tests/entrypoints/{openai => pooling}/correctness/test_mteb_embed.py,20
tests/entrypoints/{ => pooling}/openai/test_vision_embedding.py,20
tests/entrypoints/{ => pooling}/openai/test_truncation.py,20
tests/entrypoints/{ => pooling}/openai/test_score.py,20
tests/entrypoints/{ => pooling}/openai/test_rerank.py,20
tests/entrypoints/{ => pooling}/openai/test_pooling.py,20
tests/entrypoints/{ => pooling}/openai/test_embedding_long_text.py,20
tests/entrypoints/{ => pooling}/openai/test_embedding_dimensions.py,20
tests/entrypoints/{ => pooling}/openai/test_embedding.py,20
tests/entrypoints/{ => pooling}/openai/test_classification.py,20
tests/entrypoints/{ => pooling}/llm/test_score.py,20
tests/entrypoints/{ => pooling}/llm/test_reward.py,20
tests/entrypoints/{ => pooling}/llm/test_encode.py,20
tests/entrypoints/{ => pooling}/llm/test_embedding.py,20
tests/entrypoints/{ => pooling}/llm/test_classify.py,20
tests/entrypoints/pooling/openai/__init__.py,20
tests/entrypoints/pooling/llm/__init__.py,20
tests/entrypoints/pooling/correctness/__init__.py,20
tests/entrypoints/pooling/__init__.py,20
tests/entrypoints/openai/test_disable_mp.py,20
examples/pooling/embed/openai_embedding_long_text/service.sh,20
examples/pooling/embed/openai_embedding_long_text/client.py,20
examples/pooling/embed/openai_embedding_long_text/README.md,20
examples/offline_inference_scoring.py,20
examples/offline_inference_classification.py,20
docs/source/models/performance.rst,20
docs/source/getting_started/installation/{xpu.md => gpu/xpu.inc.md},20
docs/source/getting_started/installation/{tpu.md => ai_accelerator/tpu.inc.md},20
docs/source/getting_started/installation/{openvino.md => ai_accelerator/openvino.inc.md},20
docs/source/getting_started/installation/{neuron.md => ai_accelerator/neuron.inc.md},20
docs/source/getting_started/installation/{hpu-gaudi.md => ai_accelerator/hpu-gaudi.inc.md},20
docs/source/getting_started/installation/{gpu-rocm.md => gpu/rocm.inc.md},20
docs/source/getting_started/installation/{gpu-cuda.md => gpu/cuda.inc.md},20
docs/source/getting_started/installation/{cpu-x86.md => cpu/index.md},20
docs/source/getting_started/installation/{cpu-apple.md => cpu/apple.inc.md},20
docs/source/getting_started/installation/device.template.md,20
docs/source/dev/pooling_params.rst,20
csrc/quantization/gptq_marlin/{gptq_marlin_dtypes.cuh => marlin_dtypes.cuh},20
csrc/quantization/gptq_marlin/{gptq_marlin.cuh => marlin.cuh},20
cacheflow/model_executor/layers/activation.py,20
benchmarks/kernels/benchmark_moe_align_block_size.py,20
CODE_OF_CONDUCT.md,20
.github/ISSUE_TEMPLATE/750-RFC.yml,20
.github/ISSUE_TEMPLATE/700-performance-discussion.yml,20
vllm/v1/kv_offload/worker/__init__.py,19
vllm/v1/kv_offload/backends/__init__.py,19
vllm/v1/kv_offload/__init__.py,19
vllm/model_executor/layers/triton_kernel/__init__.py,19
vllm/model_executor/layers/quantization/compressed_tensors/__init__.py,19
vllm/model_executor/layers/mamba/ops/__init__.py,19
vllm/model_executor/layers/mamba/__init__.py,19
vllm/model_executor/layers/fused_moe/fused_moe_router.py,19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI325X,dtype=fp8_w8a8.json",19
"vllm/model_executor/layers/fused_moe/configs/E=60,N=704,device_name=AMD_Instinct_MI300X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=60,N=352,device_name=AMD_Instinct_MI300X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=60,N=176,device_name=AMD_Instinct_MI300X.json",19
"vllm/model_executor/layers/fused_moe/configs/E=60,N=1408,device_name=AMD_Instinct_MI300X.json",19
vllm/core/policy.py,19
vllm/compilation/rocm_aiter_fusion.py,19
tools/install_gdrcopy.sh,19
tests/{runai_model_streamer_test => model_executor/model_loader/runai_model_streamer}/test_weight_utils.py,19
tests/{runai_model_streamer_test => model_executor/model_loader/runai_model_streamer}/test_runai_utils.py,19
tests/{runai_model_streamer_test => model_executor/model_loader/runai_model_streamer}/test_runai_model_streamer_loader.py,19
tests/{runai_model_streamer_test => model_executor/model_loader/runai_model_streamer}/__init__.py,19
tests/{ => model_executor/model_loader}/tensorizer_loader/test_tensorizer.py,19
tests/{ => model_executor/model_loader}/tensorizer_loader/conftest.py,19
tests/{ => model_executor/model_loader}/tensorizer_loader/__init__.py,19
tests/{ => model_executor/model_loader}/fastsafetensors_loader/test_weight_utils.py,19
tests/{ => model_executor/model_loader}/fastsafetensors_loader/test_fastsafetensors_loader.py,19
tests/{ => model_executor/model_loader}/fastsafetensors_loader/__init__.py,19
tests/utils_/test_collection_utils.py,19
tests/tensorizer/test_tensorizer.py,19
tests/tensorizer/tensorize_vllm_model_for_testing.py,19
tests/tensorizer/__init__.py,19
tests/lora/{test_qwen2vl.py => test_qwenvl.py},19
tests/evals/gsm8k/configs/models-blackwell.txt,19
tests/entrypoints/test_openai_embedding.py,19
tests/entrypoints/openai/{test_accuracy.py => correctness/test_lmeval.py},19
tests/entrypoints/openai/correctness/__init__.py,19
tests/compile/test_compile_ranges.py,19
test_cli_client.py,19
requirements/openvino.txt,19
gradio_webserver.py => examples/gradio_webserver.py,19
examples/online_serving/opentelemetry/Otel.md,19
examples/offline_inference/qwen3_omni/only_thinker.py,19
examples/chart-helm/values.yaml,19
examples/chart-helm/values.schema.json,19
examples/chart-helm/templates/service.yaml,19
examples/chart-helm/templates/secrets.yaml,19
examples/chart-helm/templates/pvc.yaml,19
examples/chart-helm/templates/poddisruptionbudget.yaml,19
examples/chart-helm/templates/job.yaml,19
examples/chart-helm/templates/hpa.yaml,19
examples/chart-helm/templates/deployment.yaml,19
examples/chart-helm/templates/custom-objects.yaml,19
examples/chart-helm/templates/configmap.yaml,19
examples/chart-helm/templates/_helpers.tpl,19
examples/chart-helm/lintconf.yaml,19
examples/chart-helm/ct.yaml,19
examples/chart-helm/Chart.yaml,19
examples/chart-helm/.helmignore,19
docs/source/serving/deploying_with_helm.rst,19
docs/source/serving/architecture_helm_deployment.png,19
docs/source/design/multimodal/multimodal_index.md,19
docs/source/contributing/vulnerability_management.md,19
docs/cli/json_tip.inc.md,19
docs/cli/.meta.yml,19
docs/api/{summary.md => README.md},19
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_blockwise_sm120_fp8_dispatch.cuh,19
csrc/mamba/mamba_ssm/static_switch.h,19
cacheflow/{entrypoints/fastapi_server.py => server/async_llm_server.py},19
cacheflow/entrypoints/openai/protocol.py,19
assets/figures/perf_a10g_n3.png,19
assets/figures/perf_a10g_n1.png,19
assets/figures/perf_a100_n3.png,19
assets/figures/perf_a100_n1.png,19
.github/ISSUE_TEMPLATE/500-feature request.yml,19
vllm/utils/mem_constants.py,18
vllm/transformers_utils/processors/hunyuan_vl_image.py,18
vllm/model_executor/layers/fused_moe/zero_expert_fused_moe.py,18
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",18
vllm/model_executor/layers/fla/ops/kda.py,18
vllm/entrypoints/serve/rpc/api_router.py,18
vllm/entrypoints/serve/rpc/__init__.py,18
vllm/entrypoints/serve/instrumentator/server_info.py,18
vllm/entrypoints/serve/cache/api_router.py,18
vllm/entrypoints/serve/cache/__init__.py,18
vllm/entrypoints/cli/benchmark/sweep.py,18
vllm/benchmarks/sweep/param_sweep.py,18
tests/v1/kv_connector/kv_load_exception_handling/test.sh,18
tests/v1/kv_connector/kv_load_exception_handling/random_drop_connector.py,18
tests/tracing/__init__.py,18
tests/models/language/pooling/{test_cls_models.py => test_classification.py},18
tests/models/language/pooling/test_head_dtype.py,18
tests/models/language/generation/{test_models.py => test_common.py},18
tests/kernels/attention/test_flashinfer_trtllm_decode_attention.py,18
tests/entrypoints/{openai => sleep}/test_sleep.py,18
tests/entrypoints/{openai => rpc}/test_collective_rpc.py,18
tests/entrypoints/{openai => instrumentator}/test_metrics.py,18
tests/entrypoints/sleep/__init__.py,18
tests/entrypoints/rpc/__init__.py,18
tests/entrypoints/openai/test_messages.py,18
tests/entrypoints/instrumentator/__init__.py,18
tests/distributed/test_parallel_state.py,18
tests/async_engine/test_openai_server.py,18
examples/template_llava.jinja,18
examples/pooling/score/template/nemotron-rerank.jinja,18
examples/others/lmcache/disagg_prefill_lmcache_v1/disagg_vllm_launcher.sh,18
examples/online_serving/pooling/{ner.py => ner_client.py},18
examples/online_serving/openai_responses_client_with_tools.py,18
examples/online_serving/openai_embedding_long_text/client.py,18
examples/online_serving/openai_embedding_long_text/README.md,18
docs/source/features/quantization/bitblas.md,18
benchmarks/kernels/benchmark_polynorm.py,18
.github/ISSUE_TEMPLATE/800-misc discussion.yml,18
.github/ISSUE_TEMPLATE/600-new model.yml,18
.buildkite/performance-benchmarks/README.md,18
{examples => vllm/transformers_utils/chat_templates}/template_fuyu.jinja,17
{examples => vllm/transformers_utils/chat_templates}/template_deepseek_vl2.jinja,17
{examples => vllm/transformers_utils/chat_templates}/template_blip2.jinja,17
vllm/{entrypoints/openai/reasoning_parsers => reasoning}/granite_reasoning_parser.py,17
vllm/{entrypoints/openai/reasoning_parsers => reasoning}/deepseek_r1_reasoning_parser.py,17
vllm/{entrypoints/openai/reasoning_parsers => reasoning}/abs_reasoning_parsers.py,17
vllm/{entrypoints/openai/reasoning_parsers => reasoning}/__init__.py,17
vllm/v1/worker/gpu/__init__.py,17
vllm/v1/worker/gpu/README.md,17
vllm/transformers_utils/processors/hunyuan_vl.py,17
vllm/transformers_utils/configs/hunyuan_vl.py,17
vllm/model_executor/layers/quantization/quark/schemes/{quark_w4a4_mxfp4.py => quark_ocp_mx.py},17
vllm/model_executor/layers/quantization/kernels/{ => mixed_precision}/marlin.py,17
vllm/model_executor/layers/quantization/kernels/{ => mixed_precision}/machete.py,17
vllm/model_executor/layers/quantization/kernels/{ => mixed_precision}/exllama.py,17
vllm/model_executor/layers/quantization/kernels/{ => mixed_precision}/MPLinearKernel.py,17
vllm/model_executor/layers/ops/__init__.py,17
vllm/model_executor/layers/attention/backends/xformers.py,17
vllm/attention/layers/static_sink_attention.py,17
tests/{entrypoints/openai/reasoning_parsers => reasoning}/utils.py,17
tests/{entrypoints/openai/reasoning_parsers => reasoning}/test_granite_reasoning_parser.py,17
tests/{entrypoints/openai/reasoning_parsers => reasoning}/test_deepseekr1_reasoning_parser.py,17
tests/{entrypoints/openai/reasoning_parsers => reasoning}/__init__.py,17
tests/v1/metrics/test_perf_metrics.py,17
tests/v1/ec_connector/unit/test_ec_example_connector.py,17
tests/utils_/test_jsontree.py,17
tests/models/test_gguf_download.py,17
tests/models/test_compressed_tensors.py,17
tests/models/language/pooling_mteb_test/{mteb_utils.py => mteb_score_utils.py},17
tests/models/embedding/language/test_jina.py,17
tests/kernels/test_top_k_per_row.py,17
tests/kernels/moe/{test_mxfp4_moe.py => test_ocp_mx_moe.py},17
tests/entrypoints/openai/responses/test_mcp_tools.py,17
examples/template_qwen_vl_chat.jinja => vllm/transformers_utils/chat_templates/template_chatml.jinja,17
examples/template_chameleon.jinja => vllm/transformers_utils/chat_templates/template_basic.jinja,17
examples/minicpmv_example.py,17
docs/mkdocs/hooks/generate_metrics.py,17
docs/getting_started/installation/cpu.x86.inc.md,17
csrc/quantization/marlin/{ => dense}/marlin_cuda_kernel.cu,17
csrc/quantization/marlin/{ => dense}/LICENSE,17
csrc/quantization/marlin/sparse/LICENSE,17
csrc/quantization/gguf/moe.cuh,17
csrc/quantization/cutlass_w8a8/moe/blockwise_scaled_group_mm_sm100.cu,17
csrc/cpu/cpu_types_vxe.hpp,17
Dockerfile.rocm_base,17
.github/workflows/reminder_comment.yml,17
.github/workflows/cleanup_pr_body.yml,17
vllm/vllm_flash_attn/__init__.py,16
vllm/v1/core/{scheduler_output.py => sched/output.py},16
vllm/v1/core/{ => sched}/scheduler.py,16
vllm/v1/core/sched/__init__.py,16
vllm/transformers_utils/configs/ovis2.py,16
vllm/transformers_utils/configs/chameleon.py,16
vllm/model_executor/models/{transformers_moe.py => transformers/moe.py},16
vllm/model_executor/models/motif.py,16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=3072,device_name=NVIDIA_H20,dtype=fp8_w8a8.json",16
"vllm/model_executor/layers/fused_moe/configs/E=64,N=1536,device_name=NVIDIA_H20,dtype=fp8_w8a8.json",16
vllm/model_executor/layers/fla/ops/__init__.py,16
vllm/model_executor/layers/fla/__init__.py,16
vllm/distributed/eplb/policy/default.py,16
tools/check_repo.sh,16
tests/{engine => tokenization}/test_detokenize.py,16
tests/v1/test_internal_lb_dp.py,16
tests/v1/engine/test_parallel_sampling.py,16
tests/standalone_tests/python_only_compile.sh,16
tests/models/test_pixtral.py,16
tests/models/multimodal/generation/test_multimodal_gguf.py,16
tests/models/decoder_only/language/{test_jamba.py => test_hybrid.py},16
tests/entrypoints/{test_server_oot_registration.py => openai/test_oot_registration.py},16
tests/entrypoints/{test_openai_vision.py => openai/test_vision.py},16
tests/entrypoints/{test_openai_server.py => openai/test_models.py},16
tests/entrypoints/{test_openai_run_batch.py => openai/test_run_batch.py},16
tests/entrypoints/{test_openai_embedding.py => openai/test_embedding.py},16
tests/entrypoints/{test_openai_completion.py => openai/test_completion.py},16
tests/entrypoints/{test_openai_chat.py => openai/test_chat.py},16
tests/entrypoints/{test_llm_generate_multiple_loras.py => llm/test_generate_multiple_loras.py},16
tests/entrypoints/{test_llm_generate.py => llm/test_generate.py},16
tests/entrypoints/{test_llm_encode.py => llm/test_encode.py},16
tests/entrypoints/{ => openai}/test_guided_processors.py,16
tests/entrypoints/openai/__init__.py,16
tests/entrypoints/llm/__init__.py,16
tests/compile/{piecewise => fullgraph}/test_toy_llama.py,16
tests/compile/{piecewise => fullgraph}/test_simple.py,16
tests/compile/{piecewise => fullgraph}/test_multiple_graphs.py,16
tests/compile/{piecewise => fullgraph}/test_full_cudagraph.py,16
tests/compile/{piecewise => distributed}/__init__.py,16
tests/compile/{ => fullgraph}/test_multimodal_compile.py,16
tests/compile/{ => fullgraph}/test_full_graph.py,16
tests/compile/{ => fullgraph}/test_basic_correctness.py,16
tests/compile/{ => distributed}/test_sequence_parallelism.py,16
tests/compile/{ => distributed}/test_fusions_e2e.py,16
tests/compile/{ => distributed}/test_fusion_all_reduce.py,16
tests/compile/{ => distributed}/test_async_tp.py,16
tests/compile/piecewise/__init__.py,16
tests/compile/fullgraph/__init__.py,16
tests/compile/README.md,16
examples/tool_chat_template_hunyuan_a13b.jinja,16
examples/pooling/score/{cohere_rerank_online.py => cohere_rerank_client.py},16
examples/pooling/score/score_api_online.py,16
examples/online_serving/{ => pooling}/openai_pooling_client.py,16
examples/online_serving/{ => pooling}/openai_embedding_matryoshka_fy.py,16
examples/online_serving/{ => pooling}/openai_embedding_client.py,16
examples/online_serving/{ => pooling}/openai_classification_client.py,16
examples/online_serving/{ => pooling}/openai_chat_embedding_client_for_multimodal.py,16
examples/online_serving/{ => pooling}/jinaai_rerank_client.py,16
examples/online_serving/{ => pooling}/cohere_rerank_client.py,16
examples/offline_inference/{ => pooling}/qwen3_reranker.py,16
examples/offline_inference/{ => pooling}/embed_matryoshka_fy.py,16
examples/offline_inference/{ => pooling}/embed_jina_embeddings_v3.py,16
examples/offline_inference/{ => pooling}/convert_model_to_seq_cls.py,16
examples/lora_with_quantization_inference.py,16
csrc/quantization/fp8/{fp8_cuda_kernels.cu => common.cu},16
csrc/quantization/fp8/{amd_detail => amd}/quant_utils.cuh,16
csrc/quantization/fp8/{amd_detail => amd}/hip_float8_impl.h,16
csrc/quantization/fp8/{amd_detail => amd}/hip_float8.h,16
csrc/attention/vertical_slash_index.cu,16
cacheflow/models/activation.py,16
cacheflow/model_executor/weight_utils.py,16
cacheflow/model_executor/memory_analyzer.py,16
cacheflow/model_executor/layers/layernorm.py,16
cacheflow/master/frontend.py,16
.buildkite/lm-eval-harness/configs/models-large-h100.txt,16
.buildkite/lm-eval-harness/configs/Qwen2.5-VL-3B-Instruct-FP8-dynamic.yaml,16
.buildkite/lm-eval-harness/configs/Meta-Llama-4-Maverick-17B-128E-Instruct-FP8.yaml,16
vllm/transformers_utils/processors/{ovis2.py => ovis.py},15
vllm/transformers_utils/configs/{ovis2.py => ovis.py},15
vllm/profiler/gpu_profiler.py,15
vllm/model_executor/models/{ovis2.py => ovis.py},15
vllm/model_executor/models/vision_siglip_navit.py,15
vllm/model_executor/models/mistral_large_3.py,15
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/quantization/utils/configs/N=1536,K=7168,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
vllm/model_executor/layers/fused_moe/mori_prepare_finalize.py,15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=16384,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=AMD_Instinct_MI300X,dtype=fp8_w8a8.json",15
"vllm/model_executor/layers/fused_moe/configs/E=256,N=256,device_name=NVIDIA_L20,dtype=fp8_w8a8,block_shape=[128,128].json",15
"vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8.json",15
vllm/model_executor/layers/attention/mla_attention.py,15
vllm/fa_utils.py,15
vllm/entrypoints/{responses_utils.py => openai/responses/utils.py},15
vllm/entrypoints/{ => openai/responses}/context.py,15
vllm/entrypoints/{ => mcp}/tool_server.py,15
vllm/entrypoints/{ => mcp}/tool.py,15
vllm/entrypoints/mcp/__init__.py,15
vllm/entrypoints/grpc_server.py,15
vllm/attention/ops/rocm_aiter_mla_sparse.py,15
tools/update-dockerfile-graph.sh,15
tests/{tool_use => tool_parsers}/test_xlam_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_seed_oss_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_qwen3coder_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_openai_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_mistral_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_minimax_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_kimi_k2_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_jamba_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_glm4_moe_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_ernie45_moe_tool_parser.py,15
tests/{tool_use => tool_parsers}/test_deepseekv31_tool_parser.py,15
tests/{entrypoints/openai => model_executor}/test_guided_processors.py,15
tests/v1/test_kv_sharing.py,15
tests/v1/streaming_input/test_scheduler_streaming.py,15
tests/v1/streaming_input/test_gpu_model_runner_streaming.py,15
tests/v1/streaming_input/test_async_llm_streaming.py,15
tests/v1/streaming_input/__init__.py,15
tests/v1/kv_connector/unit/test_invalid_blocks_correctness.py,15
tests/v1/kv_connector/unit/test_error_propagation.py,15
tests/v1/kv_connector/unit/test_cache_pollution_prevention.py,15
tests/v1/entrypoints/openai/serving_responses/test_function_call.py,15
tests/v1/e2e/test_streaming_input.py,15
tests/v1/core/test_reset_prefix_cache_e2e.py,15
tests/tool_parsers/__init__.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_st_projector.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_snowflake_arctic_embed.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_qwen3_reranker.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_nomic.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_mxbai_rerank.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_jina.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_intfloat.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_gte.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_cross_encoder.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_bge_reranker_v2_gemma.py,15
tests/models/language/{pooling => pooling_mteb_test}/test_baai.py,15
tests/models/language/{pooling => pooling_mteb_test}/mteb_utils.py,15
tests/models/language/pooling_mteb_test/__init__.py,15
tests/evals/gsm8k/configs/models-small.txt,15
tests/evals/gsm8k/configs/Qwen3-30B-A3B-NVFP4.yaml,15
tests/entrypoints/test_grpc_server.py,15
tests/entrypoints/openai/test_responses_error.py,15
tests/entrypoints/openai/reasoning_parsers/__init__.py,15
examples/pooling/plugin/prithvi_geospatial_mae_client.py,15
examples/offline_inference_whisper.py,15
examples/offline_inference/llm_engine_reset_kv.py,15
examples/lmcache/kv_cache_sharing_lmcache_v1.py,15
csrc/sparse/cutlass/sparse_compressor_c3x.cuh,15
csrc/quantization/gptq_marlin/marlin_mma.h,15
csrc/quantization/fp8/fp8_cuda_kernels.cu,15
csrc/moe/grouped_topk_kernels.cu,15
csrc/attention/merge_attn_states.cu,15
.buildkite/performance-benchmarks/scripts/run-performance-benchmarks.sh,15
vllm/usage/__init__.py,14
vllm/model_executor/models/hunyuan_v1_moe.py,14
vllm/model_executor/layers/{shared_fused_moe => fused_moe}/shared_fused_moe.py,14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/{E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json => E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json}",14
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_H100_80GB_HBM3.json",14
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_A100-SXM4-80GB.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3072,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=16,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=96,device_name=NVIDIA_H20.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_H100_80GB_HBM3.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=384,device_name=NVIDIA_H20,dtype=fp8_w8a8,block_shape=[128,128].json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H200.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H20.json",14
"vllm/model_executor/layers/fused_moe/configs/E=128,N=192,device_name=NVIDIA_H100_80GB_HBM3.json",14
"vllm/model_executor/layers/fused_moe/configs/E=1,N=7168,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=1,N=3072,device_name=NVIDIA_H200,dtype=int8_w8a16.json",14
"vllm/model_executor/layers/fused_moe/configs/E=1,N=1792,device_name=NVIDIA_H100_80GB_HBM3,dtype=int8_w8a16.json",14
vllm/lora/ops/triton_ops/{v1/v1_shrink.py => lora_shrink.py},14
vllm/lora/ops/triton_ops/{v1/v1_kernel_metadata.py => lora_kernel_metadata.py},14
vllm/lora/ops/triton_ops/{v1/v1_expand.py => lora_expand.py},14
vllm/distributed/eplb/policy/abstract.py,14
vllm/distributed/eplb/async_worker.py,14
vllm/benchmarks/sweep/sla_sweep.py,14
tools/{ => pre_commit}/validate_config.py,14
tools/{ => pre_commit}/update-dockerfile-graph.sh,14
tools/{ => pre_commit}/shellcheck.sh,14
tools/{ => pre_commit}/png-lint.sh,14
tools/{ => pre_commit}/generate_nightly_torch_test.py,14
tools/{ => pre_commit}/enforce_regex_import.py,14
tools/{ => pre_commit}/check_triton_import.py,14
tools/{ => pre_commit}/check_spdx_header.py,14
tools/{ => pre_commit}/check_init_lazy_imports.py,14
tests/v1/kv_connector/unit/test_lmcache_connector.py,14
tests/v1/kv_connector/unit/test_config.py,14
tests/tokenizers_/{test_cached_tokenizer.py => test_hf.py},14
tests/multimodal/assets/rgba.png,14
tests/mq_llm_engine/__init__.py,14
tests/models/test_gptq_bitblas.py,14
tests/models/test_bitblas.py,14
tests/models/multimodal/generation/test_keye.py,14
tests/models/language/pooling/test_all_pooling_plus_chunked_prefill.py,14
tests/kernels/test_mla_decode_cpu.py,14
tests/kernels/moe/modular_kernel_tools/__init__.py,14
tests/evals/gsm8k/configs/DeepSeek-V2-Lite-Instruct-FP8.yaml,14
tests/entrypoints/pooling/reward/test_offline.py,14
tests/entrypoints/pooling/classify/test_offline.py,14
tests/entrypoints/openai/{test_serving_engine.py => test_serving_models.py},14
tests/entrypoints/openai/test_transcription_validation_whisper.py,14
tests/entrypoints/openai/correctness/{test_mteb.py => test_mteb_embed.py},14
server.py => cacheflow/master/server.py,14
examples/{llmserver_example.py => llm_engine_example.py},14
examples/production_monitoring/grafana.json,14
examples/production_monitoring/dummy_client.py,14
examples/openai_pooling_client.py,14
examples/online_serving/kv_events.sh,14
examples/offline_inference/{vision_language_embedding.py => vision_language_pooling.py},14
docs/source/training/rlhf.md,14
docs/source/assets/design/v1/prefix_caching/example-time-7.png,14
docs/source/assets/design/v1/prefix_caching/example-time-6.png,14
docs/source/assets/design/v1/prefix_caching/example-time-5.png,14
docs/source/assets/design/v1/prefix_caching/example-time-4.png,14
docs/source/assets/design/v1/prefix_caching/example-time-3.png,14
docs/source/assets/design/v1/prefix_caching/example-time-1.png,14
docs/source/assets/contributing/dockerfile-stages-dependency.png,14
docs/cli/bench/sweep/plot_pareto.md,14
docs/benchmarking/dashboard.md,14
docs/assets/design/{v1 => }/tpu/most_model_len.png,14
docs/assets/design/{v1 => }/prefix_caching/overview.png,14
docs/assets/design/{v1 => }/prefix_caching/free.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-7.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-6.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-5.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-4.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-3.png,14
docs/assets/design/{v1 => }/prefix_caching/example-time-1.png,14
docs/assets/design/{v1 => }/metrics/intervals-3.png,14
docs/assets/design/{v1 => }/metrics/intervals-2.png,14
docs/assets/design/{v1 => }/metrics/intervals-1.png,14
docker/versions.json,14
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm100_fp8_dispatch.cuh,14
csrc/moe/moe_wna16_utils.h,14
csrc/cpu/mla_decode.cpp,14
cacheflow/{server/llm_server.py => engine/llm_engine.py},14
cacheflow/{server/async_llm_server.py => engine/async_llm_engine.py},14
cacheflow/{server => engine}/tokenizer_utils.py,14
cacheflow/{server => engine}/ray_utils.py,14
cacheflow/{server => engine}/arg_utils.py,14
cacheflow/{server => engine}/__init__.py,14
cacheflow/master/{frontend.py => simple_frontend.py},14
cacheflow/http_frontend/test_cli_client.py,14
cacheflow/http_frontend/gradio_webserver.py,14
cacheflow/entrypoints/openai/api_server.py,14
cacheflow/entrypoints/api_server.py,14
benchmark/benchmark_cache.py,14
{assets => docs/source/assets}/figures/perf_a10g_n3_light.png,13
{assets => docs/source/assets}/figures/perf_a10g_n3_dark.png,13
{assets => docs/source/assets}/figures/perf_a10g_n1_light.png,13
{assets => docs/source/assets}/figures/perf_a10g_n1_dark.png,13
{assets => docs/source/assets}/figures/perf_a100_n3_light.png,13
{assets => docs/source/assets}/figures/perf_a100_n3_dark.png,13
{assets => docs/source/assets}/figures/perf_a100_n1_light.png,13
{assets => docs/source/assets}/figures/perf_a100_n1_dark.png,13
vllm/{v1/attention/backends/mla/common.py => model_executor/layers/attention/mla_attention.py},13
vllm/vllm_flash_attn/flash_attn_interface.pyi,13
vllm/v1/worker/gpu/buffer_utils.py,13
vllm/transformers_utils/repo_utils.py,13
vllm/transformers_utils/configs/olmo.py,13
vllm/transformers_utils/configs/isaac.py,13
vllm/model_executor/models/glm_ocr_mtp.py,13
vllm/model_executor/models/glm_ocr.py,13
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
"vllm/model_executor/layers/quantization/utils/configs/{N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json => N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json}",13
vllm/mocks/mock_nixl_connector.py,13
vllm/mocks/__init__.py,13
vllm/entrypoints/serve/lora/protocol.py,13
vllm/device_allocator/__init__.py,13
tests/v1/engine/{test_processor_multi_modal_uuids.py => test_process_multi_modal_uuids.py},13
tests/test_logprobs.py,13
tests/spec_decode/e2e/{test_correctness.py => test_multistep_correctness.py},13
tests/models/language/pooling/{test_override_pooler_config.py => test_pooler_config_init_behaviour.py},13
tests/kernels/core/test_apply_rotary_emb.py,13
tests/evals/gsm8k/configs/Qwen3-Next-80B-A3B-NVFP4-EP2.yaml,13
tests/entrypoints/test_harmony_utils.py,13
tests/entrypoints/anthropic/__init__.py,13
tests/config/draft_model_arch_groundtruth.json,13
requirements-adag.txt,13
examples/pooling/plugin/prithvi_geospatial_mae_offline.py,13
examples/others/lmcache/disagg_prefill_lmcache_v1/disagg_example_nixl.sh,13
examples/openai_example_batch.jsonl,13
examples/online_serving/prometheus_grafana/grafana.json,13
examples/lmcache/cpu_offload_lmcache_v1.py,13
examples/lmcache/README.md,13
docs/source/usage/faq.rst,13
docs/source/assets/logos/vllm-logo-text-light.png,13
docs/source/assets/logos/vllm-logo-text-dark.png,13
docs/source/assets/logos/vllm-logo-only-light.png,13
docs/mkdocs/overrides/partials/toc-item.html,13
csrc/quickreduce/quick_reduce_impl.cuh,13
csrc/quickreduce/quick_reduce.h,13
csrc/quantization/cutlass_w8a8/scaled_mm_c3x_sm100.cu,13
csrc/attention/attention_dtypes.cuh,13
cacheflow/server/tokenizer_utils.py,13
benchmark/benchmark_attention.py,13
.github/ISSUE_TEMPLATE/450-ci-failure.yml,13
.buildkite/{ => scripts}/upload-wheels.sh,13
.buildkite/{ => scripts}/run-multi-node-test.sh,13
.buildkite/{ => scripts}/run-benchmarks.sh,13
.buildkite/{ => scripts/hardware_ci}/run-xpu-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-tpu-v1-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-neuron-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-hpu-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-gh200-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-cpu-test.sh,13
.buildkite/{ => scripts/hardware_ci}/run-cpu-test-ppc64le.sh,13
.buildkite/{ => scripts/hardware_ci}/run-amd-test.sh,13
.buildkite/nightly-benchmarks/sample.yaml,13
.buildkite/lm-eval-harness/configs/Meta-Llama-4-Maverick-17B-128E-Instruct-FP8-MM.yaml,13
vllm/v1/worker/gpu/sample/logprob.py,12
vllm/v1/worker/gpu/mm/mrope_utils.py,12
vllm/utils/registry.py,12
vllm/transformers_utils/processors/deepseek_ocr.py,12
vllm/model_executor/{guided_logits_processors.py => guided_decoding/outlines_logits_processors.py},12
vllm/model_executor/{guided_decoding.py => guided_decoding/outlines_decoding.py},12
vllm/model_executor/models/glmasr_utils.py,12
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2304,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=2048,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=18432,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=7168,K=16384,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=512,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=4608,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=4096,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=32768,K=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=3072,K=1536,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
"vllm/model_executor/layers/quantization/utils/configs/N=24576,K=7168,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128, 128].json",12
vllm/model_executor/layers/fused_moe/routed_experts_capturer.py,12
"vllm/model_executor/layers/fused_moe/configs/E=16,N=800,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",12
"vllm/model_executor/layers/fused_moe/configs/E=16,N=6400,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",12
"vllm/model_executor/layers/fused_moe/configs/E=16,N=3200,device_name=NVIDIA_H100_80GB_HBM3,dtype=fp8_w8a8.json",12
vllm/entrypoints/openai/serving_tokens.py,12
vllm/entrypoints/cli/benchmark/mm_processor.py,12
vllm/compilation/{cuda_piecewise_backend.py => piecewise_backend.py},12
vllm/attention/ops/triton_prefill_attention.py,12
vllm/assets/__init__.py,12
tests/{data => config}/test_config.yaml,12
tests/runai_model_streamer/__init__.py,12
tests/multi_step/test_correctness.py,12
tests/multi_step/__init__.py,12
tests/models/{decoder_only/vision_language/processing => multimodal}/__init__.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_qwen2_vl.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_qwen.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_phi3v.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_llava_onevision.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_llava_next.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_internvl.py,12
tests/models/{decoder_only/vision_language => multimodal}/processing/test_idefics3.py,12
tests/models/test_phimoe.py,12
tests/models/multimodal/processing/__init__.py,12
tests/models/multimodal/generation/test_nemotron_parse.py,12
tests/model_executor/model_loader/{runai_model_streamer => runai_streamer_loader}/test_weight_utils.py,12
tests/model_executor/model_loader/{runai_model_streamer => runai_streamer_loader}/test_runai_utils.py,12
tests/model_executor/model_loader/{runai_model_streamer => runai_streamer_loader}/test_runai_model_streamer_loader.py,12
tests/model_executor/model_loader/{runai_model_streamer => runai_streamer_loader}/__init__.py,12
tests/model_executor/model_loader/runai_streamer_loader/test_runai_model_streamer_s3.py,12
tests/kernels/test_fused_moe.py,12
tests/kernels/moe/test_fused_topk.py,12
tests/entrypoints/test_utils.py,12
tests/entrypoints/openai/test_response_api_simple.py,12
tests/data/test_config.yaml,12
requirements/kv_connectors.txt,12
examples/{production_monitoring => prometheus_grafana}/prometheus.yaml,12
examples/{production_monitoring => prometheus_grafana}/grafana.json,12
examples/{production_monitoring => prometheus_grafana}/docker-compose.yaml,12
examples/{production_monitoring => prometheus_grafana}/README.md,12
examples/{production_monitoring => opentelemetry}/dummy_client.py,12
examples/{production_monitoring => opentelemetry}/Otel.md,12
examples/tool_chat_template_internlm2_tool.jinja,12
examples/online_serving/dashboards/perses/performance_statistics.yaml,12
examples/offline_inference/reproduciblity.py,12
docs/contributing/overview.md,12
docs/cli/bench/mm_processor.md,12
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_blockwise_sm100_fp8.cu,12
csrc/attention/mla/cutlass_mla_entry.cu,12
cmake/external_projects/qutlass.cmake,12
benchmarks/kernels/benchmark_fused_topk.py,12
.github/ISSUE_TEMPLATE/500-feature-request.yml,12
.buildkite/nightly-benchmarks/throughput-tests.json,12
.buildkite/nightly-benchmarks/serving-tests.json,12
.buildkite/nightly-benchmarks/latency-tests.json,12
.buildkite/lm-eval-harness/configs/models-mm-small.txt,12
.buildkite/lm-eval-harness/configs/models-mm-large-h100.txt,12
.buildkite/lm-eval-harness/configs/Qwen2.5-VL-7B-Instruct.yaml,12
{benchmark => benchmarks}/trace.py,11
{benchmark => benchmarks}/benchmark_text_completion.py,11
{benchmark => benchmarks}/benchmark_latency.py,11
vllm/utils/nccl.py,11
vllm/transformers_utils/processors/bagel.py,11
vllm/model_executor/layers/quantization/utils/{format_24.py => marlin_utils_test_24.py},11
vllm/lora/ops/triton_ops/README_TUNING.md,11
vllm/grpc/vllm_engine.proto,11
vllm/grpc/compile_protos.py,11
vllm/grpc/__init__.py,11
vllm/benchmarks/serve_multi.py,11
tests/{kernels.py => kernels/cache.py},11
tests/v1/{test_utils.py => utils.py},11
tests/v1/{ => metrics}/test_metrics_reader.py,11
tests/v1/{ => distributed}/test_internal_lb_dp.py,11
tests/v1/{ => distributed}/test_hybrid_lb_dp.py,11
tests/v1/{ => distributed}/test_external_lb_dp.py,11
tests/v1/{ => distributed}/test_async_llm_dp.py,11
tests/v1/{ => core}/test_kv_sharing.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/test_structured_output.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/test_stateful.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/test_image.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/test_basic.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/conftest.py,11
tests/v1/entrypoints/openai/{responses => serving_responses}/__init__.py,11
tests/v1/entrypoints/openai/responses/__init__.py,11
tests/v1/distributed/__init__.py,11
tests/utils_/{test_utils.py => test_argparse_utils.py},11
tests/tensorizer_loader/tensorize_vllm_model_for_testing.py,11
tests/spec_decode/e2e/test_integration_dist.py,11
tests/quantization/fp_quant.py,11
tests/models/multimodal/generation/conftest.py,11
tests/kernels/test_uva.py,11
tests/kernels/test_rocm_skinny_gemms.py,11
tests/kernels/test_nvfp4_quant.py,11
tests/kernels/test_allspark_gemm.py,11
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-BF16-triton.yaml,11
tests/evals/gsm8k/configs/moe-refactor/Qwen3-30B-A3B-BF16-fi-cutlass.yaml,11
tests/evals/gsm8k/configs/moe-refactor/Mixtral-8x7B-BF16-triton.yaml,11
tests/evals/gsm8k/configs/moe-refactor/Mixtral-8x7B-BF16-fi-cutlass.yaml,11
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-BF16-triton.yaml,11
tests/evals/gsm8k/configs/moe-refactor/Llama-4-Scout-BF16-fi-cutlass.yaml,11
tests/evals/gsm8k/configs/moe-refactor-dp-ep/Qwen3-30B-A3B-BF16-triton.yaml,11
tests/config/test_config_utils.py,11
tests/compile/test_multimodal_compile.py,11
tests/compile/fullgraph/test_multimodal_compile.py,11
examples/{offline_inference/disaggregated_prefill_lmcache.py => lmcache/disagg_prefill_lmcache_v0.py},11
examples/{offline_inference/cpu_offload_lmcache.py => lmcache/cpu_offload_lmcache_v0.py},11
examples/tool_chat_template_llama3.2_json.jinja,11
examples/tool_chat_template_llama3.1_json.jinja,11
examples/template_blip2.jinja,11
examples/online_serving/token_generation_client.py,11
examples/online_serving/pooling/{embedding_embed_dtype_client.py => embedding_requests_base64_client.py},11
examples/online_serving/pooling/embedding_requests_bytes_client.py,11
examples/offline_profile.py,11
examples/offline_inference/convert_model_to_seq_cls.py,11
examples/lmcache/disagg_prefill_lmcache_v1/disagg_vllm_launcher.sh,11
examples/lmcache/disagg_prefill_lmcache_v1/disagg_proxy_server.py,11
examples/lmcache/disagg_prefill_lmcache_v1/disagg_example_nixl.sh,11
examples/lmcache/disagg_prefill_lmcache_v1/configs/lmcache-prefiller-config.yaml,11
examples/lmcache/disagg_prefill_lmcache_v1/configs/lmcache-decoder-config.yaml,11
examples/fuyu_example.py,11
docs/source/dev/sampling_params.rst,11
docs/source/contributing/overview.rst,11
docs/design/dbo.md,11
csrc/quickreduce/base.h,11
csrc/quantization/marlin/marlin_cuda_kernel.cu,11
csrc/quantization/marlin/LICENSE,11
csrc/quantization/cutlass_w8a8/{scaled_mm_dq_entry.cu => scaled_mm_entry.cu},11
csrc/quantization/cutlass_w8a8/{scaled_mm_dq_c3x.cu => scaled_mm_c3x.cu},11
csrc/quantization/cutlass_w8a8/{scaled_mm_dq_c2x.cu => scaled_mm_c2x.cu},11
csrc/quantization/cutlass_w8a8/scaled_mm_c3x_sm120.cu,11
csrc/custom_quickreduce.cu,11
csrc/cuda_view.cu,11
csrc/attention/{attention_dtypes.cuh => attention_dtypes.h},11
csrc/attention/mla/cutlass_sm100_mla/kernel/sm100_mla_tile_scheduler.hpp,11
csrc/attention/mla/cutlass_sm100_mla/kernel/sm100_fmha_mla_tma_warpspecialized.hpp,11
csrc/attention/mla/cutlass_sm100_mla/kernel/sm100_fmha_mla_reduction.hpp,11
csrc/attention/mla/cutlass_sm100_mla/device/sm100_mla.hpp,11
cacheflow/worker/__init__.py,11
cacheflow/server/__init__.py,11
cacheflow/model_executor/layers/__init__.py,11
cacheflow/entrypoints/openai/__init__.py,11
cacheflow/entrypoints/__init__.py,11
cacheflow/core/__init__.py,11
benchmarks/kernels/bench_nvfp4_qutlass.py,11
benchmarks/kernels/bench_mxfp4_qutlass.py,11
benchmark/trace.py,11
assets/figures/perf_a10g_n3_light.png,11
assets/figures/perf_a10g_n3_dark.png,11
assets/figures/perf_a10g_n1_light.png,11
assets/figures/perf_a10g_n1_dark.png,11
assets/figures/perf_a100_n3_light.png,11
assets/figures/perf_a100_n3_dark.png,11
assets/figures/perf_a100_n1_light.png,11
assets/figures/perf_a100_n1_dark.png,11
.github/ISSUE_TEMPLATE/config.yml,11
.buildkite/scripts/scheduled_integration_test/qwen30b_a3b_fp8_block_ep_eplb.sh,11
.buildkite/scripts/scheduled_integration_test/deepseek_v2_lite_ep_eplb.sh,11
.buildkite/nightly-benchmarks/tests/descriptions.md,11
vllm/{vllm_flash_attn => attention/utils}/fa_utils.py,10
vllm/worker/__init__.py,10
vllm/v1/metrics/__init__.py,10
vllm/v1/core/kv_cache_metrics.py,10
vllm/transformers_utils/configs/bagel.py,10
vllm/model_executor/models/na_vit.py,10
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",10
vllm/lora/ops/triton_ops/v1/v1_shrink.py,10
vllm/lora/ops/triton_ops/v1/v1_kernel_metadata.py,10
vllm/lora/ops/triton_ops/v1/v1_expand.py,10
vllm/logging_utils/lazy.py,10
vllm/entrypoints/sagemaker/__init__.py,10
vllm/entrypoints/openai/translations/protocol.py,10
vllm/entrypoints/dynamic_lora.py,10
vllm/core/{evictor.py => evictor_v1.py},10
vllm/config/model_arch.py,10
vllm/benchmarks/sweep/server.py,10
tools/ep_kernels/configure_system_drivers.sh,10
tests/worker/spec_decode/test_multi_step_worker.py,10
tests/worker/spec_decode/__init__.py,10
tests/v1/{executor/test_multiproc_executor.py => kv_connector/unit/test_output_aggreagator.py},10
tests/v1/worker/__init__.py,10
tests/v1/sample/__init__.py,10
tests/v1/core/test_kv_cache_metrics.py,10
tests/v1/core/__init__.py,10
tests/test_test.py,10
tests/spec_decode/e2e/{test_integration_dist.py => test_integration_dist_tp4.py},10
tests/models/multimodal/processing/test_qwen3_omni.py,10
tests/models/decoder_only/audio_language/test_granite_speech.py,10
tests/kernels/utils_block.py,10
tests/kernels/test_lightning_attn.py,10
tests/kernels/test_flashmla.py,10
tests/fastsafetensors_loader/__init__.py,10
tests/entrypoints/sagemaker/test_sagemaker_stateful_sessions.py,10
tests/entrypoints/sagemaker/test_sagemaker_middleware_integration.py,10
tests/entrypoints/sagemaker/test_sagemaker_lora_adapters.py,10
tests/entrypoints/sagemaker/test_sagemaker_handler_overrides.py,10
tests/entrypoints/sagemaker/__init__.py,10
tests/config/test_model_arch_config.py,10
tests/config/base_model_arch_groundtruth.json,10
tests/benchmarks/__init__.py,10
requirements.txt => requirements-common.txt,10
requirements-cuda-arm64.txt,10
examples/tool_chat_template_toolace.jinja,10
examples/tool_chat_template_phi4_mini.jinja,10
examples/tool_chat_template_llama3.2_pythonic.jinja,10
examples/template_qwen_vl_chat.jinja,10
examples/template_pixtral_hf.jinja,10
examples/template_fuyu.jinja,10
examples/template_chameleon.jinja,10
examples/online_serving/structured_outputs/README.md,10
examples/online_serving/pooling/ner.py,10
examples/online_serving/dashboards/grafana/performance_statistics.json,10
docs/source/models/extensions/fastsafetensor.md,10
docs/source/dev/kernel/paged_attention.rst,10
docs/source/dev/engine/async_llm_engine.rst,10
docs/source/design/v1/torch_compile.md,10
docs/source/assets/kernel/value.png,10
docs/source/assets/kernel/v_vec.png,10
docs/getting_started/installation/cpu.s390x.inc.md,10
docs/design/lora_resolver_plugins.md,10
csrc/quantization/fp8/per_token_group_quant.cu,10
csrc/quantization/cutlass_w8a8/scaled_mm_c3x_sm90.cu,10
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm100_fp8.cu,10
csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c3x.hpp,10
csrc/quantization/cutlass_w8a8/broadcast_load_epilogue_c2x.hpp,10
csrc/cumem_allocator_compat.h,10
benchmarks/multi_turn/README.md,10
benchmarks/kernels/benchmark_trtllm_attention.py,10
.github/workflows/matchers/actionlint.json,10
.buildkite/nightly-benchmarks/tests/throughput-tests.json,10
.buildkite/nightly-benchmarks/tests/latency-tests.json,10
vllm/{engine/tokenizer_utils.py => transformers_utils/tokenizer.py},9
vllm/v1/worker/gpu/{ => sample}/penalties.py,9
vllm/v1/worker/gpu/spec_decode/rejection_sample.py,9
vllm/v1/worker/gpu/sample/__init__.py,9
vllm/v1/attention/backends/triton_mla.py,9
vllm/v1/attention/backends/mla/__init__.py,9
vllm/transformers_utils/configs/granite.py,9
vllm/transformers_utils/chat_templates/template_deepseek_ocr.jinja,9
vllm/model_executor/warmup/__init__.py,9
vllm/lora/{lora.py => lora_weights.py},9
vllm/lora/lora_model.py,9
vllm/logging/__init__.py,9
vllm/entrypoints/anthropic/protocol.py,9
vllm/distributed/kv_transfer/kv_connector/v1/moriio/moriio_engine.py,9
vllm/distributed/kv_transfer/kv_connector/v1/moriio/moriio_common.py,9
vllm/distributed/kv_transfer/kv_connector/v1/moriio/__init__.py,9
vllm/benchmarks/sweep/utils.py,9
vllm/benchmarks/sweep/__init__.py,9
vllm/attention/layers/__init__.py,9
tools/png-lint.sh,9
tools/install_nixl_from_source_ubuntu.py,9
tests/v1/kv_connector/unit/test_moriio_connector.py,9
tests/v1/kv_connector/__init__.py,9
tests/v1/e2e/__init__.py,9
tests/system_messages/sonnet3.5_nov2024.txt,9
tests/models/test_intern_vit.py,9
tests/models/test_danube3_4b.py,9
tests/models/fixtures/pixtral_chat_engine.pickle,9
tests/models/fixtures/pixtral_chat_engine.json,9
tests/models/fixtures/pixtral_chat.pickle,9
tests/models/decoder_only/language/test_nvfp4.py,9
tests/kernels/test_merge_attn_states.py,9
tests/kernels/moe/test_cutedsl_moe.py,9
tests/entrypoints/openai/{test_responses_function_call_parsing.py => responses/test_function_call_parsing.py},9
tests/entrypoints/openai/{test_responses_error.py => responses/test_errors.py},9
tests/entrypoints/openai/{test_response_api_with_harmony.py => responses/test_harmony.py},9
tests/entrypoints/openai/{test_response_api_simple.py => responses/test_simple.py},9
tests/entrypoints/openai/{test_response_api_parsable_context.py => responses/test_parsable_context.py},9
tests/entrypoints/openai/{test_response_api_mcp_tools.py => responses/test_mcp_tools.py},9
tests/entrypoints/openai/tool_parsers/__init__.py,9
tests/entrypoints/openai/responses/__init__.py,9
tests/entrypoints/anthropic/test_messages.py,9
tests/distributed/test_pynccl_library.py,9
tests/distributed/test_multiproc_executor.py,9
examples/{simple_server.py => llmserver_example.py},9
examples/{simple_fastapi_client.py => api_client.py},9
examples/tool_chat_template_llama4_pythonic.jinja,9
examples/pooling/score/{vision_language_reranker.py => vision_reranker_offline.py},9
examples/pooling/score/{openai_reranker.py => rerank_api_online.py},9
examples/pooling/score/{openai_cross_encoder_score.py => score_api_online.py},9
examples/pooling/score/{cohere_rerank_client.py => cohere_rerank_online.py},9
examples/pooling/score/openai_cross_encoder_score_for_multimodal.py,9
examples/pooling/embed/{openai_chat_embedding_client_for_multimodal.py => vision_embedding_online.py},9
examples/pooling/embed/vision_embedding_offline.py,9
examples/pooling/embed/embedding_requests_bytes_client.py,9
examples/openai_chatcompletion_client.py,9
examples/online_serving/openai_translation_client.py,9
examples/online_serving/disaggregated_prefill.sh,9
examples/online_serving/chart-helm/values.schema.json,9
examples/online_serving/chart-helm/tests/pvc_test.yaml,9
examples/online_serving/chart-helm/tests/job_test.yaml,9
examples/online_serving/chart-helm/tests/deployment_test.yaml,9
examples/online_serving/chart-helm/templates/job.yaml,9
examples/online_serving/chart-helm/templates/deployment.yaml,9
examples/online_serving/chart-helm/templates/_helpers.tpl,9
examples/offline_inference_with_default_generation_config.py,9
docs/source/{dev => design}/multimodal/multimodal_index.rst,9
docs/source/{dev => design}/multimodal/adding_multimodal_plugin.rst,9
docs/source/{dev => design}/kernel/paged_attention.rst,9
docs/source/{dev => design}/input_processing/model_inputs_index.rst,9
docs/source/{dev => design}/input_processing/input_processing_pipeline.rst,9
docs/source/{dev => contributing}/profiling/profiling_index.rst,9
docs/source/{dev => contributing}/dockerfile/dockerfile.rst,9
docs/source/serving/prompt_embeds.md,9
docs/source/design/arch_overview.rst,9
docs/source/assets/design/v1/prefix_caching/overview.png,9
docs/source/assets/design/v1/prefix_caching/free.png,9
docs/source/assets/design/arch_overview/llm_engine.excalidraw.png,9
docs/source/assets/design/arch_overview/entrypoints.excalidraw.png,9
docs/assets/{kernel => design/paged_attention}/value.png,9
docs/assets/{kernel => design/paged_attention}/v_vec.png,9
docs/assets/{kernel => design/paged_attention}/query.png,9
docs/assets/{kernel => design/paged_attention}/q_vecs.png,9
docs/assets/{kernel => design/paged_attention}/logits_vec.png,9
docs/assets/{kernel => design/paged_attention}/key.png,9
docs/assets/{kernel => design/paged_attention}/k_vecs.png,9
docs/assets/deployment/hf-inference-endpoints-select-model.png,9
docs/assets/deployment/hf-inference-endpoints-select-hardware.png,9
docs/assets/deployment/hf-inference-endpoints-new-endpoint.png,9
docs/assets/deployment/hf-inference-endpoints-locate-deploy-button.png,9
docs/assets/deployment/hf-inference-endpoints-create-endpoint.png,9
docs/assets/deployment/hf-inference-endpoints-configure-container.png,9
docs/assets/deployment/hf-inference-endpoints-click-deploy-button.png,9
docs/assets/deployment/hf-inference-endpoints-choose-infra.png,9
docs/assets/deployment/hf-inference-endpoints-catalog.png,9
docs/api/summary.md,9
csrc/quantization/hadamard/hadacore/hadamard_transform_cuda.cu,9
csrc/quantization/cutlass_w8a8/cutlass_visitor_2x_broadcast_epilogue.hpp,9
csrc/punica/{punica_ops.cc => punica_ops.cu},9
cacheflow/entrypoints/{simple_fastapi_frontend.py => api_server.py},9
cacheflow/entrypoints/openai/{openai_frontend.py => api_server.py},9
benchmarks/trace.py,9
benchmarks/benchmark_text_completion.py,9
.github/workflows/scripts/create_release.js,9
.buildkite/test-template-aws.j2,9
.buildkite/scripts/upload-rocm-wheels.sh,9
.buildkite/scripts/cache-rocm-base-wheels.sh,9
.buildkite/scripts/annotate-rocm-release.sh,9
vllm/{transformers_utils => tokenizers}/detokenizer_utils.py,8
vllm/{ => vllm_flash_attn}/fa_utils.py,8
vllm/v1/worker/gpu/spec_decode/__init__.py,8
vllm/v1/sample/tpu/__init__.py,8
vllm/v1/sample/ops/utils.py,8
vllm/v1/attention/ops/triton_unified_attention.py,8
vllm/transformers_utils/configs/speculators/__init__.py,8
vllm/plugins/lora_resolvers/__init__.py,8
vllm/model_executor/models/whisper_causal.py,8
vllm/model_executor/models/step1.py,8
vllm/model_executor/layers/quantization/kernels/mixed_precision/cpu.py,8
vllm/model_executor/layers/quantization/compressed_tensors/transform/utils.py,8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=7168,device_name=NVIDIA_A100-SXM4-80GB.json",8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=4096,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=3584,device_name=NVIDIA_H100_80GB_HBM3.json",8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=2048,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_H100_80GB_HBM3.json",8
"vllm/model_executor/layers/fused_moe/configs/E=8,N=1792,device_name=NVIDIA_A100-SXM4-80GB.json",8
"vllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=40,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=20,N=2560,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_H100,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_GB200,dtype=fp8_w8a8,block_shape=[128,128].json",8
"vllm/model_executor/layers/fused_moe/configs/E=160,N=640,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",8
vllm/lora/{models.py => model_manager.py},8
vllm/exceptions.py,8
vllm/entrypoints/{ => openai/parser}/harmony_utils.py,8
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/__init__.py,8
vllm/compilation/__init__.py,8
tools/install_deepgemm.sh,8
tests/v1/e2e/{test_ngram_spec_decode.py => test_spec_decode.py},8
tests/v1/determinism/conftest.py,8
tests/plugins/lora_resolvers/__init__.py,8
tests/neuron/{ => 2_core}/test_comm_ops.py,8
tests/neuron/{ => 1_core}/test_rotary_embedding.py,8
tests/neuron/{ => 1_core}/test_prefix_prefill.py,8
tests/neuron/{ => 1_core}/test_logits_processor.py,8
tests/neuron/{ => 1_core}/test_layernorm.py,8
tests/neuron/{ => 1_core}/test_cache.py,8
tests/neuron/{ => 1_core}/test_block_table.py,8
tests/neuron/{ => 1_core}/test_activation.py,8
tests/neuron/test_rotary_embedding.py,8
tests/neuron/test_layernorm.py,8
tests/neuron/test_activation.py,8
tests/models/multimodal/processing/test_audioflamingo3.py,8
tests/models/multimodal/generation/test_voxtral_streaming.py,8
tests/models/multimodal/generation/test_audioflamingo3.py,8
tests/models/language/pooling/test_bge_m3.py,8
tests/models/language/generation_ppl_test/test_qwen.py,8
tests/models/language/generation_ppl_test/test_gpt.py,8
tests/models/language/generation_ppl_test/test_gemma.py,8
tests/models/language/generation_ppl_test/__init__.py,8
tests/models/fixtures/audioflamingo3/expected_results_single.json,8
tests/models/fixtures/audioflamingo3/expected_results_batched.json,8
tests/models/decoder_only/language/test_marlin.py,8
tests/model_executor/model_loader/__init__.py,8
tests/entrypoints/{openai => }/conftest.py,8
tests/entrypoints/{ => openai/parser}/test_harmony_utils.py,8
tests/entrypoints/openai/parser/__init__.py,8
tests/compile/__init__.py,8
tests/benchmarks/sweep/test_serve_sla.py,8
examples/{template_vlm2vec.jinja => template_vlm2vec_phi3v.jinja},8
examples/template_vlm2vec_qwen2vl.jinja,8
examples/online_serving/dashboards/perses/query_statistics.yaml,8
examples/offline_inference_with_profiler.py,8
docs/source/getting_started/v1_user_guide.md,8
docs/source/features/quantization/torchao.md,8
docs/source/features/quantization/int4.md,8
docs/source/assets/kernel/query.png,8
docs/source/assets/kernel/q_vecs.png,8
docs/source/assets/kernel/logits_vec.png,8
docs/source/assets/kernel/key.png,8
docs/source/assets/kernel/k_vecs.png,8
docs/source/assets/figures/perf_a10g_n3_light.png,8
docs/source/assets/figures/perf_a10g_n3_dark.png,8
docs/source/assets/figures/perf_a10g_n1_light.png,8
docs/source/assets/figures/perf_a10g_n1_dark.png,8
docs/source/assets/figures/perf_a100_n3_light.png,8
docs/source/assets/figures/perf_a100_n3_dark.png,8
docs/source/assets/figures/perf_a100_n1_light.png,8
docs/source/assets/figures/perf_a100_n1_dark.png,8
docs/source/api/{params.md => inference_params.md},8
docs/examples/README.md,8
docs/design/{v1 => }/torch_compile.md,8
docs/design/{v1 => }/prefix_caching.md,8
docs/design/{v1 => }/p2p_nccl_connector.md,8
docs/design/{v1 => }/multiprocessing.md,8
docs/design/{v1 => }/metrics.md,8
docs/design/{kernel => }/paged_attention.md,8
docs/contributing/incremental_build.md,8
docs/benchmarking/sweeps.md,8
docs/benchmarking/cli.md,8
csrc/{moe_align_block_size_kernels.cu => moe/moe_align_sum_kernels.cu},8
csrc/moe/moe_wna16.cu,8
collect_env.py => vllm/collect_env.py,8
cacheflow/models/layernorm.py,8
cacheflow/model_executor/input_metadata.py,8
benchmarks/multi_turn/generate_multi_turn.json,8
benchmarks/kv_cache/benchmark_block_pool.py,8
benchmarks/kernels/{benchmark_trtllm_attention.py => benchmark_trtllm_decode_attention.py},8
.buildkite/scripts/scheduled_integration_test/deepseek_v2_lite_ep_async_eplb.sh,8
.buildkite/performance-benchmarks/tests/serving-tests-cpu.json,8
.buildkite/lm-eval-harness/configs/Minitron-4B-Base.yaml,8
vllm/{ => utils}/jsontree.py,7
vllm/v1/metrics/perf.py,7
vllm/v1/attention/ops/rocm_aiter_mla_sparse.py,7
vllm/v1/attention/ops/flashmla.py,7
vllm/utils/counter.py,7
vllm/transformers_utils/configs/tarsier2.py,7
vllm/tokenizers/grok2.py,7
vllm/tokenizers/deepseek_v32_encoding.py,7
vllm/third_party/flashmla/__init__.py,7
vllm/server/launch.py,7
vllm/server/__init__.py,7
vllm/plugins/lora_resolvers/hf_hub_resolver.py,7
vllm/model_executor/layers/sparse_attn_indexer.py,7
"vllm/model_executor/layers/fused_moe/configs/E=8,N=8192,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",7
"vllm/model_executor/layers/fused_moe/configs/E=8,N=14336,device_name=NVIDIA_H100_80GB_HBM3,dtype=float8.json",7
"vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=AMD_Instinct_MI308X.json",7
vllm/entrypoints/serve/instrumentator/static/swagger-ui.css,7
vllm/entrypoints/serve/instrumentator/static/swagger-ui-bundle.js,7
vllm/entrypoints/serve/instrumentator/offline_docs.py,7
vllm/entrypoints/openai/{serving_transcription.py => translations/serving.py},7
vllm/entrypoints/openai/{ => translations}/speech_to_text.py,7
vllm/entrypoints/openai/translations/__init__.py,7
vllm/entrypoints/openai/reasoning_parsers/granite_reasoning_parser.py,7
vllm/entrypoints/openai/parser/__init__.py,7
vllm/entrypoints/constants.py,7
vllm/entrypoints/cli/benchmark/__init__.py,7
vllm/distributed/kv_transfer/kv_connector/v1/p2p/__init__.py,7
vllm/distributed/kv_transfer/kv_connector/v1/lmcache_integration/multi_process_adapter.py,7
vllm/distributed/eplb/policy/__init__.py,7
vllm/distributed/device_communicators/{custom_all_reduce_utils.py => all_reduce_utils.py},7
tools/vllm-tpu/build.sh,7
tools/flashinfer-build.sh,7
tools/ep_kernels/install_system_libraries.sh,7
tools/ep_kernels/install_system_drivers.sh,7
tests/{samplers => engine}/test_stop_reason.py,7
tests/v1/engine/{test_detokenizer.py => test_output_processor.py},7
tests/quantization/test_gptq_v2.py,7
tests/plugins_tests/test_stats_logger_plugins.py,7
tests/plugins/vllm_add_dummy_stat_logger/setup.py,7
tests/plugins/vllm_add_dummy_stat_logger/dummy_stat_logger/dummy_stat_logger.py,7
tests/plugins/lora_resolvers/test_hf_hub_resolver.py,7
tests/models/language/generation/test_grok.py,7
tests/mistral_tool_use/__init__.py,7
tests/kernels/{ => attention}/test_cutlass_mla_decode.py,7
tests/entrypoints/openai/reasoning_parsers/test_granite_reasoning_parser.py,7
tests/entrypoints/openai/parser/test_harmony_utils.py,7
tests/async_engine/{test_openapi_server_ray.py => test_openapi_server.py},7
tests/async_engine/{test_openai_server.py => test_chat_template.py},7
examples/tool_chat_template_xlam_qwen.jinja,7
examples/tool_chat_template_xlam_llama.jinja,7
examples/template_dse_qwen2_vl.jinja,7
examples/pooling/token_embed/jina_embeddings_v4.py,7
examples/pooling/score/vision_language_reranker.py,7
examples/pooling/score/template/qwen3_vl_reranker.jinja,7
examples/online_serving/pooling/embedding_embed_dtype_client.py,7
examples/online_serving/disagg_xpyd/disagg_prefill_proxy_xpyd.py,7
examples/offline_inference_pixtral.py,7
examples/offline_inference_neuron_int8_quantization.py,7
examples/offline_inference_arctic.py,7
docs/source/{dev/multimodal/adding_multimodal_model.rst => models/enabling_multimodal_inputs.rst},7
docs/source/getting_started/{installation/index.md => installation.md},7
docs/source/getting_started/installation/{gpu/index.md => gpu.md},7
docs/source/getting_started/installation/{cpu/index.md => cpu.md},7
docs/source/getting_started/installation/{ai_accelerator/index.md => ai_accelerator.md},7
docs/design/v1/prefix_caching.md,7
csrc/quantization/w8a8/cutlass/moe/blockwise_scaled_group_mm_sm100.cu,7
csrc/quantization/utils.cuh,7
csrc/quantization/gguf/moe_vec.cuh,7
csrc/quantization/cutlass_w8a8/moe/{grouped_mm_c3x.cu => grouped_mm_c3x_sm90.cu},7
csrc/quantization/cutlass_w8a8/moe/grouped_mm_c3x_sm100.cu,7
csrc/cpu/cpu_attn_neon.hpp,7
cacheflow/model_executor/parallel_utils/utils.py,7
cacheflow/model_executor/parallel_utils/tensor_parallel/utils.py,7
cacheflow/model_executor/parallel_utils/tensor_parallel/random.py,7
cacheflow/model_executor/parallel_utils/tensor_parallel/mappings.py,7
cacheflow/model_executor/parallel_utils/tensor_parallel/layers.py,7
cacheflow/model_executor/parallel_utils/tensor_parallel/__init__.py,7
cacheflow/model_executor/parallel_utils/parallel_state.py,7
benchmarks/multi_turn/requirements.txt,7
.buildkite/scripts/tpu/docker_run_bm.sh,7
.buildkite/scripts/tpu/config_v6e_1.env,7
.buildkite/scripts/annotate-release.sh,7
.buildkite/nightly-benchmarks/{ => tests}/throughput-tests.json,7
.buildkite/nightly-benchmarks/{ => tests}/serving-tests.json,7
.buildkite/nightly-benchmarks/{ => tests}/latency-tests.json,7
vllm/{engine => executor}/ray_utils.py,6
vllm/v1/worker/gpu/sample/states.py,6
vllm/v1/worker/gpu/sample/output.py,6
vllm/v1/worker/gpu/metrics/logits.py,6
vllm/v1/worker/gpu/metrics/__init__.py,6
vllm/v1/kv_offload/arc_manager.py,6
vllm/v1/attention/ops/vit_attn_wrappers.py,6
vllm/profiler/wrapper.py,6
vllm/model_executor/models/exaone_moe_mtp.py,6
vllm/model_executor/models/bee.py,6
vllm/model_executor/layers/{ => fused_moe}/fused_moe.py,6
"vllm/model_executor/layers/quantization/utils/configs/N=2112,K=7168,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128,128].json",6
vllm/model_executor/layers/quantization/kernels/exllama.py,6
vllm/model_executor/layers/quantization/compressed_tensors/schemes/compressed_tensors_w4a16.py,6
"vllm/model_executor/layers/fused_moe/configs/E=64,N=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
"vllm/model_executor/layers/fused_moe/configs/E=512,N=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
"vllm/model_executor/layers/fused_moe/configs/E=512,N=256,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
"vllm/model_executor/layers/fused_moe/configs/E=512,N=128,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
"vllm/model_executor/layers/fused_moe/configs/E=256,N=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
"vllm/model_executor/layers/fused_moe/configs/E=128,N=512,device_name=NVIDIA_B200,dtype=fp8_w8a8,block_shape=[128,128].json",6
vllm/benchmarks/{ => lib}/utils.py,6
vllm/benchmarks/{ => lib}/endpoint_request_func.py,6
vllm/benchmarks/lib/__init__.py,6
tools/profiler/nsys_profile_tools/README.md,6
tests/{config => data}/test_config.yaml,6
tests/v1/spec_decode/test_acceptance_length.py,6
tests/v1/kv_connector/unit/{test_output_aggreagator.py => test_output_aggregator.py},6
tests/v1/e2e/test_lora_with_spec_decode.py,6
tests/samplers/test_stop_reason.py,6
tests/runai_model_streamer_test/test_runai_utils.py,6
tests/multi_step/{test_correctness.py => test_correctness_async_llm.py},6
tests/models/test_modelopt.py,6
tests/models/multimodal/{generation => }/conftest.py,6
tests/models/embedding/language/test_snowflake_arctic_embed.py,6
tests/lora/{test_chatglm3.py => test_chatglm3_tp.py},6
tests/kernels/test_triton_moe_ptpc_fp8.py,6
tests/kernels/test_nvfp4_scaled_mm.py,6
tests/kernels/test_int8_kernel.py,6
tests/kernels/test_block_int8.py,6
tests/entrypoints/test_openai_run_batch.py,6
tests/entrypoints/test_openai_chat.py,6
gradio_webserver.py,6
examples/tool_chat_template_granite_20b_fc.jinja,6
examples/template_inkbot.jinja,6
examples/template_chatml.jinja,6
examples/template_alpaca.jinja,6
examples/production_monitoring/prometheus.yaml,6
examples/production_monitoring/docker-compose.yaml,6
examples/openi_example_batch.jsonl,6
examples/openai_completion_client.py,6
examples/online_serving/{disagg_examples => disaggregated_serving}/disagg_proxy_demo.py,6
examples/online_serving/{ => disaggregated_serving}/kv_events.sh,6
examples/online_serving/opentelemetry/{Otel.md => README.md},6
examples/online_serving/disaggregated_serving/README.md,6
examples/online_serving/dashboards/grafana/query_statistics.json,6
examples/online_serving/dashboards/README.md,6
examples/offline_inference/{openai/openai_batch.md => openai_batch/README.md},6
examples/offline_inference/{openai => openai_batch}/openai_example_batch.jsonl,6
examples/offline_inference/torchrun_dp_example.py,6
examples/cpu_offload.py,6
docs/source/performance_benchmark/benchmarks.rst,6
docs/source/features/quantization/gptqmodel.md,6
docs/source/dev/multimodal/adding_multimodal_plugin.rst,6
docs/community/sponsors.md,6
docker/Dockerfile.tpu,6
csrc/quantization/w8a8/fp8/common.cu,6
csrc/quantization/cutlass_w8a8/{cutlass_visitor_2x_broadcast_epilogue.hpp => broadcast_load_epilogue_c2x.hpp},6
csrc/quantization/cutlass_w8a8/scaled_mm_c3x_sm90_int8_dispatch.cuh,6
csrc/quantization/cutlass_w8a8/scaled_mm_c3x_sm90_fp8_dispatch.cuh,6
csrc/quantization/cutlass_w8a8/scaled_mm_c3x.cuh,6
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm120_fp8_dispatch.cuh,6
csrc/quantization/cutlass_w8a8/c3x/scaled_mm_sm120_fp8.cu,6
csrc/moe/dynamic_4bit_int_moe_cpu.cpp,6
cacheflow/models/gpt2.py,6
cacheflow/master/policy.py,6
benchmarks/multi_turn/bench_utils.py,6
benchmarks/benchmark_prefix_block_hash.py,6
benchmarks/benchmark_hash.py,6
